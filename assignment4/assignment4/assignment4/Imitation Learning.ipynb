{"cells":[{"cell_type":"markdown","metadata":{"id":"GG62yXq0ewfI"},"source":["# Imitation Learning with Neural Network Policies\n","In this notebook, you will implement the supervised losses for behavior cloning and use it to train policies for locomotion tasks."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PpuMxrKajKbh"},"outputs":[],"source":["import os\n","from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":137922,"status":"ok","timestamp":1616560292016,"user":{"displayName":"Anthony Ng","photoUrl":"","userId":"16843483630260605487"},"user_tz":-480},"id":"8e9OHWWEe8fE","outputId":"4f495b8e-7833-4964-9b7c-e4cb149b2f9a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Hit:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n","Ign:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n","Hit:3 http://security.ubuntu.com/ubuntu bionic-security InRelease\n","Ign:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n","Hit:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n","Hit:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n","Hit:7 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n","Hit:8 http://archive.ubuntu.com/ubuntu bionic InRelease\n","Hit:10 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n","Hit:11 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n","Hit:13 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n","Hit:14 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n","Hit:15 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n","Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","54 packages can be upgraded. Run 'apt list --upgradable' to see them.\n","/content/gdrive/My Drive/282/mujoco\n","/content/gdrive/My Drive/282/mujoco\n","/content/gdrive/My Drive/282/mujoco/mujoco-py\n","Obtaining file:///content/gdrive/My%20Drive/282/mujoco/mujoco-py\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","\u001b[33m  WARNING: Missing build requirements in pyproject.toml for file:///content/gdrive/My%20Drive/282/mujoco/mujoco-py.\u001b[0m\n","\u001b[33m  WARNING: The project does not specify a build backend, and pip cannot fall back to setuptools without 'wheel'.\u001b[0m\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: imageio\u003e=2.1.2 in /usr/local/lib/python3.7/dist-packages (from mujoco-py==2.0.2.13) (2.4.1)\n","Requirement already satisfied: fasteners~=0.15 in /usr/local/lib/python3.7/dist-packages (from mujoco-py==2.0.2.13) (0.16)\n","Requirement already satisfied: cffi\u003e=1.10 in /usr/local/lib/python3.7/dist-packages (from mujoco-py==2.0.2.13) (1.14.5)\n","Requirement already satisfied: glfw\u003e=1.4.0 in /usr/local/lib/python3.7/dist-packages (from mujoco-py==2.0.2.13) (2.1.0)\n","Requirement already satisfied: numpy\u003e=1.11 in /usr/local/lib/python3.7/dist-packages (from mujoco-py==2.0.2.13) (1.19.5)\n","Requirement already satisfied: Cython\u003e=0.27.2 in /usr/local/lib/python3.7/dist-packages (from mujoco-py==2.0.2.13) (0.29.22)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from imageio\u003e=2.1.2-\u003emujoco-py==2.0.2.13) (7.0.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from fasteners~=0.15-\u003emujoco-py==2.0.2.13) (1.15.0)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi\u003e=1.10-\u003emujoco-py==2.0.2.13) (2.20)\n","Installing collected packages: mujoco-py\n","  Found existing installation: mujoco-py 2.0.2.13\n","    Can't uninstall 'mujoco-py'. No files were found to uninstall.\n","  Running setup.py develop for mujoco-py\n","Successfully installed mujoco-py\n","Compiling /content/gdrive/My Drive/282/mujoco/mujoco-py/mujoco_py/cymj.pyx because it changed.\n","[1/1] Cythonizing /content/gdrive/My Drive/282/mujoco/mujoco-py/mujoco_py/cymj.pyx\n","running build_ext\n","building 'mujoco_py.cymj' extension\n","creating /content/gdrive/My Drive/282/mujoco/mujoco-py/mujoco_py/generated/_pyxbld_2.0.2.13_37_linuxcpuextensionbuilder\n","creating /content/gdrive/My Drive/282/mujoco/mujoco-py/mujoco_py/generated/_pyxbld_2.0.2.13_37_linuxcpuextensionbuilder/temp.linux-x86_64-3.7\n","creating /content/gdrive/My Drive/282/mujoco/mujoco-py/mujoco_py/generated/_pyxbld_2.0.2.13_37_linuxcpuextensionbuilder/temp.linux-x86_64-3.7/content\n","creating /content/gdrive/My Drive/282/mujoco/mujoco-py/mujoco_py/generated/_pyxbld_2.0.2.13_37_linuxcpuextensionbuilder/temp.linux-x86_64-3.7/content/gdrive\n","creating /content/gdrive/My Drive/282/mujoco/mujoco-py/mujoco_py/generated/_pyxbld_2.0.2.13_37_linuxcpuextensionbuilder/temp.linux-x86_64-3.7/content/gdrive/My Drive\n","creating /content/gdrive/My Drive/282/mujoco/mujoco-py/mujoco_py/generated/_pyxbld_2.0.2.13_37_linuxcpuextensionbuilder/temp.linux-x86_64-3.7/content/gdrive/My Drive/282\n","creating /content/gdrive/My Drive/282/mujoco/mujoco-py/mujoco_py/generated/_pyxbld_2.0.2.13_37_linuxcpuextensionbuilder/temp.linux-x86_64-3.7/content/gdrive/My Drive/282/mujoco\n","creating /content/gdrive/My Drive/282/mujoco/mujoco-py/mujoco_py/generated/_pyxbld_2.0.2.13_37_linuxcpuextensionbuilder/temp.linux-x86_64-3.7/content/gdrive/My Drive/282/mujoco/mujoco-py\n","creating /content/gdrive/My Drive/282/mujoco/mujoco-py/mujoco_py/generated/_pyxbld_2.0.2.13_37_linuxcpuextensionbuilder/temp.linux-x86_64-3.7/content/gdrive/My Drive/282/mujoco/mujoco-py/mujoco_py\n","creating /content/gdrive/My Drive/282/mujoco/mujoco-py/mujoco_py/generated/_pyxbld_2.0.2.13_37_linuxcpuextensionbuilder/temp.linux-x86_64-3.7/content/gdrive/My Drive/282/mujoco/mujoco-py/mujoco_py/gl\n","x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-a56wZI/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-a56wZI/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -Imujoco_py -I/content/gdrive/My Drive/282/mujoco/mujoco-py/mujoco_py -I/content/282/mujoco/mujoco200/include -I/usr/local/lib/python3.7/dist-packages/numpy/core/include -I/usr/include/python3.7m -c /content/gdrive/My Drive/282/mujoco/mujoco-py/mujoco_py/cymj.c -o /content/gdrive/My Drive/282/mujoco/mujoco-py/mujoco_py/generated/_pyxbld_2.0.2.13_37_linuxcpuextensionbuilder/temp.linux-x86_64-3.7/content/gdrive/My Drive/282/mujoco/mujoco-py/mujoco_py/cymj.o -fopenmp -w\n","x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-a56wZI/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-a56wZI/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -Imujoco_py -I/content/gdrive/My Drive/282/mujoco/mujoco-py/mujoco_py -I/content/282/mujoco/mujoco200/include -I/usr/local/lib/python3.7/dist-packages/numpy/core/include -I/usr/include/python3.7m -c /content/gdrive/My Drive/282/mujoco/mujoco-py/mujoco_py/gl/osmesashim.c -o /content/gdrive/My Drive/282/mujoco/mujoco-py/mujoco_py/generated/_pyxbld_2.0.2.13_37_linuxcpuextensionbuilder/temp.linux-x86_64-3.7/content/gdrive/My Drive/282/mujoco/mujoco-py/mujoco_py/gl/osmesashim.o -fopenmp -w\n","creating /content/gdrive/My Drive/282/mujoco/mujoco-py/mujoco_py/generated/_pyxbld_2.0.2.13_37_linuxcpuextensionbuilder/lib.linux-x86_64-3.7\n","creating /content/gdrive/My Drive/282/mujoco/mujoco-py/mujoco_py/generated/_pyxbld_2.0.2.13_37_linuxcpuextensionbuilder/lib.linux-x86_64-3.7/mujoco_py\n","x86_64-linux-gnu-gcc -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fdebug-prefix-map=/build/python3.7-a56wZI/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 /content/gdrive/My Drive/282/mujoco/mujoco-py/mujoco_py/generated/_pyxbld_2.0.2.13_37_linuxcpuextensionbuilder/temp.linux-x86_64-3.7/content/gdrive/My Drive/282/mujoco/mujoco-py/mujoco_py/cymj.o /content/gdrive/My Drive/282/mujoco/mujoco-py/mujoco_py/generated/_pyxbld_2.0.2.13_37_linuxcpuextensionbuilder/temp.linux-x86_64-3.7/content/gdrive/My Drive/282/mujoco/mujoco-py/mujoco_py/gl/osmesashim.o -L/content/282/mujoco/mujoco200/bin -Wl,--enable-new-dtags,-R/content/282/mujoco/mujoco200/bin -lmujoco200 -lglewosmesa -lOSMesa -lGL -o /content/gdrive/My Drive/282/mujoco/mujoco-py/mujoco_py/generated/_pyxbld_2.0.2.13_37_linuxcpuextensionbuilder/lib.linux-x86_64-3.7/mujoco_py/cymj.cpython-37m-x86_64-linux-gnu.so -fopenmp\n","/content/gdrive/My Drive/282\n","/content/gdrive/My Drive/282/assignment4\n","Collecting gym[atari]==0.17.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b3/99/7cc3e510678119cdac91f33fb9235b98448f09a6bdf0cafea2b108d9ce51/gym-0.17.2.tar.gz (1.6MB)\n","\u001b[K     |████████████████████████████████| 1.6MB 4.5MB/s \n","\u001b[?25hRequirement already satisfied: mujoco-py==2.0.2.13 in /content/gdrive/My Drive/282/mujoco/mujoco-py (from -r requirements.txt (line 2)) (2.0.2.13)\n","Collecting tensorboard==2.3.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e9/1b/6a420d7e6ba431cf3d51b2a5bfa06a958c4141e3189385963dc7f6fbffb6/tensorboard-2.3.0-py3-none-any.whl (6.8MB)\n","\u001b[K     |████████████████████████████████| 6.8MB 16.3MB/s \n","\u001b[?25hCollecting tensorboardX==1.8\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c3/12/dcaf67e1312475b26db9e45e7bb6f32b540671a9ee120b3a72d9e09bc517/tensorboardX-1.8-py2.py3-none-any.whl (216kB)\n","\u001b[K     |████████████████████████████████| 225kB 25.4MB/s \n","\u001b[?25hCollecting matplotlib==2.2.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/da/1d/e6d9af0b5045597869537391f1036ab841c613c3f3e40f16bbc1d75450ee/matplotlib-2.2.2-cp37-cp37m-manylinux1_x86_64.whl (12.6MB)\n","\u001b[K     |████████████████████████████████| 12.6MB 19.3MB/s \n","\u001b[?25hCollecting ipython==6.4.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b1/7f/91d50f28af3e3a24342561983a7857e399ce24093876e6970b986a0b6677/ipython-6.4.0-py3-none-any.whl (750kB)\n","\u001b[K     |████████████████████████████████| 757kB 42.6MB/s \n","\u001b[?25hCollecting moviepy==1.0.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fb/32/a93f4af8b88985304a748ca0a66a64eb9fac53d0a9355ec33e713c4a3bf5/moviepy-1.0.0.tar.gz (398kB)\n","\u001b[K     |████████████████████████████████| 399kB 16.4MB/s \n","\u001b[?25hCollecting pyvirtualdisplay==1.3.2\n","  Downloading https://files.pythonhosted.org/packages/d0/8a/643043cc70791367bee2d19eb20e00ed1a246ac48e5dbe57bbbcc8be40a9/PyVirtualDisplay-1.3.2-py2.py3-none-any.whl\n","Requirement already satisfied: torch==1.8.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 9)) (1.8.0+cu101)\n","Collecting opencv-python==4.4.0.42\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fa/e3/7ed67a8f3116113a364671fb4142c446dd804c63f3d9df5c11168a1e4dbb/opencv_python-4.4.0.42-cp37-cp37m-manylinux2014_x86_64.whl (49.4MB)\n","\u001b[K     |████████████████████████████████| 49.4MB 165kB/s \n","\u001b[?25hCollecting ipdb==0.13.3\n","  Downloading https://files.pythonhosted.org/packages/c1/4c/c2552dc5c2f3a4657ae84c1a91e3c7d4f2b7df88a38d6d282e48d050ad58/ipdb-0.13.3.tar.gz\n","Collecting box2d-py\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/34/da5393985c3ff9a76351df6127c275dcb5749ae0abbe8d5210f06d97405d/box2d_py-2.3.8-cp37-cp37m-manylinux1_x86_64.whl (448kB)\n","\u001b[K     |████████████████████████████████| 450kB 21.5MB/s \n","\u001b[?25hCollecting numpy==1.20.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/6c/322f6aa128179d0ea45a543a4e29a74da2317117109899cfd56d09bf3de0/numpy-1.20.0-cp37-cp37m-manylinux2010_x86_64.whl (15.3MB)\n","\u001b[K     |████████████████████████████████| 15.3MB 31.4MB/s \n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym[atari]==0.17.2-\u003e-r requirements.txt (line 1)) (1.4.1)\n","Requirement already satisfied: pyglet\u003c=1.5.0,\u003e=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym[atari]==0.17.2-\u003e-r requirements.txt (line 1)) (1.5.0)\n","Requirement already satisfied: cloudpickle\u003c1.4.0,\u003e=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[atari]==0.17.2-\u003e-r requirements.txt (line 1)) (1.3.0)\n","Requirement already satisfied: atari_py~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[atari]==0.17.2-\u003e-r requirements.txt (line 1)) (0.2.6)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from gym[atari]==0.17.2-\u003e-r requirements.txt (line 1)) (7.0.0)\n","Requirement already satisfied: glfw\u003e=1.4.0 in /usr/local/lib/python3.7/dist-packages (from mujoco-py==2.0.2.13-\u003e-r requirements.txt (line 2)) (2.1.0)\n","Requirement already satisfied: Cython\u003e=0.27.2 in /usr/local/lib/python3.7/dist-packages (from mujoco-py==2.0.2.13-\u003e-r requirements.txt (line 2)) (0.29.22)\n","Requirement already satisfied: imageio\u003e=2.1.2 in /usr/local/lib/python3.7/dist-packages (from mujoco-py==2.0.2.13-\u003e-r requirements.txt (line 2)) (2.4.1)\n","Requirement already satisfied: cffi\u003e=1.10 in /usr/local/lib/python3.7/dist-packages (from mujoco-py==2.0.2.13-\u003e-r requirements.txt (line 2)) (1.14.5)\n","Requirement already satisfied: fasteners~=0.15 in /usr/local/lib/python3.7/dist-packages (from mujoco-py==2.0.2.13-\u003e-r requirements.txt (line 2)) (0.16)\n","Requirement already satisfied: werkzeug\u003e=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.3.0-\u003e-r requirements.txt (line 3)) (1.0.1)\n","Requirement already satisfied: requests\u003c3,\u003e=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.3.0-\u003e-r requirements.txt (line 3)) (2.23.0)\n","Requirement already satisfied: six\u003e=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.3.0-\u003e-r requirements.txt (line 3)) (1.15.0)\n","Requirement already satisfied: tensorboard-plugin-wit\u003e=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.3.0-\u003e-r requirements.txt (line 3)) (1.8.0)\n","Requirement already satisfied: google-auth\u003c2,\u003e=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.3.0-\u003e-r requirements.txt (line 3)) (1.27.1)\n","Requirement already satisfied: absl-py\u003e=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.3.0-\u003e-r requirements.txt (line 3)) (0.10.0)\n","Requirement already satisfied: google-auth-oauthlib\u003c0.5,\u003e=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.3.0-\u003e-r requirements.txt (line 3)) (0.4.3)\n","Requirement already satisfied: grpcio\u003e=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.3.0-\u003e-r requirements.txt (line 3)) (1.32.0)\n","Requirement already satisfied: setuptools\u003e=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.3.0-\u003e-r requirements.txt (line 3)) (54.1.2)\n","Requirement already satisfied: markdown\u003e=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.3.0-\u003e-r requirements.txt (line 3)) (3.3.4)\n","Requirement already satisfied: protobuf\u003e=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.3.0-\u003e-r requirements.txt (line 3)) (3.12.4)\n","Requirement already satisfied: wheel\u003e=0.26; python_version \u003e= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.3.0-\u003e-r requirements.txt (line 3)) (0.36.2)\n","Requirement already satisfied: cycler\u003e=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib==2.2.2-\u003e-r requirements.txt (line 5)) (0.10.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,\u003e=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==2.2.2-\u003e-r requirements.txt (line 5)) (2.4.7)\n","Requirement already satisfied: python-dateutil\u003e=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==2.2.2-\u003e-r requirements.txt (line 5)) (2.8.1)\n","Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from matplotlib==2.2.2-\u003e-r requirements.txt (line 5)) (2018.9)\n","Requirement already satisfied: kiwisolver\u003e=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==2.2.2-\u003e-r requirements.txt (line 5)) (1.3.1)\n","Requirement already satisfied: jedi\u003e=0.10 in /usr/local/lib/python3.7/dist-packages (from ipython==6.4.0-\u003e-r requirements.txt (line 6)) (0.18.0)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython==6.4.0-\u003e-r requirements.txt (line 6)) (0.2.0)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython==6.4.0-\u003e-r requirements.txt (line 6)) (2.6.1)\n","Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.7/dist-packages (from ipython==6.4.0-\u003e-r requirements.txt (line 6)) (4.8.0)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython==6.4.0-\u003e-r requirements.txt (line 6)) (0.7.5)\n","Requirement already satisfied: prompt-toolkit\u003c2.0.0,\u003e=1.0.15 in /usr/local/lib/python3.7/dist-packages (from ipython==6.4.0-\u003e-r requirements.txt (line 6)) (1.0.18)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython==6.4.0-\u003e-r requirements.txt (line 6)) (4.4.2)\n","Requirement already satisfied: traitlets\u003e=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython==6.4.0-\u003e-r requirements.txt (line 6)) (5.0.5)\n","Requirement already satisfied: simplegeneric\u003e0.8 in /usr/local/lib/python3.7/dist-packages (from ipython==6.4.0-\u003e-r requirements.txt (line 6)) (0.8.1)\n","Requirement already satisfied: tqdm\u003c5.0,\u003e=4.11.2 in /usr/local/lib/python3.7/dist-packages (from moviepy==1.0.0-\u003e-r requirements.txt (line 7)) (4.41.1)\n","Collecting proglog\u003c=1.0.0\n","  Downloading https://files.pythonhosted.org/packages/fe/ab/4cb19b578e1364c0b2d6efd6521a8b4b4e5c4ae6528041d31a2a951dd991/proglog-0.1.9.tar.gz\n","Collecting imageio_ffmpeg\u003e=0.2.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/89/0f/4b49476d185a273163fa648eaf1e7d4190661d1bbf37ec2975b84df9de02/imageio_ffmpeg-0.4.3-py3-none-manylinux2010_x86_64.whl (26.9MB)\n","\u001b[K     |████████████████████████████████| 26.9MB 169kB/s \n","\u001b[?25hCollecting EasyProcess\n","  Downloading https://files.pythonhosted.org/packages/48/3c/75573613641c90c6d094059ac28adb748560d99bd27ee6f80cce398f404e/EasyProcess-0.3-py2.py3-none-any.whl\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0-\u003e-r requirements.txt (line 9)) (3.7.4.3)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet\u003c=1.5.0,\u003e=1.4.0-\u003egym[atari]==0.17.2-\u003e-r requirements.txt (line 1)) (0.16.0)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi\u003e=1.10-\u003emujoco-py==2.0.2.13-\u003e-r requirements.txt (line 2)) (2.20)\n","Requirement already satisfied: idna\u003c3,\u003e=2.5 in /usr/local/lib/python3.7/dist-packages (from requests\u003c3,\u003e=2.21.0-\u003etensorboard==2.3.0-\u003e-r requirements.txt (line 3)) (2.10)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests\u003c3,\u003e=2.21.0-\u003etensorboard==2.3.0-\u003e-r requirements.txt (line 3)) (2020.12.5)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,\u003c1.26,\u003e=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests\u003c3,\u003e=2.21.0-\u003etensorboard==2.3.0-\u003e-r requirements.txt (line 3)) (1.24.3)\n","Requirement already satisfied: chardet\u003c4,\u003e=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests\u003c3,\u003e=2.21.0-\u003etensorboard==2.3.0-\u003e-r requirements.txt (line 3)) (3.0.4)\n","Requirement already satisfied: cachetools\u003c5.0,\u003e=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth\u003c2,\u003e=1.6.3-\u003etensorboard==2.3.0-\u003e-r requirements.txt (line 3)) (4.2.1)\n","Requirement already satisfied: pyasn1-modules\u003e=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth\u003c2,\u003e=1.6.3-\u003etensorboard==2.3.0-\u003e-r requirements.txt (line 3)) (0.2.8)\n","Requirement already satisfied: rsa\u003c5,\u003e=3.1.4; python_version \u003e= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth\u003c2,\u003e=1.6.3-\u003etensorboard==2.3.0-\u003e-r requirements.txt (line 3)) (4.7.2)\n","Requirement already satisfied: requests-oauthlib\u003e=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib\u003c0.5,\u003e=0.4.1-\u003etensorboard==2.3.0-\u003e-r requirements.txt (line 3)) (1.3.0)\n","Requirement already satisfied: importlib-metadata; python_version \u003c \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown\u003e=2.6.8-\u003etensorboard==2.3.0-\u003e-r requirements.txt (line 3)) (3.7.2)\n","Requirement already satisfied: parso\u003c0.9.0,\u003e=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi\u003e=0.10-\u003eipython==6.4.0-\u003e-r requirements.txt (line 6)) (0.8.1)\n","Requirement already satisfied: ptyprocess\u003e=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect; sys_platform != \"win32\"-\u003eipython==6.4.0-\u003e-r requirements.txt (line 6)) (0.7.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit\u003c2.0.0,\u003e=1.0.15-\u003eipython==6.4.0-\u003e-r requirements.txt (line 6)) (0.2.5)\n","Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from traitlets\u003e=4.2-\u003eipython==6.4.0-\u003e-r requirements.txt (line 6)) (0.2.0)\n","Requirement already satisfied: pyasn1\u003c0.5.0,\u003e=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules\u003e=0.2.1-\u003egoogle-auth\u003c2,\u003e=1.6.3-\u003etensorboard==2.3.0-\u003e-r requirements.txt (line 3)) (0.4.8)\n","Requirement already satisfied: oauthlib\u003e=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib\u003e=0.7.0-\u003egoogle-auth-oauthlib\u003c0.5,\u003e=0.4.1-\u003etensorboard==2.3.0-\u003e-r requirements.txt (line 3)) (3.1.0)\n","Requirement already satisfied: zipp\u003e=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version \u003c \"3.8\"-\u003emarkdown\u003e=2.6.8-\u003etensorboard==2.3.0-\u003e-r requirements.txt (line 3)) (3.4.1)\n","Building wheels for collected packages: gym, moviepy, ipdb, proglog\n","  Building wheel for gym (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gym: filename=gym-0.17.2-cp37-none-any.whl size=1650891 sha256=ae4b67ef36dd067a19a946a200449760da5181c3af6de338e4a95910553cf6ba\n","  Stored in directory: /root/.cache/pip/wheels/87/e0/91/f56e44e8062f8cd549673da49f59e1d4fe8b17398119b1d221\n","  Building wheel for moviepy (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for moviepy: filename=moviepy-1.0.0-cp37-none-any.whl size=131366 sha256=10f61a576f2f3cbe7441ff1d2c0481e3defa3741c64ed4f0671bb9172082473e\n","  Stored in directory: /root/.cache/pip/wheels/52/e2/4c/f594a5945bc98e052ef248b46a0f1f7ea838b0b2a5f8895651\n","  Building wheel for ipdb (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ipdb: filename=ipdb-0.13.3-cp37-none-any.whl size=10848 sha256=f8bb6001cace4764b65aaae51ed89e6ce525782bf446fd4de6f58aef0485f3f0\n","  Stored in directory: /root/.cache/pip/wheels/75/00/30/4169bcc3643f0cf946dcf37af1b71364b390c4df91da02b03c\n","  Building wheel for proglog (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for proglog: filename=proglog-0.1.9-cp37-none-any.whl size=6148 sha256=2db2106aeea920b32058fae166a1c12169c864e49c84d6c81ac6328a0f419972\n","  Stored in directory: /root/.cache/pip/wheels/65/56/60/1d0306a8d90b188af393c1812ddb502a8821b70917f82dcc00\n","Successfully built gym moviepy ipdb proglog\n","\u001b[31mERROR: tensorflow 2.4.1 has requirement numpy~=1.19.2, but you'll have numpy 1.20.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: tensorflow 2.4.1 has requirement tensorboard~=2.4, but you'll have tensorboard 2.3.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: plotnine 0.6.0 has requirement matplotlib\u003e=3.1.1, but you'll have matplotlib 2.2.2 which is incompatible.\u001b[0m\n","\u001b[31mERROR: moviepy 1.0.0 has requirement imageio\u003c3.0,\u003e=2.5; python_version \u003e= \"3.4\", but you'll have imageio 2.4.1 which is incompatible.\u001b[0m\n","\u001b[31mERROR: mizani 0.6.0 has requirement matplotlib\u003e=3.1.1, but you'll have matplotlib 2.2.2 which is incompatible.\u001b[0m\n","\u001b[31mERROR: google-colab 1.0.0 has requirement ipython~=5.5.0, but you'll have ipython 6.4.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n","\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug\u003c0.2.7,\u003e=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Installing collected packages: numpy, opencv-python, gym, tensorboard, tensorboardX, matplotlib, ipython, proglog, imageio-ffmpeg, moviepy, EasyProcess, pyvirtualdisplay, ipdb, box2d-py\n","  Found existing installation: numpy 1.19.5\n","    Uninstalling numpy-1.19.5:\n","      Successfully uninstalled numpy-1.19.5\n","  Found existing installation: opencv-python 4.1.2.30\n","    Uninstalling opencv-python-4.1.2.30:\n","      Successfully uninstalled opencv-python-4.1.2.30\n","  Found existing installation: gym 0.17.3\n","    Uninstalling gym-0.17.3:\n","      Successfully uninstalled gym-0.17.3\n","  Found existing installation: tensorboard 2.4.1\n","    Uninstalling tensorboard-2.4.1:\n","      Successfully uninstalled tensorboard-2.4.1\n","  Found existing installation: matplotlib 3.2.2\n","    Uninstalling matplotlib-3.2.2:\n","      Successfully uninstalled matplotlib-3.2.2\n","  Found existing installation: ipython 5.5.0\n","    Uninstalling ipython-5.5.0:\n","      Successfully uninstalled ipython-5.5.0\n","  Found existing installation: moviepy 0.2.3.5\n","    Uninstalling moviepy-0.2.3.5:\n","      Successfully uninstalled moviepy-0.2.3.5\n","Successfully installed EasyProcess-0.3 box2d-py-2.3.8 gym-0.17.2 imageio-ffmpeg-0.4.3 ipdb-0.13.3 ipython-6.4.0 matplotlib-2.2.2 moviepy-1.0.0 numpy-1.20.0 opencv-python-4.4.0.42 proglog-0.1.9 pyvirtualdisplay-1.3.2 tensorboard-2.3.0 tensorboardX-1.8\n"]},{"data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["IPython","matplotlib","mpl_toolkits","numpy"]}}},"metadata":{"tags":[]},"output_type":"display_data"}],"source":["DRIVE_PATH = '/content/gdrive/My\\ Drive/282'\n","DRIVE_PYTHON_PATH = DRIVE_PATH.replace('\\\\', '')\n","if not os.path.exists(DRIVE_PYTHON_PATH):\n","  %mkdir $DRIVE_PATH\n","\n","## the space in `My Drive` causes some issues,\n","## make a symlink to avoid this\n","SYM_PATH = '/content/282'\n","if not os.path.exists(SYM_PATH):\n","  !ln -s $DRIVE_PATH $SYM_PATH\n","!apt update \n","!apt install -y --no-install-recommends \\\n","        build-essential \\\n","        curl \\\n","        git \\\n","        gnupg2 \\\n","        make \\\n","        cmake \\\n","        ffmpeg \\\n","        swig \\\n","        libz-dev \\\n","        unzip \\\n","        zlib1g-dev \\\n","        libglfw3 \\\n","        libglfw3-dev \\\n","        libxrandr2 \\\n","        libxinerama-dev \\\n","        libxi6 \\\n","        libxcursor-dev \\\n","        libgl1-mesa-dev \\\n","        libgl1-mesa-glx \\\n","        libglew-dev \\\n","        libosmesa6-dev \\\n","        lsb-release \\\n","        ack-grep \\\n","        patchelf \\\n","        wget \\\n","        xpra \\\n","        xserver-xorg-dev \\\n","        xvfb \\\n","        python-opengl \\\n","        ffmpeg \u003e /dev/null 2\u003e\u00261\n","MJC_PATH = '{}/mujoco'.format(SYM_PATH)\n","if not os.path.exists(MJC_PATH):\n","  %mkdir $MJC_PATH\n","%cd $MJC_PATH\n","if not os.path.exists(os.path.join(MJC_PATH, 'mujoco200')):\n","  !wget -q https://www.roboti.us/download/mujoco200_linux.zip\n","  !unzip -q mujoco200_linux.zip\n","  %mv mujoco200_linux mujoco200\n","  %rm mujoco200_linux.zip\n","import os\n","\n","os.environ['LD_LIBRARY_PATH'] += ':{}/mujoco200/bin'.format(MJC_PATH)\n","os.environ['MUJOCO_PY_MUJOCO_PATH'] = '{}/mujoco200'.format(MJC_PATH)\n","os.environ['MUJOCO_PY_MJKEY_PATH'] = '{}/mjkey.txt'.format(MJC_PATH)\n","\n","## installation on colab does not find *.so files\n","## in LD_LIBRARY_PATH, copy over manually instead\n","!cp $MJC_PATH/mujoco200/bin/*.so /usr/lib/x86_64-linux-gnu/\n","%cd $MJC_PATH\n","if not os.path.exists('mujoco-py'):\n","  !git clone https://github.com/openai/mujoco-py.git\n","%cd mujoco-py\n","%pip install -e .\n","\n","## cythonize at the first import\n","import mujoco_py\n","%cd $SYM_PATH\n","\n","%cd assignment4\n","%pip install -r requirements.txt"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":44540,"status":"ok","timestamp":1616560447662,"user":{"displayName":"Anthony Ng","photoUrl":"","userId":"16843483630260605487"},"user_tz":-480},"id":"VNF_WtPpewfO"},"outputs":[],"source":["#@title imports\n","# As usual, a bit of setup\n","import os\n","import shutil\n","import time\n","import numpy as np\n","import torch\n","\n","import deeprl.infrastructure.pytorch_util as ptu\n","\n","from deeprl.infrastructure.rl_trainer import RL_Trainer\n","from deeprl.infrastructure.trainers import BC_Trainer\n","from deeprl.agents.bc_agent import BCAgent\n","from deeprl.policies.loaded_gaussian_policy import LoadedGaussianPolicy\n","from deeprl.policies.MLP_policy import MLPPolicySL\n","\n","%load_ext autoreload\n","%autoreload 2\n","\n","def rel_error(x, y):\n","    \"\"\" returns relative error \"\"\"\n","    return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))\n","\n","def remove_folder(path):\n","    # check if folder exists\n","    if os.path.exists(path): \n","        print(\"Clearing old results at {}\".format(path))\n","        # remove if exists\n","        shutil.rmtree(path)\n","    else:\n","        print(\"Folder {} does not exist yet. No old results to delete\".format(path))"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"background_save":true},"executionInfo":{"elapsed":2455,"status":"ok","timestamp":1616561611120,"user":{"displayName":"Anthony Ng","photoUrl":"","userId":"16843483630260605487"},"user_tz":-480},"id":"Qe4TFfLLewfP"},"outputs":[],"source":["bc_base_args_dict = dict(\n","    expert_policy_file = 'deeprl/policies/experts/Hopper.pkl', #@param\n","    expert_data = 'deeprl/expert_data/expert_data_Hopper-v2.pkl', #@param\n","    env_name = 'Hopper-v2', #@param ['Ant-v2', 'Humanoid-v2', 'Walker2d-v2', 'HalfCheetah-v2', 'Hopper-v2']\n","    exp_name = 'test_bc', #@param\n","    do_dagger = True, #@param {type: \"boolean\"}\n","    ep_len = 1000, #@param {type: \"integer\"}\n","    save_params = False, #@param {type: \"boolean\"}\n","\n","    # Training\n","    num_agent_train_steps_per_iter = 1000, #@param {type: \"integer\"})\n","    n_iter = 1, #@param {type: \"integer\"})\n","\n","    # batches \u0026 buffers\n","    batch_size = 10000, #@param {type: \"integer\"})\n","    eval_batch_size = 1000, #@param {type: \"integer\"}\n","    train_batch_size = 100, #@param {type: \"integer\"}\n","    max_replay_buffer_size = 1000000, #@param {type: \"integer\"}\n","\n","    #@markdown network\n","    n_layers = 2, #@param {type: \"integer\"}\n","    size = 64, #@param {type: \"integer\"}\n","    learning_rate = 5e-3, #@param {type: \"number\"}\n","\n","    #@markdown logging\n","    video_log_freq = -1, #@param {type: \"integer\"}\n","    scalar_log_freq = 1, #@param {type: \"integer\"}\n","\n","    #@markdown gpu \u0026 run-time settings\n","    no_gpu = False, #@param {type: \"boolean\"}\n","    which_gpu = 0, #@param {type: \"integer\"}\n","    seed = 2, #@param {type: \"integer\"}\n","    logdir = 'test',\n",")\n"]},{"cell_type":"markdown","metadata":{"id":"JvhGQLgCewfP"},"source":["# Infrastructure\n","**Policies**: We have provided implementations of simple neural network policies for your convenience. For discrete environments, the neural network takes in the current state and outputs the logits of the policy's action distribution at this state. The policy then outputs a categorical distribution using those logits. In environments with continuous action spaces, the network will output the mean of a diagonal Gaussian distribution, as well as having a separate single parameter for the log standard deviations of the Gaussian. \n","\n","Calling forward on the policy will output a torch distribution object, so look at the documentation at https://pytorch.org/docs/stable/distributions.html.\n","Look at \u003ccode\u003epolicies/MLP_policy\u003c/code\u003e to make sure you understand the implementation.\n","\n","**RL Training Loop**: The reinforcement learning training loop, which alternates between gathering samples from the environment and updating the policy (and other learned functions) can be found in \u003ccode\u003einfrastructure/rl_trainer.py\u003c/code\u003e. While you won't need to understand this for the basic behavior cloning part (as you only use a fixed set of expert data), you should read through and understand the run_training_loop function before starting the Dagger implementation."]},{"cell_type":"markdown","metadata":{"id":"yznkKuLAewfQ"},"source":["# Basic Behavior Cloning\n","The first part of the assignment will be a familiar exercise in supervised learning. Given a dataset of expert trajectories, we will simply train our policy to imitate the expert via maximum likelihood. Fill out the update method in the MLPPolicySL class in \u003ccode\u003epolicies/MLP_policy.py\u003c/code\u003e."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"3NTYuc6XewfQ"},"outputs":[{"name":"stdout","output_type":"stream","text":["Weight before update [[-0.00432252  0.30971584 -0.47518533]\n"," [-0.4248946  -0.22236897  0.15482073]]\n","[[-1.4790758   0.69899046]\n"," [-1.1322743   0.54298437]\n"," [-0.2453982   0.36416277]\n"," [-1.3827623  -1.2013232 ]\n"," [-1.5841014  -0.08110598]]\n","tensor([[-0.2873,  1.0582],\n","        [-0.7216, -1.1946],\n","        [-0.8755, -0.9074],\n","        [-1.2642, -0.5128],\n","        [-1.8740, -0.9291]])\n"]},{"ename":"RuntimeError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-102-996e5740d40f\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 22\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Training Loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/gdrive/My Drive/282/assignment4/deeprl/policies/MLP_policy.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, observations, actions, adv_n, acs_labels_na, qvals)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 153\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--\u003e 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 147\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"]}],"source":["### Basic test for correctness of loss and gradients\n","torch.manual_seed(0)\n","ac_dim = 2\n","ob_dim = 3\n","batch_size = 5\n","\n","policy = MLPPolicySL(\n","            ac_dim=ac_dim,\n","            ob_dim=ob_dim,\n","            n_layers=1,\n","            size=2,\n","            learning_rate=0.25)\n","\n","np.random.seed(0)\n","obs = np.random.normal(size=(batch_size, ob_dim))\n","acts = np.random.normal(size=(batch_size, ac_dim))\n","\n","first_weight_before = np.array(ptu.to_numpy(next(policy.mean_net.parameters())))\n","print(\"Weight before update\", first_weight_before)\n","\n","for i in range(5):\n","    loss = policy.update(obs, acts)['Training Loss']\n","\n","print(loss)\n","expected_loss = 2.628419\n","loss_error = rel_error(loss, expected_loss)\n","print(\"Loss Error\", loss_error, \"should be on the order of 1e-6 or lower\")\n","\n","first_weight_after = ptu.to_numpy(next(policy.mean_net.parameters()))\n","print('Weight after update', first_weight_after)\n","\n","weight_change = first_weight_after - first_weight_before\n","print(\"Change in weights\", weight_change)\n","\n","expected_change = np.array([[ 0.04385546, -0.4614172,  -1.0613215 ],\n","                            [ 0.20986436, -1.2060736,  -1.0026767 ]])\n","updated_weight_error = rel_error(weight_change, expected_change)\n","print(\"Weight Update Error\", updated_weight_error, \"should be on the order of 1e-6 or lower\")\n"]},{"cell_type":"markdown","metadata":{"id":"uswlI5FfewfR"},"source":["Having implemented our behavior cloning loss, we can now start training some policies to imitate the expert policies provided. \n","\n","Run the following cell to train policies with simple behavior cloning on the HalfCheetah environment."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QYfLMy00ewfR"},"outputs":[],"source":["bc_args = dict(bc_base_args_dict)\n","\n","env_str = 'HalfCheetah'\n","bc_args['expert_policy_file'] = 'deeprl/policies/experts/{}.pkl'.format(env_str)\n","bc_args['expert_data'] = 'deeprl/expert_data/expert_data_{}-v2.pkl'.format(env_str)\n","bc_args['env_name'] = '{}-v2'.format(env_str)\n","\n","# Delete all previous logs\n","remove_folder('logs/behavior_cloning/{}'.format(env_str))\n","\n","for seed in range(3):\n","    print(\"Running behavior cloning experiment with seed\", seed)\n","    bc_args['seed'] = seed\n","    bc_args['logdir'] = 'logs/behavior_cloning/{}/seed{}'.format(env_str, seed)\n","    bctrainer = BC_Trainer(bc_args)\n","    bctrainer.run_training_loop()"]},{"cell_type":"markdown","metadata":{"id":"kUmCsIcuewfS"},"source":["Visualize your results using Tensorboard. You should see that on HalfCheetah, the returns of your learned policies (Eval_AverageReturn) are fairly similar (thought a bit lower) to that of the expert (Initial_DataCollection_Average_Return)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2AfmkLIAewfS"},"outputs":[],"source":["### Visualize behavior cloning results on HalfCheetah\n","%load_ext tensorboard\n","%tensorboard --logdir logs/behavior_cloning/HalfCheetah"]},{"cell_type":"markdown","metadata":{"id":"q3RwRRFdewfT"},"source":["Now run the following cell to train policies with simple behavior cloning on Hopper."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C0Plou4zewfT"},"outputs":[],"source":["bc_args = dict(bc_base_args_dict)\n","\n","env_str = 'Hopper'\n","bc_args['expert_policy_file'] = 'deeprl/policies/experts/{}.pkl'.format(env_str)\n","bc_args['expert_data'] = 'deeprl/expert_data/expert_data_{}-v2.pkl'.format(env_str)\n","bc_args['env_name'] = '{}-v2'.format(env_str)\n","\n","# Delete all previous logs\n","remove_folder('logs/behavior_cloning/{}'.format(env_str))\n","\n","for seed in range(3):\n","    print(\"Running behavior cloning experiment on Hopper with seed\", seed)\n","    bc_args['seed'] = seed\n","    bc_args['logdir'] = 'logs/behavior_cloning/{}/seed{}'.format(env_str, seed)\n","    bctrainer = BC_Trainer(bc_args)\n","    bctrainer.run_training_loop()"]},{"cell_type":"markdown","metadata":{"id":"52OyJBYiewfT"},"source":["Visualize your results using Tensorboard. You should see that on Hopper, the returns of your learned policies (Eval_AverageReturn) are substantially lower than that of the expert (Initial_DataCollection_Average_Return), due to the distribution shift issues that arise when doing naive behavior cloning."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H_4ezQ29ewfU"},"outputs":[],"source":["### Visualize behavior cloning results on Hopper\n","%load_ext tensorboard\n","%tensorboard --logdir logs/behavior_cloning/Hopper"]},{"cell_type":"markdown","metadata":{"id":"BSiUeo58ewfU"},"source":["# Dataset Aggregation\n","As discussed in lecture, behavior cloning can suffer from distribution shift, as a small mismatch between the learned and expert policy can take the learned policy to new states that were unseen during training, on which the learned policy hasn't been trained. In Dagger, we will address this issue iteratively, where we use our expert policy to provide labels for the new states we encounter with our learned policy, and then retrain our policy on these newly labeled states.\n","\n","Implement the \u003ccode\u003edo_relabel_with_expert\u003c/code\u003e function in \u003ccode\u003einfrastructure/rl_trainer.py\u003c/code\u003e. The errors in the expert actions should be on the order of 1e-6 or less."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E365v2jhewfU"},"outputs":[],"source":["### Test do relabel function\n","bc_args = dict(bc_base_args_dict)\n","\n","env_str = 'Hopper'\n","bc_args['expert_policy_file'] = 'deeprl/policies/experts/{}.pkl'.format(env_str)\n","bc_args['expert_data'] = 'deeprl/expert_data/expert_data_{}-v2.pkl'.format(env_str)\n","bc_args['env_name'] = '{}-v2'.format(env_str)\n","bctrainer = BC_Trainer(bc_args)\n","\n","np.random.seed(0)\n","T = 2\n","ob_dim = 11\n","ac_dim = 3\n","\n","paths = []\n","for i in range(3):\n","    obs = np.random.normal(size=(T, ob_dim))\n","    acs = np.random.normal(size=(T, ac_dim))\n","    paths.append(dict(observation=obs,\n","                      action=acs))\n","    \n","rl_trainer = bctrainer.rl_trainer\n","relabeled_paths = rl_trainer.do_relabel_with_expert(bctrainer.loaded_expert_policy, paths)\n","\n","expert_actions = np.array([[[-1.7814021, -0.11137983,  1.763353  ],\n","                            [-2.589222,   -5.463195,    2.4301376 ]],\n","                           [[-2.8287444, -5.298558,   3.0320463],\n","                            [ 3.9611065,  2.626403,  -2.8639293]],\n","                           [[-0.3055225,  -0.9865407,   0.80830705],\n","                            [ 2.8788857,   3.5550566,  -0.92875874]]])\n","\n","for i, (path, relabeled_path) in enumerate(zip(paths, relabeled_paths)):\n","    assert np.all(path['observation'] == relabeled_path['observation'])\n","    print(\"Path {} expert action error\".format(i), rel_error(expert_actions[i], relabeled_path['action']))"]},{"cell_type":"markdown","metadata":{"id":"QZol9Gr_ewfV"},"source":["We can run Dagger on the Hopper env again."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ukDO9X51ewfV"},"outputs":[],"source":["dagger_args = dict(bc_base_args_dict)\n","\n","dagger_args['do_dagger'] = True\n","dagger_args['n_iter'] = 10\n","\n","env_str = 'Hopper'\n","dagger_args['expert_policy_file'] = 'deeprl/policies/experts/{}.pkl'.format(env_str)\n","dagger_args['expert_data'] = 'deeprl/expert_data/expert_data_{}-v2.pkl'.format(env_str)\n","dagger_args['env_name'] = '{}-v2'.format(env_str)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J96PfZuBewfW"},"outputs":[],"source":["# Delete all previous logs\n","remove_folder('logs/dagger/{}'.format(env_str))\n","\n","for seed in range(3):\n","    print(\"Running Dagger experiment with seed\", seed)\n","    dagger_args['seed'] = seed\n","    dagger_args['logdir'] = 'logs/dagger/{}/seed{}'.format(env_str, seed)\n","    bctrainer = BC_Trainer(dagger_args)\n","    bctrainer.run_training_loop()"]},{"cell_type":"markdown","metadata":{"id":"2fewZLNpewfW"},"source":["Visualizing the Dagger results on Hopper, we see that Dagger is able to recover the performance of the expert policy after a few iterations of online interaction and expert relabeling."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bNKUKmkXewfW"},"outputs":[],"source":["### Visualize Dagger results on Hopper\n","%load_ext tensorboard\n","%tensorboard --logdir logs/dagger/Hopper"]}],"metadata":{"colab":{"name":"Imitation Learning.ipynb","toc_visible":true,"version":""},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"}},"nbformat":4,"nbformat_minor":0}