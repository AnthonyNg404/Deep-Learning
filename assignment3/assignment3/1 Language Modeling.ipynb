{"cells":[{"cell_type":"markdown","metadata":{"id":"yIqzcT6vyUJI"},"source":["# Introduction"]},{"cell_type":"markdown","metadata":{"id":"eQrUWcSeyUJm"},"source":["\u003ccenter\u003e\u003ch3\u003e**Welcome to the Language modeling Notebook.**\u003c/h3\u003e\u003c/center\u003e\n","\n","In this assignment, you are going to train a neural network to **generate news headlines**.\n","To reduce computational needs, we have reduced it to headlines about technology, and a handful of Tech giants.\n","In this assignment you will:\n","- Learn to preprocess raw text so it can be fed into an LSTM.\n","- Make use of the LSTM library of Pytorch, to train a Language model to generate headlines\n","- Use your network to generate headlines, and judge which headlines are likely or not\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"lCAzgVCryUJr"},"source":["**What is a language model?**\n","\n","Language modeling is the task of assigning a probability to sentences in a language. Besides assigning a probability to each sequence of words, the language models also assigns a probability for the likelihood of a given word (or a sequence of words) to follow a sequence of words.\n","— Page 105, __[Neural Network Methods in Natural Language Processing](https://www.amazon.com/Language-Processing-Synthesis-Lectures-Technologies/dp/1627052984/)__, 2017.\n","\n","In terms of neural network, we are training a neural network to produce probabilities (classification) over a fixed vocabulary of words.\n","Concretely, we are training a neural network to produce:\n","$$ P ( w_{i+1} | w_1, w_2, w_3, ..., w_i), \\forall i \\in (1,n)$$\n","\n","** Why is language modeling important? **\n","\n","Language modeling is a core problem in NLP.\n","\n","Language models can either be used as a stand-alone to produce new text that matches the distribution of text the model is trained on, but can also be used at the front-end of a more sophisticated model to produce better results.\n","\n","Recently for example, the __[BERT](https://arxiv.org/abs/1810.04805)__ paper show-cased that pretraining a large neural network on a language modeling task can help improve state-of-the-art on many NLP tasks. \n","\n","How good can the generation of a Language model be?\n","\n","If you have not seen the post about GPT-2 by OpenAI, you should read some of the samples they generated from their language model __[here](https://blog.openai.com/better-language-models/#sample1)__.\n","Because of computational restrictions, we will not achieve as good text production, but the same algorithm is at the core. They just use more data and compute."]},{"cell_type":"markdown","metadata":{"id":"LL29FMhfyUJv"},"source":["# Library imports"]},{"cell_type":"markdown","metadata":{"id":"5OXaa4g1yUJx"},"source":["Before starting, make sure you have all these libraries."]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4798,"status":"ok","timestamp":1616321400381,"user":{"displayName":"Anthony Ng","photoUrl":"","userId":"16843483630260605487"},"user_tz":-480},"id":"g81IeWKxyYO-","outputId":"c9b9f39d-58f1-4c95-b736-64c74de69460"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting segtok\n","  Downloading https://files.pythonhosted.org/packages/41/08/582dab5f4b1d5ca23bc6927b4bb977c8ff7f3a87a3b98844ef833e2f5623/segtok-1.5.10.tar.gz\n","Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from segtok) (2019.12.20)\n","Building wheels for collected packages: segtok\n","  Building wheel for segtok (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for segtok: filename=segtok-1.5.10-cp37-none-any.whl size=25019 sha256=27d0c19149c38e025bad774e3b4e8adf3f078cfb663775d06ba5064b03e7a3a1\n","  Stored in directory: /root/.cache/pip/wheels/b4/39/f6/9ca1c5cabde964d728023b5751c3a206a5c8cc40252321fb6b\n","Successfully built segtok\n","Installing collected packages: segtok\n","Successfully installed segtok-1.5.10\n"]}],"source":["!pip install segtok"]},{"cell_type":"markdown","metadata":{"id":"vrZp_fiv_uXb"},"source":["Run the first of the following two cells if you are running the homework locally, and run the second cell if you are running the homework in Colab"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4xD0hDtw_uXb"},"outputs":[],"source":["DRIVE=False\n","root_folder = \"\"\n","dataset_folder = \"dataset/\""]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18085,"status":"ok","timestamp":1616321381614,"user":{"displayName":"Anthony Ng","photoUrl":"","userId":"16843483630260605487"},"user_tz":-480},"id":"se7xdZD7y-CL","outputId":"62746bcc-0c14-4416-efbd-514a88825218"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","root_folder = \"/content/drive/My Drive/assignment3/\"\n","dataset_folder = \"/content/drive/My Drive/assignment3/dataset/\""]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18077,"status":"ok","timestamp":1616321381614,"user":{"displayName":"Anthony Ng","photoUrl":"","userId":"16843483630260605487"},"user_tz":-480},"id":"3t0xxDcJ_1BI","outputId":"694a51c0-cdfc-4ea6-bf30-806994476d93"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/My Drive/assignment3\n"]}],"source":["cd '/content/drive/My Drive/assignment3/'"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15334,"status":"ok","timestamp":1616232115311,"user":{"displayName":"Anthony Ng","photoUrl":"","userId":"16843483630260605487"},"user_tz":-480},"id":"U7qgrYwMAJD6","outputId":"7462deac-1452-4510-821d-84cb126be8f5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading data... Please wait, this might take a while...\n","--2021-03-20 09:21:40--  https://bcourses.berkeley.edu/files/74751488/download?download_frd=1\n","Resolving bcourses.berkeley.edu (bcourses.berkeley.edu)... 54.87.43.232, 3.212.170.206, 3.227.43.190\n","Connecting to bcourses.berkeley.edu (bcourses.berkeley.edu)|54.87.43.232|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://a1072-74751488.cluster71.canvas-user-content.com/files/1072~74751488/download?download_frd=1 [following]\n","--2021-03-20 09:21:40--  https://a1072-74751488.cluster71.canvas-user-content.com/files/1072~74751488/download?download_frd=1\n","Resolving a1072-74751488.cluster71.canvas-user-content.com (a1072-74751488.cluster71.canvas-user-content.com)... 18.235.63.234, 50.17.223.148, 18.215.90.155\n","Connecting to a1072-74751488.cluster71.canvas-user-content.com (a1072-74751488.cluster71.canvas-user-content.com)|18.235.63.234|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://inst-fs-iad-prod.inscloudgate.net/files/e53ed798-32ca-4d33-a1f0-f1dab9c49d64/CS182_HW3_dataset.zip?download=1\u0026token=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzUxMiJ9.eyJpYXQiOjE2MTYxOTg1MTQsInVzZXJfaWQiOm51bGwsInJlc291cmNlIjoiL2ZpbGVzL2U1M2VkNzk4LTMyY2EtNGQzMy1hMWYwLWYxZGFiOWM0OWQ2NC9DUzE4Ml9IVzNfZGF0YXNldC56aXAiLCJqdGkiOiI1NDg3ZDI4MS0zNjI4LTRmOGYtYTk5MS1lY2VkMjI2ZjJjODMiLCJob3N0IjpudWxsLCJvcmlnaW5hbF91cmwiOiJodHRwczovL2ExMDcyLTc0NzUxNDg4LmNsdXN0ZXI3MS5jYW52YXMtdXNlci1jb250ZW50LmNvbS9maWxlcy8xMDcyfjc0NzUxNDg4L2Rvd25sb2FkP2Rvd25sb2FkX2ZyZD0xXHUwMDI2bm9fY2FjaGU9dHJ1ZVx1MDAyNnJlZGlyZWN0PXRydWUiLCJleHAiOjE2MTYyODQ5MTR9.t4QDa63Su3hA6gbwKX1RM4nWkFLU3m88YP_hq6mMhuH-JTM-7ftxeVBWQuDUjzv1SYTDqD9Uw3WOjZ168A17JA [following]\n","--2021-03-20 09:21:41--  https://inst-fs-iad-prod.inscloudgate.net/files/e53ed798-32ca-4d33-a1f0-f1dab9c49d64/CS182_HW3_dataset.zip?download=1\u0026token=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzUxMiJ9.eyJpYXQiOjE2MTYxOTg1MTQsInVzZXJfaWQiOm51bGwsInJlc291cmNlIjoiL2ZpbGVzL2U1M2VkNzk4LTMyY2EtNGQzMy1hMWYwLWYxZGFiOWM0OWQ2NC9DUzE4Ml9IVzNfZGF0YXNldC56aXAiLCJqdGkiOiI1NDg3ZDI4MS0zNjI4LTRmOGYtYTk5MS1lY2VkMjI2ZjJjODMiLCJob3N0IjpudWxsLCJvcmlnaW5hbF91cmwiOiJodHRwczovL2ExMDcyLTc0NzUxNDg4LmNsdXN0ZXI3MS5jYW52YXMtdXNlci1jb250ZW50LmNvbS9maWxlcy8xMDcyfjc0NzUxNDg4L2Rvd25sb2FkP2Rvd25sb2FkX2ZyZD0xXHUwMDI2bm9fY2FjaGU9dHJ1ZVx1MDAyNnJlZGlyZWN0PXRydWUiLCJleHAiOjE2MTYyODQ5MTR9.t4QDa63Su3hA6gbwKX1RM4nWkFLU3m88YP_hq6mMhuH-JTM-7ftxeVBWQuDUjzv1SYTDqD9Uw3WOjZ168A17JA\n","Resolving inst-fs-iad-prod.inscloudgate.net (inst-fs-iad-prod.inscloudgate.net)... 34.202.73.32, 34.237.16.124, 54.160.176.205, ...\n","Connecting to inst-fs-iad-prod.inscloudgate.net (inst-fs-iad-prod.inscloudgate.net)|34.202.73.32|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://cdn.inst-fs-iad-prod.inscloudgate.net/2fe3a69f-0bf2-4d03-a048-11eb74490958/CS182_HW3_dataset.zip?token=eyJhbGciOiJIUzUxMiIsInR5cCI6IkpXVCIsImtpZCI6ImNkbiJ9.eyJyZXNvdXJjZSI6Ii8yZmUzYTY5Zi0wYmYyLTRkMDMtYTA0OC0xMWViNzQ0OTA5NTgvQ1MxODJfSFczX2RhdGFzZXQuemlwIiwidGVuYW50IjoiY2FudmFzIiwidXNlcl9pZCI6bnVsbCwiaWF0IjoxNjE2MTk4NTE0LCJleHAiOjE2MTYyODQ5MTR9.jpDqf1lOt4dYG8MAhobKmI07IvPhluvwoNWh4sgeH1pAJRtSNRt--9RfdiyzZlpRb3o07x6XTYjtV4zL03NDlQ\u0026download=1\u0026content_type=application%2Fx-zip-compressed [following]\n","--2021-03-20 09:21:41--  https://cdn.inst-fs-iad-prod.inscloudgate.net/2fe3a69f-0bf2-4d03-a048-11eb74490958/CS182_HW3_dataset.zip?token=eyJhbGciOiJIUzUxMiIsInR5cCI6IkpXVCIsImtpZCI6ImNkbiJ9.eyJyZXNvdXJjZSI6Ii8yZmUzYTY5Zi0wYmYyLTRkMDMtYTA0OC0xMWViNzQ0OTA5NTgvQ1MxODJfSFczX2RhdGFzZXQuemlwIiwidGVuYW50IjoiY2FudmFzIiwidXNlcl9pZCI6bnVsbCwiaWF0IjoxNjE2MTk4NTE0LCJleHAiOjE2MTYyODQ5MTR9.jpDqf1lOt4dYG8MAhobKmI07IvPhluvwoNWh4sgeH1pAJRtSNRt--9RfdiyzZlpRb3o07x6XTYjtV4zL03NDlQ\u0026download=1\u0026content_type=application%2Fx-zip-compressed\n","Resolving cdn.inst-fs-iad-prod.inscloudgate.net (cdn.inst-fs-iad-prod.inscloudgate.net)... 54.192.87.104, 54.192.87.30, 54.192.87.42, ...\n","Connecting to cdn.inst-fs-iad-prod.inscloudgate.net (cdn.inst-fs-iad-prod.inscloudgate.net)|54.192.87.104|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 143712234 (137M) [application/x-zip-compressed]\n","Saving to: ‘cs182_homework.zip’\n","\n","cs182_homework.zip  100%[===================\u003e] 137.05M  42.3MB/s    in 3.3s    \n","\n","2021-03-20 09:21:45 (41.8 MB/s) - ‘cs182_homework.zip’ saved [143712234/143712234]\n","\n","Finished downloading. Unzipping and Verifying Data Integrity...\n","Checksum ok! Unzipping.\n","Archive:  cs182_homework.zip\n","  inflating: dataset/headline_generation_dataset_processed.json  \n","  inflating: dataset/headline_generation_vocabulary.txt  \n","  inflating: dataset/summarization_dataset_preprocessed.json  \n","  inflating: dataset/wp_vocab10000.model  \n","  inflating: dataset/wp_vocab10000.vocab  \n","Done downloading!\n"]}],"source":["!bash download_data.sh"]},{"cell_type":"markdown","metadata":{"id":"K-IuQsPW_uXc"},"source":["\n","\n","\n"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":810,"status":"ok","timestamp":1616321387092,"user":{"displayName":"Anthony Ng","photoUrl":"","userId":"16843483630260605487"},"user_tz":-480},"id":"N1twBPSLyUJz"},"outputs":[],"source":["%load_ext autoreload\n","%autoreload 2"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":3470,"status":"ok","timestamp":1616321407317,"user":{"displayName":"Anthony Ng","photoUrl":"","userId":"16843483630260605487"},"user_tz":-480},"id":"pPLGvVwByUJ3"},"outputs":[],"source":["import os\n","import sys\n","sys.path.append(root_folder)\n","from segtok import tokenizer\n","from collections import Counter\n","import torch as th\n","from torch import nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","import numpy as np\n","import json\n","from utils import validate_to_array"]},{"cell_type":"markdown","metadata":{"id":"OQTfdCRdyUJ8"},"source":["# Loading the datasets"]},{"cell_type":"markdown","metadata":{"id":"3dNGkjKmyUJ9"},"source":["Make sure the dataset files are all in the `dataset` folder of the assignment.\n","\n"," - If you are using this notebook locally: You should run the `download_data.sh` script.\n"," - If you are using the Colab version of the notebook, make sure that your Google Drive is mounted, and you verify from the file explorer in Colab that the files are viewable within `/content/drive/cs182_hw3_public/dataset/`\n"," \n"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3253,"status":"ok","timestamp":1616321413555,"user":{"displayName":"Anthony Ng","photoUrl":"","userId":"16843483630260605487"},"user_tz":-480},"id":"iLaRmt5uyUJ_","outputId":"0930f42e-93d9-4286-bda0-ad0d71dddc56"},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of training samples: 88568\n","Number of validation samples: 946\n"]}],"source":["# This cell loads the data for the model\n","# Run this before working on loading any of the additional data\n","\n","with open(dataset_folder+\"headline_generation_dataset_processed.json\", \"r\") as f:\n","    d_released = json.load(f)\n","\n","with open(dataset_folder+\"headline_generation_vocabulary.txt\", \"r\",encoding='utf8') as f:\n","    vocabulary = f.read().split(\"\\n\")\n","w2i = {w: i for i, w in enumerate(vocabulary)} # Word to index\n","i2w = {i: w for i, w in enumerate(vocabulary)} # Index to word\n","unkI, padI, startI = w2i['UNK'], w2i['PAD'], w2i['\u003cSTART\u003e']\n","\n","vocab_size = len(vocabulary)\n","input_length = len(d_released[0]['numerized']) # The length of the first element in the dataset, they are all of the same length\n","d_train = [d for d in d_released if d['cut'] == 'training']\n","d_valid = [d for d in d_released if d['cut'] == 'validation']\n","\n","print(\"Number of training samples:\",len(d_train))\n","print(\"Number of validation samples:\",len(d_valid))"]},{"cell_type":"markdown","metadata":{"id":"u31F-vXqyUKB"},"source":["Now that we have loaded the data, let's inspect one of the elements. Each sample in our dataset is has a `numerized` vector, that contains the preprocessed headline. This vector is what we will feed in to the neural network. The field `numerized` corresponds to this list of tokens. The already loaded dictionary `vocabulary` maps token lists to the actual string. Use these elements to recover `title` key of entry 1001 in the training dataset.\n","\n","**TODO**: Write the numerized2text function in notebook_utils and inspect element 1001 in the training dataset (`entry = d_train[1001]`).\n","\n"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":604,"status":"ok","timestamp":1616321414561,"user":{"displayName":"Anthony Ng","photoUrl":"","userId":"16843483630260605487"},"user_tz":-480},"id":"GqsHaZNbyUKD"},"outputs":[],"source":["def numerize_sequence(tokenized):\n","    return [w2i.get(w, unkI) for w in tokenized]\n","def pad_sequence(numerized, pad_index, to_length):\n","    pad = numerized[:to_length]\n","    padded = pad + [pad_index] * (to_length - len(pad))\n","    mask = [w != pad_index for w in padded]\n","    return padded, mask"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1215,"status":"ok","timestamp":1616312836025,"user":{"displayName":"Anthony Ng","photoUrl":"","userId":"16843483630260605487"},"user_tz":-480},"id":"GV2Bm_27TzOu","outputId":"a2248021-2ea0-48cd-cfa2-cb69b9821d38"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'cut': 'training', 'title': \"Microsoft donates cloud computing 'worth $1 bn'\", 'url': 'http://www.france24.com/en/20160120-microsoft-donates-cloud-computing-worth-1-bn', 'mask': [True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False], 'numerized': [20, 2908, 116, 1022, 8, 692, 24, 155, 1669, 8, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]}\n"]}],"source":["print(d_train[1001])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":936,"status":"ok","timestamp":1616221856524,"user":{"displayName":"Anthony Ng","photoUrl":"","userId":"16843483630260605487"},"user_tz":-480},"id":"hRjQEAiAVFEL","outputId":"5f5ecb11-444a-4839-ae3a-e92559b298f7"},"outputs":[{"name":"stdout","output_type":"stream","text":["1 2 0\n"]}],"source":["print(unkI, padI, startI)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":950,"status":"ok","timestamp":1616222035785,"user":{"displayName":"Anthony Ng","photoUrl":"","userId":"16843483630260605487"},"user_tz":-480},"id":"_u6OqydvVi5P","outputId":"aba598e7-9855-484c-be3f-ac74007ea752"},"outputs":[{"name":"stdout","output_type":"stream","text":["['microsoft', 'donates', 'cloud', 'computing', \"'\", 'worth', '$', '1', 'bn', \"'\", 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n"]}],"source":["print([i2w.get(i, unkI) for i in d_train[1001]['numerized']])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":907,"status":"ok","timestamp":1616221726392,"user":{"displayName":"Anthony Ng","photoUrl":"","userId":"16843483630260605487"},"user_tz":-480},"id":"8uCew8rdUapr","outputId":"6ea37a34-2098-48ff-847d-5814a3c7fc68"},"outputs":[{"name":"stdout","output_type":"stream","text":["[1, 228, 2843, 2110, 1590, 169, 1590, 5573, 610, 1, 2871, 1590, 7233, 18, 610, 4106, 169, 1, 2843, 1, 1590, 1, 2871, 1, 2843, 1590, 1260, 744, 1, 610, 228, 7233, 2341, 1, 8, 5755, 1590, 2110, 610, 7067, 1, 24, 155, 1, 3383, 7233, 8]\n"]}],"source":["print(numerize_sequence(d_train[1001]['title']))"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1074,"status":"ok","timestamp":1616321420355,"user":{"displayName":"Anthony Ng","photoUrl":"","userId":"16843483630260605487"},"user_tz":-480},"id":"C23VMn5DyUKF","outputId":"dce5b865-f0e5-4c95-f70d-307cf368feef"},"outputs":[{"name":"stdout","output_type":"stream","text":["Reversing the numerized: microsoft donates cloud computing ' worth $ 1 bn '\n","From the `title` entry: Microsoft donates cloud computing 'worth $1 bn'\n"]}],"source":["def numerized2text(numerized):\n","    \"\"\" Converts an integer sequence in the vocabulary into a string corresponding to the title.\n","    \n","        Arguments:\n","            numerized: List[int]  -- The list of vocabulary indices corresponding to the string\n","        Returns:\n","            title: str -- The string corresponding to the numerized input, without padding.\n","    \"\"\"\n","    #####\n","    # BEGIN YOUR CODE HERE \n","    # Recover each word from the vocabulary in the list of indices in numerized, using the vocabulary variable\n","    # Hint 1: Use the string.join() function to reconstruct a single string\n","    # Hint 2: The objects and/or functions defined in above cells may be useful.\n","    #####\n","\n","    word_list = [i2w.get(i) for i in numerized if i != 2]\n","    converted_string = ' '.join(word_list).strip()\n","    '''\n","    remove = []\n","    for i in range(1, len(converted_string)-1):\n","      if converted_string[i-1] in string.punctuation and converted_string[i+1] not in string.punctuation:\n","        remove.append(i)\n","        print(i)\n","      elif converted_string[i-1] not in string.punctuation and converted_string[i+1] in string.punctuation:\n","        remove.append(i)\n","        print(i)\n","    remove = reversed(remove)\n","    print(remove)\n","    for j in remove:\n","      converted_string = converted_string[:j] + converted_string[j+1:]\n","    '''\n","\n","    #####\n","    # END YOUR CODE HERE\n","    #####\n","    \n","    return converted_string\n","\n","entry = d_train[1001]\n","print(\"Reversing the numerized: \"+numerized2text(entry['numerized']))\n","validate_to_array(numerized2text,(entry['numerized'],),'numerized2text',root_folder)\n","print(\"From the `title` entry: \"+ entry['title'])"]},{"cell_type":"markdown","metadata":{"id":"ZrpgWj1FyUKH"},"source":["In language modeling, we train a model to produce the next word in the sequence given all previously generated words. This has, in practice, two steps:\n","\n","\n","    1. Adding a special \u003cSTART\u003e token to the start of the sequence for the input. This \"shifts\" the input to the right by one. We call this the \"source\" sequence\n","    2. Making the network predict the original, unshifted version (we call this the \"target\" sequence)\n","\n","    \n","Let's take an example. Say we want to train the network on the sentence: \"The cat is great.\"\n","The input to the network will be \"`\u003cSTART\u003e` The cat is great.\" The target will be: \"The cat is great\".\n","    \n","Therefore the first prediction is to select the word \"The\" given the `\u003cSTART\u003e` token.\n","The second prediction is to produce the word \"cat\" given the two tokens \"`\u003cSTART\u003e` The\".\n","At each step, the network learns to predict the next word, given all previous ones.\n","    \n","---"]},{"cell_type":"markdown","metadata":{"id":"HO2ww8XPyUKK"},"source":["Your next step is to write the build_batch function. Given a dataset, we select a random subset of samples, and will build the \"inputs\" and the \"targets\" of the batch, following the procedure we've described.\n","\n","**TODO**: write the build_batch function. We give you the structure, and you have to fill in where we have left things `your_code`.\n"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":995,"status":"ok","timestamp":1616321467203,"user":{"displayName":"Anthony Ng","photoUrl":"","userId":"16843483630260605487"},"user_tz":-480},"id":"Kl0f7hKKyUKL"},"outputs":[],"source":["def build_batch(dataset, indices):\n","    \"\"\" Builds a batch of source and target elements from the dataset.\n","    \n","        Arguments:\n","            dataset: List[db_element] -- A list of dataset elements\n","            indices: List[int] -- A list of indices of the dataset to sample\n","        Returns:\n","            batch_input: List[List[int]] -- List of source sequences\n","            batch_target: List[List[int]] -- List of target sequences\n","            batch_target_mask: List[List[int]] -- List of target batch masks\n","    \"\"\"\n","    #####\n","    # BEGIN YOUR CODE HERE \n","    #####\n","    \n","    # We get a list of indices we will choose from the dataset.\n","    # indices = range(iteration*batch_size,(iteration+1)*batch_size)\n","    \n","    # Recover what the entries for the batch are\n","    batch = [dataset[i] for i in indices]\n","    \n","    # Get the raw numerized for this input, each element of the dataset has a 'numerized' key\n","    batch_numerized = np.array([i['numerized'] for i in batch], dtype=object)\n","    \n","    # Create an array of startI that will be concatenated at position 1 for the input.\n","    # Should be of shape (batch_size, 1)\n","    start_tokens = np.array([[startI] for i in batch])\n","\n","    # Concatenate the start_tokens with the rest of the input\n","    # The np.concatenate function should be useful\n","    # The output should now be [batch_size, sequence_length+1]\n","    batch_input = np.hstack((start_tokens, batch_numerized))\n","\n","    # Remove the last word from each element in the batch\n","    # To restore the [batch_size, sequence_length] size\n","    batch_input = batch_input[:, :batch_input.shape[1]-1]\n","    \n","    # The target should be the un-shifted numerized input\n","    batch_target = np.array([i['numerized'] for i in batch])\n","\n","    # The target-mask is a 0 or 1 filter to note which tokens are\n","    # padding or not, to give the loss, so the model doesn't get rewarded for\n","    # predicting PAD tokens.\n","    batch_target_mask = np.array([a['mask'] for a in batch])\n","    \n","    #####\n","    # END YOUR CODE HERE \n","    #####\n","        \n","    return batch_input, batch_target, batch_target_mask\n","validate_to_array(build_batch,(d_train, range(100)),'build_batch',root_folder)"]},{"cell_type":"markdown","metadata":{"id":"fBbG3vC5yUKN"},"source":["# Creating the language model"]},{"cell_type":"markdown","metadata":{"id":"b3Eg8rHGyUKP"},"source":["Now that we've written the data pipelining, we are ready to write the Neural network.\n","\n","The steps to setting up a neural network to do Language modeling are:\n","- Creating the placeholders for the model, where we can feed in our inputs and targets.\n","- Creating an RNN of our choice, size, and with optional parameters\n","- Using the RNN on our placeholder inputs.\n","- Getting the output from the RNN, and projecting it into a vocabulary sized dimension, so that we can make word predictions.\n","- Setting up the loss on the outputs so that the network learns to produce the correct words.\n","- Finally, choosing an optimizer, and defining a training operation: using the optimizer to minimize the loss.\n","\n","We provide skeleton code for the model, you can fill in the `your_code` section. If you are unfamiliar with Pytorch, we provide some idea of what functions to look for, you should use the Pytorch online documentation.\n","\n","**TODO**: Fill in the LanguageModel in the language_model file.\n"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":1439,"status":"ok","timestamp":1616321471027,"user":{"displayName":"Anthony Ng","photoUrl":"","userId":"16843483630260605487"},"user_tz":-480},"id":"rKJ2D23GyUKR"},"outputs":[],"source":["from language_model import LanguageModel"]},{"cell_type":"markdown","metadata":{"id":"qz7ixZGKyUKT"},"source":["# Training the model"]},{"cell_type":"markdown","metadata":{"id":"9sDUBkpnyUKU"},"source":["Your objective is to train the Language on the dataset you are provided to reach a **validation loss \u003c= 5.50**\n","\n","**TODO**: Train your model so that it achieves a validation loss of \u003c= 5.5. \n","\n","**Careful**: we will be testing this loss on an unreleased test set, so make sure to evaluate properly on a validation set and not overfit. You must save the model you want us to test under: models/final_language_model (the .index, .meta and .data files)\n","\n","**Advice**:\n","- It should be possible to attain loss \u003c= 5.50 with a 1-layer LSTM of size 256 or less.\n","- You should not need more than 10 epochs to attain the threshold. More passes over the data can however give you a better model.\n","- You can however try using:\n","    - LSTM dropout (Pytorch has a layer for that)\n","    - Multi-layer RNN cell (Pytorch has a layer for that)\n","    - Change your optimizers, tune your learning_rate, use a learning rate schedule.\n","    \n","**Extra credit**:\n","\n","Get the loss below **validation loss \u003c= 5.00** and get 5 points of extra-credit on this assignment. Get creative,\n","\n","but remember, what you do should work on our held-out test set to get the points."]},{"cell_type":"markdown","metadata":{"id":"XkFSJn7GPrQt"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"T2jzYljYPrTN"},"source":[""]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":973,"status":"ok","timestamp":1616322299745,"user":{"displayName":"Anthony Ng","photoUrl":"","userId":"16843483630260605487"},"user_tz":-480},"id":"b01AZj0RyUKW","outputId":"cc60a182-9ac8-4ef9-90b3-cb3741f93393"},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda\n"]}],"source":["# We can create our model,\n","# with parameters of our choosing.\n","hidden_size = 256\n","num_layers = 1\n","dropout = .5\n","\n","# Setup the loss using cross-entropy loss.\n","# The logits are the output_logits we've computed,\n","# look at the pytorch docs for `CrossEntropyLoss` and `permute`\n","# to align the axes correctly and to account for the masking properly.\n","# The targets are the goal labels we are trying to match.\n","# Note that if you directly take the mean of the loss tensor,\n","# it will underestimate your loss! (why would that be?)\n","# Lastly, there are a few valid forms of averaging token losses,\n","# here we will take the mean of all non-mask tokens together.\n","criterion = nn.CrossEntropyLoss(reduction='none')\n","def loss_fn(pred, target, mask):\n","    pred =  pred.permute(0, 2, 1) # put the class probabilities in the middle\n","    loss_tensor = nn.CrossEntropyLoss()\n","    loss_masked = loss_tensor(pred, target) * mask\n","    loss_per_sample = th.mean(th.sum(loss_masked, 1) / th.count_nonzero(mask, dim=1))\n","    return loss_per_sample\n","\n","# The build_batch function outputs numpy, but our model is built in pytorch,\n","# so you need to convert numpy to pytorch.\n","# You also have to cast the masks into float32, target into long, and input into long.\n","# Look at the `float` and `long` function.\n","batch_to_torch = lambda b_in,b_target,b_mask: (th.from_numpy(b_in.astype(np.long)),\n","                                               th.from_numpy(b_target.astype(np.long)), \n","                                               th.from_numpy(b_mask.astype(np.float32)))\n","\n","\n","# Look at the docs for torch.optim and pick an optimizer\n","# And provide it with a start learning rate.\n","optimizer_class = optim.Adam\n","lr = 1e-5\n","epochs = 20\n","batch_size = 128\n","\n","model_id = 'test1'\n","os.makedirs(root_folder+'models/part1/',exist_ok=True)\n","\n","device = th.device(\"cuda\" if th.cuda.is_available() else \"cpu\")\n","print(device)\n","list_to_device = lambda th_obj: [tensor.to(device) for tensor in th_obj]"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":793,"status":"ok","timestamp":1616322304020,"user":{"displayName":"Anthony Ng","photoUrl":"","userId":"16843483630260605487"},"user_tz":-480},"id":"fjIAKqbvg9ER"},"outputs":[],"source":["model = LanguageModel(vocab_size=vocab_size, rnn_size=hidden_size, num_layers=num_layers, dropout=dropout)\n","optimizer = optimizer_class(model.parameters(), lr=lr)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"sVDHLiOmyUKX","scrolled":false},"outputs":[{"name":"stderr","output_type":"stream","text":["\n","\n","  0%|          | 0/692 [00:00\u003c?, ?it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 0 Loss: 12.532670021057129 Accuracy: 0.05756457522511482:   0%|          | 0/692 [00:00\u003c?, ?it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 0 Loss: 12.532670021057129 Accuracy: 0.05756457522511482:   1%|          | 4/692 [00:00\u003c00:18, 37.70it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 0 Loss: 12.532670021057129 Accuracy: 0.05756457522511482:   1%|          | 8/692 [00:00\u003c00:17, 38.07it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 10 Loss: 12.685227203369141 Accuracy: 0.05103300996124745:   1%|          | 8/692 [00:00\u003c00:17, 38.07it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 10 Loss: 12.685227203369141 Accuracy: 0.05103300996124745:   2%|▏         | 12/692 [00:00\u003c00:17, 38.52it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 10 Loss: 12.685227203369141 Accuracy: 0.05103300996124745:   2%|▏         | 17/692 [00:00\u003c00:17, 39.32it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 20 Loss: 12.77226972579956 Accuracy: 0.05463302358984947:   2%|▏         | 17/692 [00:00\u003c00:17, 39.32it/s] \u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 20 Loss: 12.77226972579956 Accuracy: 0.05463302358984947:   3%|▎         | 22/692 [00:00\u003c00:16, 39.56it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 20 Loss: 12.77226972579956 Accuracy: 0.05463302358984947:   4%|▍         | 27/692 [00:00\u003c00:16, 40.19it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 30 Loss: 12.697291946411132 Accuracy: 0.05844188369810581:   4%|▍         | 27/692 [00:00\u003c00:16, 40.19it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 30 Loss: 12.697291946411132 Accuracy: 0.05844188369810581:   5%|▍         | 32/692 [00:00\u003c00:16, 40.22it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 30 Loss: 12.697291946411132 Accuracy: 0.05844188369810581:   5%|▌         | 37/692 [00:00\u003c00:16, 40.54it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 40 Loss: 12.690194416046143 Accuracy: 0.05350551120936871:   5%|▌         | 37/692 [00:01\u003c00:16, 40.54it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 40 Loss: 12.690194416046143 Accuracy: 0.05350551120936871:   6%|▌         | 42/692 [00:01\u003c00:16, 40.50it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 40 Loss: 12.690194416046143 Accuracy: 0.05350551120936871:   7%|▋         | 47/692 [00:01\u003c00:15, 40.75it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 50 Loss: 12.72916202545166 Accuracy: 0.05356048345565796:   7%|▋         | 47/692 [00:01\u003c00:15, 40.75it/s] \u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 50 Loss: 12.72916202545166 Accuracy: 0.05356048345565796:   8%|▊         | 52/692 [00:01\u003c00:15, 40.61it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 50 Loss: 12.72916202545166 Accuracy: 0.05356048345565796:   8%|▊         | 57/692 [00:01\u003c00:15, 40.81it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 60 Loss: 12.546381855010987 Accuracy: 0.05291292406618595:   8%|▊         | 57/692 [00:01\u003c00:15, 40.81it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 60 Loss: 12.546381855010987 Accuracy: 0.05291292406618595:   9%|▉         | 62/692 [00:01\u003c00:15, 40.68it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 60 Loss: 12.546381855010987 Accuracy: 0.05291292406618595:  10%|▉         | 67/692 [00:01\u003c00:15, 40.89it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 70 Loss: 12.920895671844482 Accuracy: 0.0525562971830368:  10%|▉         | 67/692 [00:01\u003c00:15, 40.89it/s] \u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 70 Loss: 12.920895671844482 Accuracy: 0.0525562971830368:  10%|█         | 72/692 [00:01\u003c00:15, 40.83it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 70 Loss: 12.920895671844482 Accuracy: 0.0525562971830368:  11%|█         | 77/692 [00:01\u003c00:15, 40.94it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 80 Loss: 12.767942810058594 Accuracy: 0.0530889492481947:  11%|█         | 77/692 [00:01\u003c00:15, 40.94it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 80 Loss: 12.767942810058594 Accuracy: 0.0530889492481947:  12%|█▏        | 82/692 [00:02\u003c00:14, 40.78it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 80 Loss: 12.767942810058594 Accuracy: 0.0530889492481947:  13%|█▎        | 87/692 [00:02\u003c00:14, 41.03it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 90 Loss: 12.710949039459228 Accuracy: 0.05543832890689373:  13%|█▎        | 87/692 [00:02\u003c00:14, 41.03it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 90 Loss: 12.710949039459228 Accuracy: 0.05543832890689373:  13%|█▎        | 92/692 [00:02\u003c00:14, 40.90it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 90 Loss: 12.710949039459228 Accuracy: 0.05543832890689373:  14%|█▍        | 97/692 [00:02\u003c00:14, 41.14it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 100 Loss: 12.68112564086914 Accuracy: 0.049535664916038516:  14%|█▍        | 97/692 [00:02\u003c00:14, 41.14it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 100 Loss: 12.68112564086914 Accuracy: 0.049535664916038516:  15%|█▍        | 102/692 [00:02\u003c00:14, 40.86it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 100 Loss: 12.68112564086914 Accuracy: 0.049535664916038516:  15%|█▌        | 107/692 [00:02\u003c00:14, 41.04it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 110 Loss: 12.682486248016357 Accuracy: 0.05251370556652546:  15%|█▌        | 107/692 [00:02\u003c00:14, 41.04it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 110 Loss: 12.682486248016357 Accuracy: 0.05251370556652546:  16%|█▌        | 112/692 [00:02\u003c00:14, 40.82it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 110 Loss: 12.682486248016357 Accuracy: 0.05251370556652546:  17%|█▋        | 117/692 [00:02\u003c00:14, 40.89it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 120 Loss: 12.62767219543457 Accuracy: 0.051385678723454474:  17%|█▋        | 117/692 [00:02\u003c00:14, 40.89it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 120 Loss: 12.62767219543457 Accuracy: 0.051385678723454474:  18%|█▊        | 122/692 [00:03\u003c00:13, 40.72it/s]\u001b[A\u001b[A\n","Epoch: 1 Iteration: 250 Loss: 12.770635318756103 Accuracy: 0.0525106318295002:  36%|███▋      | 251/692 [00:16\u003c00:10, 40.86it/s]\u001b[A\n","\n","Epoch: 0 Iteration: 120 Loss: 12.62767219543457 Accuracy: 0.051385678723454474:  18%|█▊        | 127/692 [00:03\u003c00:13, 40.98it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 130 Loss: 12.610848331451416 Accuracy: 0.05701720118522644:  18%|█▊        | 127/692 [00:03\u003c00:13, 40.98it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 130 Loss: 12.610848331451416 Accuracy: 0.05701720118522644:  19%|█▉        | 132/692 [00:03\u003c00:13, 40.75it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 130 Loss: 12.610848331451416 Accuracy: 0.05701720118522644:  20%|█▉        | 137/692 [00:03\u003c00:13, 40.95it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 140 Loss: 12.660177612304688 Accuracy: 0.051340820267796516:  20%|█▉        | 137/692 [00:03\u003c00:13, 40.95it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 140 Loss: 12.660177612304688 Accuracy: 0.051340820267796516:  21%|██        | 142/692 [00:03\u003c00:13, 40.79it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 140 Loss: 12.660177612304688 Accuracy: 0.051340820267796516:  21%|██        | 147/692 [00:03\u003c00:13, 41.01it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 150 Loss: 12.6658353805542 Accuracy: 0.05504013374447823:  21%|██        | 147/692 [00:03\u003c00:13, 41.01it/s]   \u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 150 Loss: 12.6658353805542 Accuracy: 0.05504013374447823:  22%|██▏       | 152/692 [00:03\u003c00:13, 40.69it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 150 Loss: 12.6658353805542 Accuracy: 0.05504013374447823:  23%|██▎       | 157/692 [00:03\u003c00:13, 40.90it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 160 Loss: 12.76297721862793 Accuracy: 0.051417742297053336:  23%|██▎       | 157/692 [00:03\u003c00:13, 40.90it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 160 Loss: 12.76297721862793 Accuracy: 0.051417742297053336:  23%|██▎       | 162/692 [00:03\u003c00:13, 40.66it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 160 Loss: 12.76297721862793 Accuracy: 0.051417742297053336:  24%|██▍       | 167/692 [00:04\u003c00:12, 40.84it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 170 Loss: 12.784313201904297 Accuracy: 0.052066683769226074:  24%|██▍       | 167/692 [00:04\u003c00:12, 40.84it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 170 Loss: 12.784313201904297 Accuracy: 0.052066683769226074:  25%|██▍       | 172/692 [00:04\u003c00:12, 40.67it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 170 Loss: 12.784313201904297 Accuracy: 0.052066683769226074:  26%|██▌       | 177/692 [00:04\u003c00:12, 40.97it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 180 Loss: 12.780261898040772 Accuracy: 0.05178641825914383:  26%|██▌       | 177/692 [00:04\u003c00:12, 40.97it/s] \u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 180 Loss: 12.780261898040772 Accuracy: 0.05178641825914383:  26%|██▋       | 182/692 [00:04\u003c00:12, 40.83it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 180 Loss: 12.780261898040772 Accuracy: 0.05178641825914383:  27%|██▋       | 187/692 [00:04\u003c00:12, 41.08it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 190 Loss: 12.638301944732666 Accuracy: 0.056619416922330856:  27%|██▋       | 187/692 [00:04\u003c00:12, 41.08it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 190 Loss: 12.638301944732666 Accuracy: 0.056619416922330856:  28%|██▊       | 192/692 [00:04\u003c00:12, 40.76it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 190 Loss: 12.638301944732666 Accuracy: 0.056619416922330856:  28%|██▊       | 197/692 [00:04\u003c00:12, 40.92it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 200 Loss: 12.747759819030762 Accuracy: 0.05355874113738537:  28%|██▊       | 197/692 [00:04\u003c00:12, 40.92it/s] \u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 200 Loss: 12.747759819030762 Accuracy: 0.05355874113738537:  29%|██▉       | 202/692 [00:04\u003c00:12, 40.74it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 200 Loss: 12.747759819030762 Accuracy: 0.05355874113738537:  30%|██▉       | 207/692 [00:05\u003c00:11, 40.89it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 210 Loss: 12.638440322875976 Accuracy: 0.05353729613125324:  30%|██▉       | 207/692 [00:05\u003c00:11, 40.89it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 210 Loss: 12.638440322875976 Accuracy: 0.05353729613125324:  31%|███       | 212/692 [00:05\u003c00:11, 40.78it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 210 Loss: 12.638440322875976 Accuracy: 0.05353729613125324:  31%|███▏      | 217/692 [00:05\u003c00:11, 40.99it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 220 Loss: 13.011805534362793 Accuracy: 0.05241775587201118:  31%|███▏      | 217/692 [00:05\u003c00:11, 40.99it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 220 Loss: 13.011805534362793 Accuracy: 0.05241775587201118:  32%|███▏      | 222/692 [00:05\u003c00:11, 40.75it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 220 Loss: 13.011805534362793 Accuracy: 0.05241775587201118:  33%|███▎      | 227/692 [00:05\u003c00:11, 40.87it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 230 Loss: 12.71463747024536 Accuracy: 0.055353473499417306:  33%|███▎      | 227/692 [00:05\u003c00:11, 40.87it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 230 Loss: 12.71463747024536 Accuracy: 0.055353473499417306:  34%|███▎      | 232/692 [00:05\u003c00:11, 40.75it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 230 Loss: 12.71463747024536 Accuracy: 0.055353473499417306:  34%|███▍      | 237/692 [00:05\u003c00:11, 40.98it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 240 Loss: 12.77491044998169 Accuracy: 0.05465694293379784:  34%|███▍      | 237/692 [00:05\u003c00:11, 40.98it/s] \u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 240 Loss: 12.77491044998169 Accuracy: 0.05465694293379784:  35%|███▍      | 242/692 [00:05\u003c00:11, 40.71it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 240 Loss: 12.77491044998169 Accuracy: 0.05465694293379784:  36%|███▌      | 247/692 [00:06\u003c00:10, 40.95it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 250 Loss: 12.767288112640381 Accuracy: 0.05272677317261696:  36%|███▌      | 247/692 [00:06\u003c00:10, 40.95it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 250 Loss: 12.767288112640381 Accuracy: 0.05272677317261696:  36%|███▋      | 252/692 [00:06\u003c00:10, 40.76it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 250 Loss: 12.767288112640381 Accuracy: 0.05272677317261696:  37%|███▋      | 257/692 [00:06\u003c00:10, 40.97it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 260 Loss: 12.802899265289307 Accuracy: 0.05271505489945412:  37%|███▋      | 257/692 [00:06\u003c00:10, 40.97it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 260 Loss: 12.802899265289307 Accuracy: 0.05271505489945412:  38%|███▊      | 262/692 [00:06\u003c00:10, 40.72it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 260 Loss: 12.802899265289307 Accuracy: 0.05271505489945412:  39%|███▊      | 267/692 [00:06\u003c00:10, 40.96it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 270 Loss: 12.540508842468261 Accuracy: 0.05445393584668636:  39%|███▊      | 267/692 [00:06\u003c00:10, 40.96it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 270 Loss: 12.540508842468261 Accuracy: 0.05445393584668636:  39%|███▉      | 272/692 [00:06\u003c00:10, 40.67it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 270 Loss: 12.540508842468261 Accuracy: 0.05445393584668636:  40%|████      | 277/692 [00:06\u003c00:10, 40.89it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 280 Loss: 12.650472927093507 Accuracy: 0.053913244605064393:  40%|████      | 277/692 [00:06\u003c00:10, 40.89it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 280 Loss: 12.650472927093507 Accuracy: 0.053913244605064393:  41%|████      | 282/692 [00:06\u003c00:10, 40.78it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 280 Loss: 12.650472927093507 Accuracy: 0.053913244605064393:  41%|████▏     | 287/692 [00:07\u003c00:09, 40.92it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 290 Loss: 12.832385444641114 Accuracy: 0.05340872630476952:  41%|████▏     | 287/692 [00:07\u003c00:09, 40.92it/s] \u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 290 Loss: 12.832385444641114 Accuracy: 0.05340872630476952:  42%|████▏     | 292/692 [00:07\u003c00:09, 40.68it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 290 Loss: 12.832385444641114 Accuracy: 0.05340872630476952:  43%|████▎     | 297/692 [00:07\u003c00:09, 40.81it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 300 Loss: 12.704896354675293 Accuracy: 0.053346548601984976:  43%|████▎     | 297/692 [00:07\u003c00:09, 40.81it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 300 Loss: 12.704896354675293 Accuracy: 0.053346548601984976:  44%|████▎     | 302/692 [00:07\u003c00:09, 40.55it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 300 Loss: 12.704896354675293 Accuracy: 0.053346548601984976:  44%|████▍     | 307/692 [00:07\u003c00:09, 40.89it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 310 Loss: 12.843850135803223 Accuracy: 0.0503280695527792:  44%|████▍     | 307/692 [00:07\u003c00:09, 40.89it/s]  \u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 310 Loss: 12.843850135803223 Accuracy: 0.0503280695527792:  45%|████▌     | 312/692 [00:07\u003c00:09, 40.77it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 310 Loss: 12.843850135803223 Accuracy: 0.0503280695527792:  46%|████▌     | 317/692 [00:07\u003c00:09, 41.06it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 320 Loss: 12.77052183151245 Accuracy: 0.05539476647973061:  46%|████▌     | 317/692 [00:07\u003c00:09, 41.06it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 320 Loss: 12.77052183151245 Accuracy: 0.05539476647973061:  47%|████▋     | 322/692 [00:07\u003c00:09, 40.78it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 320 Loss: 12.77052183151245 Accuracy: 0.05539476647973061:  47%|████▋     | 327/692 [00:08\u003c00:08, 40.99it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 330 Loss: 12.704770278930663 Accuracy: 0.05656445324420929:  47%|████▋     | 327/692 [00:08\u003c00:08, 40.99it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 330 Loss: 12.704770278930663 Accuracy: 0.05656445324420929:  48%|████▊     | 332/692 [00:08\u003c00:08, 40.60it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 330 Loss: 12.704770278930663 Accuracy: 0.05656445324420929:  49%|████▊     | 337/692 [00:08\u003c00:08, 40.88it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 340 Loss: 12.800544452667236 Accuracy: 0.05510180480778217:  49%|████▊     | 337/692 [00:08\u003c00:08, 40.88it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 340 Loss: 12.800544452667236 Accuracy: 0.05510180480778217:  49%|████▉     | 342/692 [00:08\u003c00:08, 40.69it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 340 Loss: 12.800544452667236 Accuracy: 0.05510180480778217:  50%|█████     | 347/692 [00:08\u003c00:08, 40.95it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 350 Loss: 12.6256534576416 Accuracy: 0.0539542842656374:  50%|█████     | 347/692 [00:08\u003c00:08, 40.95it/s]   \u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 350 Loss: 12.6256534576416 Accuracy: 0.0539542842656374:  51%|█████     | 352/692 [00:08\u003c00:08, 40.76it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 350 Loss: 12.6256534576416 Accuracy: 0.0539542842656374:  52%|█████▏    | 357/692 [00:08\u003c00:08, 40.96it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 360 Loss: 12.585276985168457 Accuracy: 0.0590316042304039:  52%|█████▏    | 357/692 [00:08\u003c00:08, 40.96it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 360 Loss: 12.585276985168457 Accuracy: 0.0590316042304039:  52%|█████▏    | 362/692 [00:08\u003c00:08, 40.86it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 360 Loss: 12.585276985168457 Accuracy: 0.0590316042304039:  53%|█████▎    | 367/692 [00:08\u003c00:07, 40.98it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 370 Loss: 12.606637096405029 Accuracy: 0.050943315774202344:  53%|█████▎    | 367/692 [00:09\u003c00:07, 40.98it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 370 Loss: 12.606637096405029 Accuracy: 0.050943315774202344:  54%|█████▍    | 372/692 [00:09\u003c00:07, 40.88it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 370 Loss: 12.606637096405029 Accuracy: 0.050943315774202344:  54%|█████▍    | 377/692 [00:09\u003c00:07, 41.05it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 380 Loss: 12.735515975952149 Accuracy: 0.05330537743866444:  54%|█████▍    | 377/692 [00:09\u003c00:07, 41.05it/s] \u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 380 Loss: 12.735515975952149 Accuracy: 0.05330537743866444:  55%|█████▌    | 382/692 [00:09\u003c00:07, 40.85it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 380 Loss: 12.735515975952149 Accuracy: 0.05330537743866444:  56%|█████▌    | 387/692 [00:09\u003c00:07, 41.04it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 390 Loss: 12.761882495880126 Accuracy: 0.053901332244277:  56%|█████▌    | 387/692 [00:09\u003c00:07, 41.04it/s]  \u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 390 Loss: 12.761882495880126 Accuracy: 0.053901332244277:  57%|█████▋    | 392/692 [00:09\u003c00:07, 40.81it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 390 Loss: 12.761882495880126 Accuracy: 0.053901332244277:  57%|█████▋    | 397/692 [00:09\u003c00:07, 40.99it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 400 Loss: 12.733389377593994 Accuracy: 0.05145951248705387:  57%|█████▋    | 397/692 [00:09\u003c00:07, 40.99it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 400 Loss: 12.733389377593994 Accuracy: 0.05145951248705387:  58%|█████▊    | 402/692 [00:09\u003c00:07, 40.90it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 400 Loss: 12.733389377593994 Accuracy: 0.05145951248705387:  59%|█████▉    | 407/692 [00:09\u003c00:06, 40.99it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 410 Loss: 12.730550384521484 Accuracy: 0.05090712457895279:  59%|█████▉    | 407/692 [00:10\u003c00:06, 40.99it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 410 Loss: 12.730550384521484 Accuracy: 0.05090712457895279:  60%|█████▉    | 412/692 [00:10\u003c00:06, 40.89it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 410 Loss: 12.730550384521484 Accuracy: 0.05090712457895279:  60%|██████    | 417/692 [00:10\u003c00:06, 41.21it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 420 Loss: 12.700628185272217 Accuracy: 0.05341205410659313:  60%|██████    | 417/692 [00:10\u003c00:06, 41.21it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 420 Loss: 12.700628185272217 Accuracy: 0.05341205410659313:  61%|██████    | 422/692 [00:10\u003c00:06, 41.00it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 420 Loss: 12.700628185272217 Accuracy: 0.05341205410659313:  62%|██████▏   | 427/692 [00:10\u003c00:06, 41.20it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 430 Loss: 12.752767753601074 Accuracy: 0.05228603966534138:  62%|██████▏   | 427/692 [00:10\u003c00:06, 41.20it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 430 Loss: 12.752767753601074 Accuracy: 0.05228603966534138:  62%|██████▏   | 432/692 [00:10\u003c00:06, 40.80it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 430 Loss: 12.752767753601074 Accuracy: 0.05228603966534138:  63%|██████▎   | 437/692 [00:10\u003c00:06, 41.00it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 440 Loss: 12.74193172454834 Accuracy: 0.05133361220359802:  63%|██████▎   | 437/692 [00:10\u003c00:06, 41.00it/s] \u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 440 Loss: 12.74193172454834 Accuracy: 0.05133361220359802:  64%|██████▍   | 442/692 [00:10\u003c00:06, 40.48it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 440 Loss: 12.74193172454834 Accuracy: 0.05133361220359802:  65%|██████▍   | 447/692 [00:10\u003c00:06, 40.74it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 450 Loss: 12.662399196624756 Accuracy: 0.05331713519990444:  65%|██████▍   | 447/692 [00:11\u003c00:06, 40.74it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 450 Loss: 12.662399196624756 Accuracy: 0.05331713519990444:  65%|██████▌   | 452/692 [00:11\u003c00:05, 40.59it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 450 Loss: 12.662399196624756 Accuracy: 0.05331713519990444:  66%|██████▌   | 457/692 [00:11\u003c00:05, 40.79it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 460 Loss: 12.822428607940674 Accuracy: 0.05401118174195289:  66%|██████▌   | 457/692 [00:11\u003c00:05, 40.79it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 460 Loss: 12.822428607940674 Accuracy: 0.05401118174195289:  67%|██████▋   | 462/692 [00:11\u003c00:05, 40.59it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 460 Loss: 12.822428607940674 Accuracy: 0.05401118174195289:  67%|██████▋   | 467/692 [00:11\u003c00:05, 40.71it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 470 Loss: 12.738194751739503 Accuracy: 0.05231322795152664:  67%|██████▋   | 467/692 [00:11\u003c00:05, 40.71it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 470 Loss: 12.738194751739503 Accuracy: 0.05231322795152664:  68%|██████▊   | 472/692 [00:11\u003c00:05, 40.48it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 470 Loss: 12.738194751739503 Accuracy: 0.05231322795152664:  69%|██████▉   | 477/692 [00:11\u003c00:05, 40.77it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 480 Loss: 12.664183807373046 Accuracy: 0.053302671387791635:  69%|██████▉   | 477/692 [00:11\u003c00:05, 40.77it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 480 Loss: 12.664183807373046 Accuracy: 0.053302671387791635:  70%|██████▉   | 482/692 [00:11\u003c00:05, 40.59it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 480 Loss: 12.664183807373046 Accuracy: 0.053302671387791635:  70%|███████   | 487/692 [00:11\u003c00:05, 40.81it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 490 Loss: 12.788479900360107 Accuracy: 0.053789838403463366:  70%|███████   | 487/692 [00:12\u003c00:05, 40.81it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 490 Loss: 12.788479900360107 Accuracy: 0.053789838403463366:  71%|███████   | 492/692 [00:12\u003c00:04, 40.60it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 490 Loss: 12.788479900360107 Accuracy: 0.053789838403463366:  72%|███████▏  | 497/692 [00:12\u003c00:04, 40.90it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 500 Loss: 12.524225997924805 Accuracy: 0.05392023473978043:  72%|███████▏  | 497/692 [00:12\u003c00:04, 40.90it/s] \u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 500 Loss: 12.524225997924805 Accuracy: 0.05392023473978043:  73%|███████▎  | 502/692 [00:12\u003c00:04, 40.82it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 500 Loss: 12.524225997924805 Accuracy: 0.05392023473978043:  73%|███████▎  | 507/692 [00:12\u003c00:04, 41.01it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 510 Loss: 12.694548416137696 Accuracy: 0.05180300958454609:  73%|███████▎  | 507/692 [00:12\u003c00:04, 41.01it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 510 Loss: 12.694548416137696 Accuracy: 0.05180300958454609:  74%|███████▍  | 512/692 [00:12\u003c00:04, 40.89it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 510 Loss: 12.694548416137696 Accuracy: 0.05180300958454609:  75%|███████▍  | 517/692 [00:12\u003c00:04, 41.08it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 520 Loss: 12.649851417541504 Accuracy: 0.0507518969476223:  75%|███████▍  | 517/692 [00:12\u003c00:04, 41.08it/s] \u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 520 Loss: 12.649851417541504 Accuracy: 0.0507518969476223:  75%|███████▌  | 522/692 [00:12\u003c00:04, 40.87it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 520 Loss: 12.649851417541504 Accuracy: 0.0507518969476223:  76%|███████▌  | 527/692 [00:12\u003c00:04, 41.03it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 530 Loss: 12.72058687210083 Accuracy: 0.05055347010493279:  76%|███████▌  | 527/692 [00:13\u003c00:04, 41.03it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 530 Loss: 12.72058687210083 Accuracy: 0.05055347010493279:  77%|███████▋  | 532/692 [00:13\u003c00:03, 40.72it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 530 Loss: 12.72058687210083 Accuracy: 0.05055347010493279:  78%|███████▊  | 537/692 [00:13\u003c00:03, 40.70it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 540 Loss: 12.668080615997315 Accuracy: 0.05402316711843014:  78%|███████▊  | 537/692 [00:13\u003c00:03, 40.70it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 540 Loss: 12.668080615997315 Accuracy: 0.05402316711843014:  78%|███████▊  | 542/692 [00:13\u003c00:03, 40.38it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 540 Loss: 12.668080615997315 Accuracy: 0.05402316711843014:  79%|███████▉  | 547/692 [00:13\u003c00:03, 40.75it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 550 Loss: 12.928070068359375 Accuracy: 0.05336504466831684:  79%|███████▉  | 547/692 [00:13\u003c00:03, 40.75it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 550 Loss: 12.928070068359375 Accuracy: 0.05336504466831684:  80%|███████▉  | 552/692 [00:13\u003c00:03, 40.67it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 550 Loss: 12.928070068359375 Accuracy: 0.05336504466831684:  80%|████████  | 557/692 [00:13\u003c00:03, 40.89it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 560 Loss: 12.685278511047363 Accuracy: 0.05297805666923523:  80%|████████  | 557/692 [00:13\u003c00:03, 40.89it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 560 Loss: 12.685278511047363 Accuracy: 0.05297805666923523:  81%|████████  | 562/692 [00:13\u003c00:03, 40.71it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 560 Loss: 12.685278511047363 Accuracy: 0.05297805666923523:  82%|████████▏ | 567/692 [00:13\u003c00:03, 41.02it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 570 Loss: 12.857769298553468 Accuracy: 0.053639334812760356:  82%|████████▏ | 567/692 [00:13\u003c00:03, 41.02it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 570 Loss: 12.857769298553468 Accuracy: 0.053639334812760356:  83%|████████▎ | 572/692 [00:14\u003c00:02, 40.87it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 570 Loss: 12.857769298553468 Accuracy: 0.053639334812760356:  83%|████████▎ | 577/692 [00:14\u003c00:02, 41.00it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 580 Loss: 12.474573135375977 Accuracy: 0.05324963554739952:  83%|████████▎ | 577/692 [00:14\u003c00:02, 41.00it/s] \u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 580 Loss: 12.474573135375977 Accuracy: 0.05324963554739952:  84%|████████▍ | 582/692 [00:14\u003c00:02, 40.68it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 580 Loss: 12.474573135375977 Accuracy: 0.05324963554739952:  85%|████████▍ | 587/692 [00:14\u003c00:02, 40.91it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 590 Loss: 12.652732849121094 Accuracy: 0.05351237952709198:  85%|████████▍ | 587/692 [00:14\u003c00:02, 40.91it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 590 Loss: 12.652732849121094 Accuracy: 0.05351237952709198:  86%|████████▌ | 592/692 [00:14\u003c00:02, 40.62it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 590 Loss: 12.652732849121094 Accuracy: 0.05351237952709198:  86%|████████▋ | 597/692 [00:14\u003c00:02, 40.79it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 600 Loss: 12.614520645141601 Accuracy: 0.05522181019186974:  86%|████████▋ | 597/692 [00:14\u003c00:02, 40.79it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 600 Loss: 12.614520645141601 Accuracy: 0.05522181019186974:  87%|████████▋ | 602/692 [00:14\u003c00:02, 40.64it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 600 Loss: 12.614520645141601 Accuracy: 0.05522181019186974:  88%|████████▊ | 607/692 [00:14\u003c00:02, 40.87it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 610 Loss: 12.53261308670044 Accuracy: 0.054289791360497476:  88%|████████▊ | 607/692 [00:14\u003c00:02, 40.87it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 610 Loss: 12.53261308670044 Accuracy: 0.054289791360497476:  88%|████████▊ | 612/692 [00:15\u003c00:01, 40.65it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 610 Loss: 12.53261308670044 Accuracy: 0.054289791360497476:  89%|████████▉ | 617/692 [00:15\u003c00:01, 40.92it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 620 Loss: 12.67653293609619 Accuracy: 0.052755539491772654:  89%|████████▉ | 617/692 [00:15\u003c00:01, 40.92it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 620 Loss: 12.67653293609619 Accuracy: 0.052755539491772654:  90%|████████▉ | 622/692 [00:15\u003c00:01, 40.67it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 620 Loss: 12.67653293609619 Accuracy: 0.052755539491772654:  91%|█████████ | 627/692 [00:15\u003c00:01, 40.80it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 630 Loss: 12.606340217590333 Accuracy: 0.05361357368528843:  91%|█████████ | 627/692 [00:15\u003c00:01, 40.80it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 630 Loss: 12.606340217590333 Accuracy: 0.05361357368528843:  91%|█████████▏| 632/692 [00:15\u003c00:01, 40.60it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 630 Loss: 12.606340217590333 Accuracy: 0.05361357368528843:  92%|█████████▏| 637/692 [00:15\u003c00:01, 40.82it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 640 Loss: 12.55851182937622 Accuracy: 0.05338344983756542:  92%|█████████▏| 637/692 [00:15\u003c00:01, 40.82it/s] \u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 640 Loss: 12.55851182937622 Accuracy: 0.05338344983756542:  93%|█████████▎| 642/692 [00:15\u003c00:01, 40.69it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 640 Loss: 12.55851182937622 Accuracy: 0.05338344983756542:  93%|█████████▎| 647/692 [00:15\u003c00:01, 40.92it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 650 Loss: 12.814156913757325 Accuracy: 0.051971451565623286:  93%|█████████▎| 647/692 [00:15\u003c00:01, 40.92it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 650 Loss: 12.814156913757325 Accuracy: 0.051971451565623286:  94%|█████████▍| 652/692 [00:15\u003c00:00, 40.77it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 650 Loss: 12.814156913757325 Accuracy: 0.051971451565623286:  95%|█████████▍| 657/692 [00:16\u003c00:00, 40.98it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 660 Loss: 12.681385707855224 Accuracy: 0.0530803631991148:  95%|█████████▍| 657/692 [00:16\u003c00:00, 40.98it/s]  \u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 660 Loss: 12.681385707855224 Accuracy: 0.0530803631991148:  96%|█████████▌| 662/692 [00:16\u003c00:00, 40.71it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 660 Loss: 12.681385707855224 Accuracy: 0.0530803631991148:  96%|█████████▋| 667/692 [00:16\u003c00:00, 40.96it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 670 Loss: 12.76705026626587 Accuracy: 0.051146532595157626:  96%|█████████▋| 667/692 [00:16\u003c00:00, 40.96it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 670 Loss: 12.76705026626587 Accuracy: 0.051146532595157626:  97%|█████████▋| 672/692 [00:16\u003c00:00, 40.65it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 670 Loss: 12.76705026626587 Accuracy: 0.051146532595157626:  98%|█████████▊| 677/692 [00:16\u003c00:00, 40.85it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 680 Loss: 12.710973834991455 Accuracy: 0.05160648673772812:  98%|█████████▊| 677/692 [00:16\u003c00:00, 40.85it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 680 Loss: 12.710973834991455 Accuracy: 0.05160648673772812:  99%|█████████▊| 682/692 [00:16\u003c00:00, 40.73it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 680 Loss: 12.710973834991455 Accuracy: 0.05160648673772812:  99%|█████████▉| 687/692 [00:16\u003c00:00, 40.86it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 690 Loss: 12.735701751708984 Accuracy: 0.05612796992063522:  99%|█████████▉| 687/692 [00:16\u003c00:00, 40.86it/s]\u001b[A\u001b[A\n","\n","Epoch: 0 Iteration: 690 Loss: 12.735701751708984 Accuracy: 0.05612796992063522: 100%|██████████| 692/692 [00:16\u003c00:00, 40.79it/s]\n","\n","\n","  0%|          | 0/692 [00:00\u003c?, ?it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 0 Loss: 12.74298677444458 Accuracy: 0.055390074476599695:   0%|          | 0/692 [00:00\u003c?, ?it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 0 Loss: 12.74298677444458 Accuracy: 0.055390074476599695:   1%|          | 5/692 [00:00\u003c00:16, 40.82it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 0 Loss: 12.74298677444458 Accuracy: 0.055390074476599695:   1%|▏         | 10/692 [00:00\u003c00:16, 40.99it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 10 Loss: 12.643792724609375 Accuracy: 0.05516827069222927:   1%|▏         | 10/692 [00:00\u003c00:16, 40.99it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 10 Loss: 12.643792724609375 Accuracy: 0.05516827069222927:   2%|▏         | 14/692 [00:00\u003c00:16, 40.61it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 10 Loss: 12.643792724609375 Accuracy: 0.05516827069222927:   3%|▎         | 19/692 [00:00\u003c00:16, 40.85it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 20 Loss: 12.499413108825683 Accuracy: 0.04867208451032638:   3%|▎         | 19/692 [00:00\u003c00:16, 40.85it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 20 Loss: 12.499413108825683 Accuracy: 0.04867208451032638:   3%|▎         | 23/692 [00:00\u003c00:16, 40.44it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 20 Loss: 12.499413108825683 Accuracy: 0.04867208451032638:   4%|▍         | 28/692 [00:00\u003c00:16, 40.72it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 30 Loss: 12.715149974822998 Accuracy: 0.0530230887234211:   4%|▍         | 28/692 [00:00\u003c00:16, 40.72it/s] \u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 30 Loss: 12.715149974822998 Accuracy: 0.0530230887234211:   5%|▍         | 33/692 [00:00\u003c00:16, 40.69it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 30 Loss: 12.715149974822998 Accuracy: 0.0530230887234211:   5%|▌         | 38/692 [00:00\u003c00:16, 40.84it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 40 Loss: 12.76974925994873 Accuracy: 0.05379355326294899:   5%|▌         | 38/692 [00:01\u003c00:16, 40.84it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 40 Loss: 12.76974925994873 Accuracy: 0.05379355326294899:   6%|▌         | 42/692 [00:01\u003c00:16, 40.37it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 40 Loss: 12.76974925994873 Accuracy: 0.05379355326294899:   7%|▋         | 47/692 [00:01\u003c00:15, 40.72it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 50 Loss: 12.80942611694336 Accuracy: 0.05230607390403748:   7%|▋         | 47/692 [00:01\u003c00:15, 40.72it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 50 Loss: 12.80942611694336 Accuracy: 0.05230607390403748:   7%|▋         | 51/692 [00:01\u003c00:15, 40.48it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 50 Loss: 12.80942611694336 Accuracy: 0.05230607390403748:   8%|▊         | 56/692 [00:01\u003c00:15, 40.67it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 60 Loss: 12.683594894409179 Accuracy: 0.05153398439288139:   8%|▊         | 56/692 [00:01\u003c00:15, 40.67it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 60 Loss: 12.683594894409179 Accuracy: 0.05153398439288139:   9%|▉         | 61/692 [00:01\u003c00:15, 40.65it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 60 Loss: 12.683594894409179 Accuracy: 0.05153398439288139:  10%|▉         | 66/692 [00:01\u003c00:15, 40.65it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 70 Loss: 12.679842472076416 Accuracy: 0.05283842794597149:  10%|▉         | 66/692 [00:01\u003c00:15, 40.65it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 70 Loss: 12.679842472076416 Accuracy: 0.05283842794597149:  10%|█         | 71/692 [00:01\u003c00:15, 40.61it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 70 Loss: 12.679842472076416 Accuracy: 0.05283842794597149:  11%|█         | 76/692 [00:01\u003c00:15, 40.76it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 80 Loss: 12.76899528503418 Accuracy: 0.052284881472587585:  11%|█         | 76/692 [00:01\u003c00:15, 40.76it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 80 Loss: 12.76899528503418 Accuracy: 0.052284881472587585:  12%|█▏        | 81/692 [00:01\u003c00:15, 40.70it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 80 Loss: 12.76899528503418 Accuracy: 0.052284881472587585:  12%|█▏        | 86/692 [00:02\u003c00:14, 40.83it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 90 Loss: 12.764677238464355 Accuracy: 0.05219295620918274:  12%|█▏        | 86/692 [00:02\u003c00:14, 40.83it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 90 Loss: 12.764677238464355 Accuracy: 0.05219295620918274:  13%|█▎        | 91/692 [00:02\u003c00:14, 40.83it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 90 Loss: 12.764677238464355 Accuracy: 0.05219295620918274:  14%|█▍        | 96/692 [00:02\u003c00:14, 40.66it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 100 Loss: 12.500627708435058 Accuracy: 0.054633695632219315:  14%|█▍        | 96/692 [00:02\u003c00:14, 40.66it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 100 Loss: 12.500627708435058 Accuracy: 0.054633695632219315:  15%|█▍        | 101/692 [00:02\u003c00:14, 40.71it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 100 Loss: 12.500627708435058 Accuracy: 0.054633695632219315:  15%|█▌        | 106/692 [00:02\u003c00:14, 40.73it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 110 Loss: 12.856598377227783 Accuracy: 0.05096975713968277:  15%|█▌        | 106/692 [00:02\u003c00:14, 40.73it/s] \u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 110 Loss: 12.856598377227783 Accuracy: 0.05096975713968277:  16%|█▌        | 111/692 [00:02\u003c00:14, 40.74it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 110 Loss: 12.856598377227783 Accuracy: 0.05096975713968277:  17%|█▋        | 116/692 [00:02\u003c00:14, 40.79it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 120 Loss: 12.71818265914917 Accuracy: 0.0544644333422184:  17%|█▋        | 116/692 [00:02\u003c00:14, 40.79it/s]  \u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 120 Loss: 12.71818265914917 Accuracy: 0.0544644333422184:  17%|█▋        | 121/692 [00:02\u003c00:13, 40.88it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 120 Loss: 12.71818265914917 Accuracy: 0.0544644333422184:  18%|█▊        | 126/692 [00:03\u003c00:13, 40.96it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 130 Loss: 12.786964988708496 Accuracy: 0.05080954097211361:  18%|█▊        | 126/692 [00:03\u003c00:13, 40.96it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 130 Loss: 12.786964988708496 Accuracy: 0.05080954097211361:  19%|█▉        | 131/692 [00:03\u003c00:13, 40.93it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 130 Loss: 12.786964988708496 Accuracy: 0.05080954097211361:  20%|█▉        | 136/692 [00:03\u003c00:13, 40.89it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 140 Loss: 12.835602569580079 Accuracy: 0.05069032870233059:  20%|█▉        | 136/692 [00:03\u003c00:13, 40.89it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 140 Loss: 12.835602569580079 Accuracy: 0.05069032870233059:  20%|██        | 141/692 [00:03\u003c00:13, 40.88it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 140 Loss: 12.835602569580079 Accuracy: 0.05069032870233059:  21%|██        | 146/692 [00:03\u003c00:13, 40.82it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 150 Loss: 12.82003345489502 Accuracy: 0.05381888933479786:  21%|██        | 146/692 [00:03\u003c00:13, 40.82it/s] \u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 150 Loss: 12.82003345489502 Accuracy: 0.05381888933479786:  22%|██▏       | 151/692 [00:03\u003c00:13, 40.56it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 150 Loss: 12.82003345489502 Accuracy: 0.05381888933479786:  23%|██▎       | 156/692 [00:03\u003c00:13, 40.78it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 160 Loss: 12.813235569000245 Accuracy: 0.05097614414989948:  23%|██▎       | 156/692 [00:03\u003c00:13, 40.78it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 160 Loss: 12.813235569000245 Accuracy: 0.05097614414989948:  23%|██▎       | 161/692 [00:03\u003c00:12, 40.85it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 160 Loss: 12.813235569000245 Accuracy: 0.05097614414989948:  24%|██▍       | 166/692 [00:04\u003c00:12, 40.99it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 170 Loss: 12.802387809753418 Accuracy: 0.05245676189661026:  24%|██▍       | 166/692 [00:04\u003c00:12, 40.99it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 170 Loss: 12.802387809753418 Accuracy: 0.05245676189661026:  25%|██▍       | 171/692 [00:04\u003c00:12, 41.00it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 170 Loss: 12.802387809753418 Accuracy: 0.05245676189661026:  25%|██▌       | 176/692 [00:04\u003c00:12, 40.89it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 180 Loss: 12.596856117248535 Accuracy: 0.053649702295660975:  25%|██▌       | 176/692 [00:04\u003c00:12, 40.89it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 180 Loss: 12.596856117248535 Accuracy: 0.053649702295660975:  26%|██▌       | 181/692 [00:04\u003c00:12, 40.92it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 180 Loss: 12.596856117248535 Accuracy: 0.053649702295660975:  27%|██▋       | 186/692 [00:04\u003c00:12, 41.06it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 190 Loss: 12.939580345153809 Accuracy: 0.05513775534927845:  27%|██▋       | 186/692 [00:04\u003c00:12, 41.06it/s] \u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 190 Loss: 12.939580345153809 Accuracy: 0.05513775534927845:  28%|██▊       | 191/692 [00:04\u003c00:12, 40.96it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 190 Loss: 12.939580345153809 Accuracy: 0.05513775534927845:  28%|██▊       | 196/692 [00:04\u003c00:12, 40.72it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 200 Loss: 12.494307804107667 Accuracy: 0.05425740852952003:  28%|██▊       | 196/692 [00:04\u003c00:12, 40.72it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 200 Loss: 12.494307804107667 Accuracy: 0.05425740852952003:  29%|██▉       | 201/692 [00:04\u003c00:12, 40.60it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 200 Loss: 12.494307804107667 Accuracy: 0.05425740852952003:  30%|██▉       | 206/692 [00:05\u003c00:12, 40.16it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 210 Loss: 12.667308902740478 Accuracy: 0.056081097573041916:  30%|██▉       | 206/692 [00:05\u003c00:12, 40.16it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 210 Loss: 12.667308902740478 Accuracy: 0.056081097573041916:  30%|███       | 211/692 [00:05\u003c00:11, 40.19it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 210 Loss: 12.667308902740478 Accuracy: 0.056081097573041916:  31%|███       | 216/692 [00:05\u003c00:11, 40.48it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 220 Loss: 12.542706775665284 Accuracy: 0.05451748259365559:  31%|███       | 216/692 [00:05\u003c00:11, 40.48it/s] \u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 220 Loss: 12.542706775665284 Accuracy: 0.05451748259365559:  32%|███▏      | 221/692 [00:05\u003c00:11, 40.33it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 220 Loss: 12.542706775665284 Accuracy: 0.05451748259365559:  33%|███▎      | 226/692 [00:05\u003c00:11, 40.49it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 230 Loss: 12.646902370452882 Accuracy: 0.05079351179301739:  33%|███▎      | 226/692 [00:05\u003c00:11, 40.49it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 230 Loss: 12.646902370452882 Accuracy: 0.05079351179301739:  33%|███▎      | 231/692 [00:05\u003c00:11, 40.59it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 230 Loss: 12.646902370452882 Accuracy: 0.05079351179301739:  34%|███▍      | 236/692 [00:05\u003c00:11, 40.87it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 240 Loss: 12.623075866699219 Accuracy: 0.05236671604216099:  34%|███▍      | 236/692 [00:05\u003c00:11, 40.87it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 240 Loss: 12.623075866699219 Accuracy: 0.05236671604216099:  35%|███▍      | 241/692 [00:05\u003c00:11, 40.98it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 240 Loss: 12.623075866699219 Accuracy: 0.05236671604216099:  36%|███▌      | 246/692 [00:06\u003c00:10, 41.02it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 250 Loss: 12.714214611053468 Accuracy: 0.05436065904796124:  36%|███▌      | 246/692 [00:06\u003c00:10, 41.02it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 250 Loss: 12.714214611053468 Accuracy: 0.05436065904796124:  36%|███▋      | 251/692 [00:06\u003c00:10, 40.89it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 250 Loss: 12.714214611053468 Accuracy: 0.05436065904796124:  37%|███▋      | 256/692 [00:06\u003c00:10, 40.90it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 260 Loss: 12.775783061981201 Accuracy: 0.05294073857367039:  37%|███▋      | 256/692 [00:06\u003c00:10, 40.90it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 260 Loss: 12.775783061981201 Accuracy: 0.05294073857367039:  38%|███▊      | 261/692 [00:06\u003c00:10, 40.88it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 260 Loss: 12.775783061981201 Accuracy: 0.05294073857367039:  38%|███▊      | 266/692 [00:06\u003c00:10, 40.96it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 270 Loss: 12.702416038513183 Accuracy: 0.05495377071201801:  38%|███▊      | 266/692 [00:06\u003c00:10, 40.96it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 270 Loss: 12.702416038513183 Accuracy: 0.05495377071201801:  39%|███▉      | 271/692 [00:06\u003c00:10, 41.04it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 270 Loss: 12.702416038513183 Accuracy: 0.05495377071201801:  40%|███▉      | 276/692 [00:06\u003c00:10, 41.02it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 280 Loss: 12.635709285736084 Accuracy: 0.05000634081661701:  40%|███▉      | 276/692 [00:06\u003c00:10, 41.02it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 280 Loss: 12.635709285736084 Accuracy: 0.05000634081661701:  41%|████      | 281/692 [00:06\u003c00:09, 41.16it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 280 Loss: 12.635709285736084 Accuracy: 0.05000634081661701:  41%|████▏     | 286/692 [00:07\u003c00:09, 41.14it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 290 Loss: 12.524889659881591 Accuracy: 0.05602166652679443:  41%|████▏     | 286/692 [00:07\u003c00:09, 41.14it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 290 Loss: 12.524889659881591 Accuracy: 0.05602166652679443:  42%|████▏     | 291/692 [00:07\u003c00:09, 41.16it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 290 Loss: 12.524889659881591 Accuracy: 0.05602166652679443:  43%|████▎     | 296/692 [00:07\u003c00:09, 41.21it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 300 Loss: 12.675795459747315 Accuracy: 0.05197987779974937:  43%|████▎     | 296/692 [00:07\u003c00:09, 41.21it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 300 Loss: 12.675795459747315 Accuracy: 0.05197987779974937:  43%|████▎     | 301/692 [00:07\u003c00:09, 41.03it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 300 Loss: 12.675795459747315 Accuracy: 0.05197987779974937:  44%|████▍     | 306/692 [00:07\u003c00:09, 41.03it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 310 Loss: 12.799664115905761 Accuracy: 0.05395932160317898:  44%|████▍     | 306/692 [00:07\u003c00:09, 41.03it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 310 Loss: 12.799664115905761 Accuracy: 0.05395932160317898:  45%|████▍     | 311/692 [00:07\u003c00:09, 40.99it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 310 Loss: 12.799664115905761 Accuracy: 0.05395932160317898:  46%|████▌     | 316/692 [00:07\u003c00:09, 40.94it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 320 Loss: 12.7577654838562 Accuracy: 0.055598584935069084:  46%|████▌     | 316/692 [00:07\u003c00:09, 40.94it/s] \u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 320 Loss: 12.7577654838562 Accuracy: 0.055598584935069084:  46%|████▋     | 321/692 [00:07\u003c00:09, 40.88it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 320 Loss: 12.7577654838562 Accuracy: 0.055598584935069084:  47%|████▋     | 326/692 [00:07\u003c00:08, 40.98it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 330 Loss: 12.701080417633056 Accuracy: 0.053643171489238736:  47%|████▋     | 326/692 [00:08\u003c00:08, 40.98it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 330 Loss: 12.701080417633056 Accuracy: 0.053643171489238736:  48%|████▊     | 331/692 [00:08\u003c00:08, 40.94it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 330 Loss: 12.701080417633056 Accuracy: 0.053643171489238736:  49%|████▊     | 336/692 [00:08\u003c00:08, 40.98it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 340 Loss: 12.657341480255127 Accuracy: 0.05552106127142906:  49%|████▊     | 336/692 [00:08\u003c00:08, 40.98it/s] \u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 340 Loss: 12.657341480255127 Accuracy: 0.05552106127142906:  49%|████▉     | 341/692 [00:08\u003c00:08, 40.96it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 340 Loss: 12.657341480255127 Accuracy: 0.05552106127142906:  50%|█████     | 346/692 [00:08\u003c00:08, 41.09it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 350 Loss: 12.746461772918702 Accuracy: 0.05514664240181446:  50%|█████     | 346/692 [00:08\u003c00:08, 41.09it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 350 Loss: 12.746461772918702 Accuracy: 0.05514664240181446:  51%|█████     | 351/692 [00:08\u003c00:08, 40.95it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 350 Loss: 12.746461772918702 Accuracy: 0.05514664240181446:  51%|█████▏    | 356/692 [00:08\u003c00:08, 41.04it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 360 Loss: 12.755816650390624 Accuracy: 0.05236957706511021:  51%|█████▏    | 356/692 [00:08\u003c00:08, 41.04it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 360 Loss: 12.755816650390624 Accuracy: 0.05236957706511021:  52%|█████▏    | 361/692 [00:08\u003c00:08, 41.09it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 360 Loss: 12.755816650390624 Accuracy: 0.05236957706511021:  53%|█████▎    | 366/692 [00:08\u003c00:07, 41.09it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 370 Loss: 12.747200012207031 Accuracy: 0.05358310528099537:  53%|█████▎    | 366/692 [00:09\u003c00:07, 41.09it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 370 Loss: 12.747200012207031 Accuracy: 0.05358310528099537:  54%|█████▎    | 371/692 [00:09\u003c00:07, 41.00it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 370 Loss: 12.747200012207031 Accuracy: 0.05358310528099537:  54%|█████▍    | 376/692 [00:09\u003c00:07, 41.06it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 380 Loss: 12.692376232147216 Accuracy: 0.05162280648946762:  54%|█████▍    | 376/692 [00:09\u003c00:07, 41.06it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 380 Loss: 12.692376232147216 Accuracy: 0.05162280648946762:  55%|█████▌    | 381/692 [00:09\u003c00:07, 40.88it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 380 Loss: 12.692376232147216 Accuracy: 0.05162280648946762:  56%|█████▌    | 386/692 [00:09\u003c00:07, 40.99it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 390 Loss: 12.60848035812378 Accuracy: 0.05323017686605454:  56%|█████▌    | 386/692 [00:09\u003c00:07, 40.99it/s] \u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 390 Loss: 12.60848035812378 Accuracy: 0.05323017686605454:  57%|█████▋    | 391/692 [00:09\u003c00:07, 40.90it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 390 Loss: 12.60848035812378 Accuracy: 0.05323017686605454:  57%|█████▋    | 396/692 [00:09\u003c00:07, 41.18it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 400 Loss: 12.637020015716553 Accuracy: 0.05570029616355896:  57%|█████▋    | 396/692 [00:09\u003c00:07, 41.18it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 400 Loss: 12.637020015716553 Accuracy: 0.05570029616355896:  58%|█████▊    | 401/692 [00:09\u003c00:07, 41.20it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 400 Loss: 12.637020015716553 Accuracy: 0.05570029616355896:  59%|█████▊    | 406/692 [00:09\u003c00:06, 41.12it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 410 Loss: 12.965104961395264 Accuracy: 0.05606936141848564:  59%|█████▊    | 406/692 [00:10\u003c00:06, 41.12it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 410 Loss: 12.965104961395264 Accuracy: 0.05606936141848564:  59%|█████▉    | 411/692 [00:10\u003c00:06, 41.00it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 410 Loss: 12.965104961395264 Accuracy: 0.05606936141848564:  60%|██████    | 416/692 [00:10\u003c00:06, 41.09it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 420 Loss: 12.648076438903809 Accuracy: 0.054703564196825025:  60%|██████    | 416/692 [00:10\u003c00:06, 41.09it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 420 Loss: 12.648076438903809 Accuracy: 0.054703564196825025:  61%|██████    | 421/692 [00:10\u003c00:06, 41.06it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 420 Loss: 12.648076438903809 Accuracy: 0.054703564196825025:  62%|██████▏   | 426/692 [00:10\u003c00:06, 40.87it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 430 Loss: 12.819972610473632 Accuracy: 0.05753014087677002:  62%|██████▏   | 426/692 [00:10\u003c00:06, 40.87it/s] \u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 430 Loss: 12.819972610473632 Accuracy: 0.05753014087677002:  62%|██████▏   | 431/692 [00:10\u003c00:06, 40.68it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 430 Loss: 12.819972610473632 Accuracy: 0.05753014087677002:  63%|██████▎   | 436/692 [00:10\u003c00:06, 40.75it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 440 Loss: 12.690765953063964 Accuracy: 0.05296775959432125:  63%|██████▎   | 436/692 [00:10\u003c00:06, 40.75it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 440 Loss: 12.690765953063964 Accuracy: 0.05296775959432125:  64%|██████▎   | 441/692 [00:10\u003c00:06, 40.74it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 440 Loss: 12.690765953063964 Accuracy: 0.05296775959432125:  64%|██████▍   | 446/692 [00:10\u003c00:06, 40.87it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 450 Loss: 12.583064365386964 Accuracy: 0.05293494202196598:  64%|██████▍   | 446/692 [00:11\u003c00:06, 40.87it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 450 Loss: 12.583064365386964 Accuracy: 0.05293494202196598:  65%|██████▌   | 451/692 [00:11\u003c00:05, 40.76it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 450 Loss: 12.583064365386964 Accuracy: 0.05293494202196598:  66%|██████▌   | 456/692 [00:11\u003c00:05, 40.65it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 460 Loss: 12.743514728546142 Accuracy: 0.05712299607694149:  66%|██████▌   | 456/692 [00:11\u003c00:05, 40.65it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 460 Loss: 12.743514728546142 Accuracy: 0.05712299607694149:  67%|██████▋   | 461/692 [00:11\u003c00:05, 40.76it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 460 Loss: 12.743514728546142 Accuracy: 0.05712299607694149:  67%|██████▋   | 466/692 [00:11\u003c00:05, 40.89it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 470 Loss: 12.701769256591797 Accuracy: 0.056378310173749925:  67%|██████▋   | 466/692 [00:11\u003c00:05, 40.89it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 470 Loss: 12.701769256591797 Accuracy: 0.056378310173749925:  68%|██████▊   | 471/692 [00:11\u003c00:05, 40.79it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 470 Loss: 12.701769256591797 Accuracy: 0.056378310173749925:  69%|██████▉   | 476/692 [00:11\u003c00:05, 40.96it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 480 Loss: 12.72985200881958 Accuracy: 0.05001299679279327:  69%|██████▉   | 476/692 [00:11\u003c00:05, 40.96it/s]  \u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 480 Loss: 12.72985200881958 Accuracy: 0.05001299679279327:  70%|██████▉   | 481/692 [00:11\u003c00:05, 40.92it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 480 Loss: 12.72985200881958 Accuracy: 0.05001299679279327:  70%|███████   | 486/692 [00:11\u003c00:05, 40.98it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 490 Loss: 12.712962245941162 Accuracy: 0.0532859992235899:  70%|███████   | 486/692 [00:12\u003c00:05, 40.98it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 490 Loss: 12.712962245941162 Accuracy: 0.0532859992235899:  71%|███████   | 491/692 [00:12\u003c00:04, 40.97it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 490 Loss: 12.712962245941162 Accuracy: 0.0532859992235899:  72%|███████▏  | 496/692 [00:12\u003c00:04, 40.95it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 500 Loss: 12.71127290725708 Accuracy: 0.0500274982303381:  72%|███████▏  | 496/692 [00:12\u003c00:04, 40.95it/s] \u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 500 Loss: 12.71127290725708 Accuracy: 0.0500274982303381:  72%|███████▏  | 501/692 [00:12\u003c00:04, 40.92it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 500 Loss: 12.71127290725708 Accuracy: 0.0500274982303381:  73%|███████▎  | 506/692 [00:12\u003c00:04, 40.93it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 510 Loss: 12.717076969146728 Accuracy: 0.05272597633302212:  73%|███████▎  | 506/692 [00:12\u003c00:04, 40.93it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 510 Loss: 12.717076969146728 Accuracy: 0.05272597633302212:  74%|███████▍  | 511/692 [00:12\u003c00:04, 40.91it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 510 Loss: 12.717076969146728 Accuracy: 0.05272597633302212:  75%|███████▍  | 516/692 [00:12\u003c00:04, 41.05it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 520 Loss: 12.658294105529786 Accuracy: 0.04910649843513966:  75%|███████▍  | 516/692 [00:12\u003c00:04, 41.05it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 520 Loss: 12.658294105529786 Accuracy: 0.04910649843513966:  75%|███████▌  | 521/692 [00:12\u003c00:04, 41.04it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 520 Loss: 12.658294105529786 Accuracy: 0.04910649843513966:  76%|███████▌  | 526/692 [00:12\u003c00:04, 40.99it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 530 Loss: 12.685198307037354 Accuracy: 0.0551270816475153:  76%|███████▌  | 526/692 [00:12\u003c00:04, 40.99it/s] \u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 530 Loss: 12.685198307037354 Accuracy: 0.0551270816475153:  77%|███████▋  | 531/692 [00:12\u003c00:03, 40.94it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 530 Loss: 12.685198307037354 Accuracy: 0.0551270816475153:  77%|███████▋  | 536/692 [00:13\u003c00:03, 41.06it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 540 Loss: 12.731507682800293 Accuracy: 0.05570542104542255:  77%|███████▋  | 536/692 [00:13\u003c00:03, 41.06it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 540 Loss: 12.731507682800293 Accuracy: 0.05570542104542255:  78%|███████▊  | 541/692 [00:13\u003c00:03, 40.96it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 540 Loss: 12.731507682800293 Accuracy: 0.05570542104542255:  79%|███████▉  | 546/692 [00:13\u003c00:03, 40.67it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 550 Loss: 12.838142013549804 Accuracy: 0.05328582301735878:  79%|███████▉  | 546/692 [00:13\u003c00:03, 40.67it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 550 Loss: 12.838142013549804 Accuracy: 0.05328582301735878:  80%|███████▉  | 551/692 [00:13\u003c00:03, 40.73it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 550 Loss: 12.838142013549804 Accuracy: 0.05328582301735878:  80%|████████  | 556/692 [00:13\u003c00:03, 40.74it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 560 Loss: 12.669419384002685 Accuracy: 0.053987234085798266:  80%|████████  | 556/692 [00:13\u003c00:03, 40.74it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 560 Loss: 12.669419384002685 Accuracy: 0.053987234085798266:  81%|████████  | 561/692 [00:13\u003c00:03, 40.76it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 560 Loss: 12.669419384002685 Accuracy: 0.053987234085798266:  82%|████████▏ | 566/692 [00:13\u003c00:03, 40.78it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 570 Loss: 12.51472053527832 Accuracy: 0.05197921767830849:  82%|████████▏ | 566/692 [00:13\u003c00:03, 40.78it/s]  \u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 570 Loss: 12.51472053527832 Accuracy: 0.05197921767830849:  83%|████████▎ | 571/692 [00:13\u003c00:02, 40.71it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 570 Loss: 12.51472053527832 Accuracy: 0.05197921767830849:  83%|████████▎ | 576/692 [00:14\u003c00:02, 40.83it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 580 Loss: 12.575901794433594 Accuracy: 0.05216174647212028:  83%|████████▎ | 576/692 [00:14\u003c00:02, 40.83it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 580 Loss: 12.575901794433594 Accuracy: 0.05216174647212028:  84%|████████▍ | 581/692 [00:14\u003c00:02, 40.89it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 580 Loss: 12.575901794433594 Accuracy: 0.05216174647212028:  85%|████████▍ | 586/692 [00:14\u003c00:02, 40.96it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 590 Loss: 12.584556484222412 Accuracy: 0.05357567854225635:  85%|████████▍ | 586/692 [00:14\u003c00:02, 40.96it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 590 Loss: 12.584556484222412 Accuracy: 0.05357567854225635:  85%|████████▌ | 591/692 [00:14\u003c00:02, 40.98it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 590 Loss: 12.584556484222412 Accuracy: 0.05357567854225635:  86%|████████▌ | 596/692 [00:14\u003c00:02, 40.86it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 600 Loss: 12.764824104309081 Accuracy: 0.05478080846369267:  86%|████████▌ | 596/692 [00:14\u003c00:02, 40.86it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 600 Loss: 12.764824104309081 Accuracy: 0.05478080846369267:  87%|████████▋ | 601/692 [00:14\u003c00:02, 40.90it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 600 Loss: 12.764824104309081 Accuracy: 0.05478080846369267:  88%|████████▊ | 606/692 [00:14\u003c00:02, 40.91it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 610 Loss: 12.673551940917969 Accuracy: 0.05383727625012398:  88%|████████▊ | 606/692 [00:14\u003c00:02, 40.91it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 610 Loss: 12.673551940917969 Accuracy: 0.05383727625012398:  88%|████████▊ | 611/692 [00:14\u003c00:01, 40.85it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 610 Loss: 12.673551940917969 Accuracy: 0.05383727625012398:  89%|████████▉ | 616/692 [00:15\u003c00:01, 40.87it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 620 Loss: 12.74045352935791 Accuracy: 0.05528725571930408:  89%|████████▉ | 616/692 [00:15\u003c00:01, 40.87it/s] \u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 620 Loss: 12.74045352935791 Accuracy: 0.05528725571930408:  90%|████████▉ | 621/692 [00:15\u003c00:01, 40.77it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 620 Loss: 12.74045352935791 Accuracy: 0.05528725571930408:  90%|█████████ | 626/692 [00:15\u003c00:01, 40.91it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 630 Loss: 12.777443504333496 Accuracy: 0.05307992175221443:  90%|█████████ | 626/692 [00:15\u003c00:01, 40.91it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 630 Loss: 12.777443504333496 Accuracy: 0.05307992175221443:  91%|█████████ | 631/692 [00:15\u003c00:01, 40.86it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 630 Loss: 12.777443504333496 Accuracy: 0.05307992175221443:  92%|█████████▏| 636/692 [00:15\u003c00:01, 40.90it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 640 Loss: 12.842073059082031 Accuracy: 0.05158281177282333:  92%|█████████▏| 636/692 [00:15\u003c00:01, 40.90it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 640 Loss: 12.842073059082031 Accuracy: 0.05158281177282333:  93%|█████████▎| 641/692 [00:15\u003c00:01, 40.92it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 640 Loss: 12.842073059082031 Accuracy: 0.05158281177282333:  93%|█████████▎| 646/692 [00:15\u003c00:01, 40.78it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 650 Loss: 12.78561897277832 Accuracy: 0.05020716041326523:  93%|█████████▎| 646/692 [00:15\u003c00:01, 40.78it/s] \u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 650 Loss: 12.78561897277832 Accuracy: 0.05020716041326523:  94%|█████████▍| 651/692 [00:15\u003c00:01, 40.74it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 650 Loss: 12.78561897277832 Accuracy: 0.05020716041326523:  95%|█████████▍| 656/692 [00:16\u003c00:00, 40.85it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 660 Loss: 12.863957977294922 Accuracy: 0.054643073305487636:  95%|█████████▍| 656/692 [00:16\u003c00:00, 40.85it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 660 Loss: 12.863957977294922 Accuracy: 0.054643073305487636:  96%|█████████▌| 661/692 [00:16\u003c00:00, 40.89it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 660 Loss: 12.863957977294922 Accuracy: 0.054643073305487636:  96%|█████████▌| 666/692 [00:16\u003c00:00, 41.00it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 670 Loss: 12.720084285736084 Accuracy: 0.0553808655589819:  96%|█████████▌| 666/692 [00:16\u003c00:00, 41.00it/s]  \u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 670 Loss: 12.720084285736084 Accuracy: 0.0553808655589819:  97%|█████████▋| 671/692 [00:16\u003c00:00, 40.99it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 670 Loss: 12.720084285736084 Accuracy: 0.0553808655589819:  98%|█████████▊| 676/692 [00:16\u003c00:00, 40.58it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 680 Loss: 12.640428733825683 Accuracy: 0.056304332241415976:  98%|█████████▊| 676/692 [00:16\u003c00:00, 40.58it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 680 Loss: 12.640428733825683 Accuracy: 0.056304332241415976:  98%|█████████▊| 681/692 [00:16\u003c00:00, 40.71it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 680 Loss: 12.640428733825683 Accuracy: 0.056304332241415976:  99%|█████████▉| 686/692 [00:16\u003c00:00, 40.82it/s]\u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 690 Loss: 12.81040449142456 Accuracy: 0.05043763816356659:  99%|█████████▉| 686/692 [00:16\u003c00:00, 40.82it/s]  \u001b[A\u001b[A\n","\n","Epoch: 1 Iteration: 690 Loss: 12.81040449142456 Accuracy: 0.05043763816356659: 100%|██████████| 692/692 [00:16\u003c00:00, 40.86it/s]\n","\n","\n","  0%|          | 0/692 [00:00\u003c?, ?it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 0 Loss: 12.737397003173829 Accuracy: 0.05086732134222984:   0%|          | 0/692 [00:00\u003c?, ?it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 0 Loss: 12.737397003173829 Accuracy: 0.05086732134222984:   1%|          | 4/692 [00:00\u003c00:17, 39.94it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 0 Loss: 12.737397003173829 Accuracy: 0.05086732134222984:   1%|▏         | 9/692 [00:00\u003c00:16, 40.39it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 10 Loss: 12.611701583862304 Accuracy: 0.05264311768114567:   1%|▏         | 9/692 [00:00\u003c00:16, 40.39it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 10 Loss: 12.611701583862304 Accuracy: 0.05264311768114567:   2%|▏         | 13/692 [00:00\u003c00:16, 40.13it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 10 Loss: 12.611701583862304 Accuracy: 0.05264311768114567:   3%|▎         | 18/692 [00:00\u003c00:16, 40.56it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 20 Loss: 12.663146591186523 Accuracy: 0.055730852857232095:   3%|▎         | 18/692 [00:00\u003c00:16, 40.56it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 20 Loss: 12.663146591186523 Accuracy: 0.055730852857232095:   3%|▎         | 22/692 [00:00\u003c00:16, 40.24it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 20 Loss: 12.663146591186523 Accuracy: 0.055730852857232095:   4%|▍         | 27/692 [00:00\u003c00:16, 40.61it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 30 Loss: 12.523730087280274 Accuracy: 0.05143754594027996:   4%|▍         | 27/692 [00:00\u003c00:16, 40.61it/s] \u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 30 Loss: 12.523730087280274 Accuracy: 0.05143754594027996:   5%|▍         | 32/692 [00:00\u003c00:16, 40.53it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 30 Loss: 12.523730087280274 Accuracy: 0.05143754594027996:   5%|▌         | 37/692 [00:00\u003c00:16, 40.81it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 40 Loss: 12.576033020019532 Accuracy: 0.052389505133032796:   5%|▌         | 37/692 [00:01\u003c00:16, 40.81it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 40 Loss: 12.576033020019532 Accuracy: 0.052389505133032796:   6%|▌         | 42/692 [00:01\u003c00:15, 40.79it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 40 Loss: 12.576033020019532 Accuracy: 0.052389505133032796:   7%|▋         | 47/692 [00:01\u003c00:15, 40.93it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 50 Loss: 12.660024452209473 Accuracy: 0.051146960258483885:   7%|▋         | 47/692 [00:01\u003c00:15, 40.93it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 50 Loss: 12.660024452209473 Accuracy: 0.051146960258483885:   8%|▊         | 52/692 [00:01\u003c00:15, 40.80it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 50 Loss: 12.660024452209473 Accuracy: 0.051146960258483885:   8%|▊         | 57/692 [00:01\u003c00:15, 40.98it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 60 Loss: 12.821367073059083 Accuracy: 0.0519786961376667:   8%|▊         | 57/692 [00:01\u003c00:15, 40.98it/s]  \u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 60 Loss: 12.821367073059083 Accuracy: 0.0519786961376667:   9%|▉         | 62/692 [00:01\u003c00:15, 40.71it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 60 Loss: 12.821367073059083 Accuracy: 0.0519786961376667:  10%|▉         | 67/692 [00:01\u003c00:15, 40.95it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 70 Loss: 12.817614364624024 Accuracy: 0.0516778938472271:  10%|▉         | 67/692 [00:01\u003c00:15, 40.95it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 70 Loss: 12.817614364624024 Accuracy: 0.0516778938472271:  10%|█         | 72/692 [00:01\u003c00:15, 40.76it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 70 Loss: 12.817614364624024 Accuracy: 0.0516778938472271:  11%|█         | 77/692 [00:01\u003c00:15, 40.90it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 80 Loss: 12.702572917938232 Accuracy: 0.05550193451344967:  11%|█         | 77/692 [00:01\u003c00:15, 40.90it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 80 Loss: 12.702572917938232 Accuracy: 0.05550193451344967:  12%|█▏        | 82/692 [00:02\u003c00:14, 40.82it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 80 Loss: 12.702572917938232 Accuracy: 0.05550193451344967:  13%|█▎        | 87/692 [00:02\u003c00:14, 40.99it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 90 Loss: 12.568257999420165 Accuracy: 0.05151839852333069:  13%|█▎        | 87/692 [00:02\u003c00:14, 40.99it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 90 Loss: 12.568257999420165 Accuracy: 0.05151839852333069:  13%|█▎        | 92/692 [00:02\u003c00:14, 40.67it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 90 Loss: 12.568257999420165 Accuracy: 0.05151839852333069:  14%|█▍        | 97/692 [00:02\u003c00:14, 40.93it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 100 Loss: 12.832671642303467 Accuracy: 0.050140231102705005:  14%|█▍        | 97/692 [00:02\u003c00:14, 40.93it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 100 Loss: 12.832671642303467 Accuracy: 0.050140231102705005:  15%|█▍        | 102/692 [00:02\u003c00:14, 40.76it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 100 Loss: 12.832671642303467 Accuracy: 0.050140231102705005:  15%|█▌        | 107/692 [00:02\u003c00:14, 41.00it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 110 Loss: 12.7405029296875 Accuracy: 0.05529868677258491:  15%|█▌        | 107/692 [00:02\u003c00:14, 41.00it/s]   \u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 110 Loss: 12.7405029296875 Accuracy: 0.05529868677258491:  16%|█▌        | 112/692 [00:02\u003c00:14, 40.72it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 110 Loss: 12.7405029296875 Accuracy: 0.05529868677258491:  17%|█▋        | 117/692 [00:02\u003c00:14, 40.68it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 120 Loss: 12.61096544265747 Accuracy: 0.0543281365185976:  17%|█▋        | 117/692 [00:02\u003c00:14, 40.68it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 120 Loss: 12.61096544265747 Accuracy: 0.0543281365185976:  18%|█▊        | 122/692 [00:02\u003c00:14, 40.51it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 120 Loss: 12.61096544265747 Accuracy: 0.0543281365185976:  18%|█▊        | 127/692 [00:03\u003c00:13, 40.84it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 130 Loss: 12.608980274200439 Accuracy: 0.054454590380191806:  18%|█▊        | 127/692 [00:03\u003c00:13, 40.84it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 130 Loss: 12.608980274200439 Accuracy: 0.054454590380191806:  19%|█▉        | 132/692 [00:03\u003c00:13, 40.71it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 130 Loss: 12.608980274200439 Accuracy: 0.054454590380191806:  20%|█▉        | 137/692 [00:03\u003c00:13, 40.93it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 140 Loss: 12.816547393798828 Accuracy: 0.052030603587627414:  20%|█▉        | 137/692 [00:03\u003c00:13, 40.93it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 140 Loss: 12.816547393798828 Accuracy: 0.052030603587627414:  21%|██        | 142/692 [00:03\u003c00:13, 40.63it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 140 Loss: 12.816547393798828 Accuracy: 0.052030603587627414:  21%|██        | 147/692 [00:03\u003c00:13, 40.92it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 150 Loss: 12.730069637298584 Accuracy: 0.05507030375301838:  21%|██        | 147/692 [00:03\u003c00:13, 40.92it/s] \u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 150 Loss: 12.730069637298584 Accuracy: 0.05507030375301838:  22%|██▏       | 152/692 [00:03\u003c00:13, 40.82it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 150 Loss: 12.730069637298584 Accuracy: 0.05507030375301838:  23%|██▎       | 157/692 [00:03\u003c00:13, 41.05it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 160 Loss: 12.939235210418701 Accuracy: 0.054004646465182306:  23%|██▎       | 157/692 [00:03\u003c00:13, 41.05it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 160 Loss: 12.939235210418701 Accuracy: 0.054004646465182306:  23%|██▎       | 162/692 [00:03\u003c00:12, 40.78it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 160 Loss: 12.939235210418701 Accuracy: 0.054004646465182306:  24%|██▍       | 167/692 [00:04\u003c00:12, 40.95it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 170 Loss: 12.55567979812622 Accuracy: 0.055437136068940164:  24%|██▍       | 167/692 [00:04\u003c00:12, 40.95it/s] \u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 170 Loss: 12.55567979812622 Accuracy: 0.055437136068940164:  25%|██▍       | 172/692 [00:04\u003c00:12, 40.75it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 170 Loss: 12.55567979812622 Accuracy: 0.055437136068940164:  26%|██▌       | 177/692 [00:04\u003c00:12, 40.93it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 180 Loss: 12.752307033538818 Accuracy: 0.05388919524848461:  26%|██▌       | 177/692 [00:04\u003c00:12, 40.93it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 180 Loss: 12.752307033538818 Accuracy: 0.05388919524848461:  26%|██▋       | 182/692 [00:04\u003c00:12, 40.72it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 180 Loss: 12.752307033538818 Accuracy: 0.05388919524848461:  27%|██▋       | 187/692 [00:04\u003c00:12, 40.94it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 190 Loss: 12.625533294677734 Accuracy: 0.05542446374893188:  27%|██▋       | 187/692 [00:04\u003c00:12, 40.94it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 190 Loss: 12.625533294677734 Accuracy: 0.05542446374893188:  28%|██▊       | 192/692 [00:04\u003c00:12, 40.83it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 190 Loss: 12.625533294677734 Accuracy: 0.05542446374893188:  28%|██▊       | 197/692 [00:04\u003c00:12, 41.08it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 200 Loss: 12.639185333251953 Accuracy: 0.05546349324285984:  28%|██▊       | 197/692 [00:04\u003c00:12, 41.08it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 200 Loss: 12.639185333251953 Accuracy: 0.05546349324285984:  29%|██▉       | 202/692 [00:04\u003c00:12, 40.55it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 200 Loss: 12.639185333251953 Accuracy: 0.05546349324285984:  30%|██▉       | 207/692 [00:05\u003c00:12, 40.14it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 210 Loss: 12.722596454620362 Accuracy: 0.055891639366745946:  30%|██▉       | 207/692 [00:05\u003c00:12, 40.14it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 210 Loss: 12.722596454620362 Accuracy: 0.055891639366745946:  31%|███       | 212/692 [00:05\u003c00:11, 40.19it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 210 Loss: 12.722596454620362 Accuracy: 0.055891639366745946:  31%|███▏      | 217/692 [00:05\u003c00:11, 40.37it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 220 Loss: 12.668284797668457 Accuracy: 0.051345844939351085:  31%|███▏      | 217/692 [00:05\u003c00:11, 40.37it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 220 Loss: 12.668284797668457 Accuracy: 0.051345844939351085:  32%|███▏      | 222/692 [00:05\u003c00:11, 40.45it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 220 Loss: 12.668284797668457 Accuracy: 0.051345844939351085:  33%|███▎      | 227/692 [00:05\u003c00:11, 40.70it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 230 Loss: 12.843363952636718 Accuracy: 0.05344406925141811:  33%|███▎      | 227/692 [00:05\u003c00:11, 40.70it/s] \u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 230 Loss: 12.843363952636718 Accuracy: 0.05344406925141811:  34%|███▎      | 232/692 [00:05\u003c00:11, 40.67it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 230 Loss: 12.843363952636718 Accuracy: 0.05344406925141811:  34%|███▍      | 237/692 [00:05\u003c00:11, 40.87it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 240 Loss: 12.689308643341064 Accuracy: 0.05075678303837776:  34%|███▍      | 237/692 [00:05\u003c00:11, 40.87it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 240 Loss: 12.689308643341064 Accuracy: 0.05075678303837776:  35%|███▍      | 242/692 [00:05\u003c00:11, 40.65it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 240 Loss: 12.689308643341064 Accuracy: 0.05075678303837776:  36%|███▌      | 247/692 [00:06\u003c00:10, 40.75it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 250 Loss: 12.760354137420654 Accuracy: 0.05297393314540386:  36%|███▌      | 247/692 [00:06\u003c00:10, 40.75it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 250 Loss: 12.760354137420654 Accuracy: 0.05297393314540386:  36%|███▋      | 252/692 [00:06\u003c00:10, 40.62it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 250 Loss: 12.760354137420654 Accuracy: 0.05297393314540386:  37%|███▋      | 257/692 [00:06\u003c00:10, 40.77it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 260 Loss: 12.862878608703614 Accuracy: 0.05443211980164051:  37%|███▋      | 257/692 [00:06\u003c00:10, 40.77it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 260 Loss: 12.862878608703614 Accuracy: 0.05443211980164051:  38%|███▊      | 262/692 [00:06\u003c00:10, 40.70it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 260 Loss: 12.862878608703614 Accuracy: 0.05443211980164051:  39%|███▊      | 267/692 [00:06\u003c00:10, 40.96it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 270 Loss: 12.92698802947998 Accuracy: 0.05378047749400139:  39%|███▊      | 267/692 [00:06\u003c00:10, 40.96it/s] \u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 270 Loss: 12.92698802947998 Accuracy: 0.05378047749400139:  39%|███▉      | 272/692 [00:06\u003c00:10, 40.74it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 270 Loss: 12.92698802947998 Accuracy: 0.05378047749400139:  40%|████      | 277/692 [00:06\u003c00:10, 40.99it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 280 Loss: 12.70367660522461 Accuracy: 0.05208282060921192:  40%|████      | 277/692 [00:06\u003c00:10, 40.99it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 280 Loss: 12.70367660522461 Accuracy: 0.05208282060921192:  41%|████      | 282/692 [00:06\u003c00:10, 40.70it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 280 Loss: 12.70367660522461 Accuracy: 0.05208282060921192:  41%|████▏     | 287/692 [00:07\u003c00:09, 40.97it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 290 Loss: 12.771507167816162 Accuracy: 0.055259060487151145:  41%|████▏     | 287/692 [00:07\u003c00:09, 40.97it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 290 Loss: 12.771507167816162 Accuracy: 0.055259060487151145:  42%|████▏     | 292/692 [00:07\u003c00:09, 40.73it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 290 Loss: 12.771507167816162 Accuracy: 0.055259060487151145:  43%|████▎     | 297/692 [00:07\u003c00:09, 40.93it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 300 Loss: 12.68523530960083 Accuracy: 0.053585491701960565:  43%|████▎     | 297/692 [00:07\u003c00:09, 40.93it/s] \u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 300 Loss: 12.68523530960083 Accuracy: 0.053585491701960565:  44%|████▎     | 302/692 [00:07\u003c00:09, 40.68it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 300 Loss: 12.68523530960083 Accuracy: 0.053585491701960565:  44%|████▍     | 307/692 [00:07\u003c00:09, 40.88it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 310 Loss: 12.730089473724366 Accuracy: 0.050045549869537354:  44%|████▍     | 307/692 [00:07\u003c00:09, 40.88it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 310 Loss: 12.730089473724366 Accuracy: 0.050045549869537354:  45%|████▌     | 312/692 [00:07\u003c00:09, 40.57it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 310 Loss: 12.730089473724366 Accuracy: 0.050045549869537354:  46%|████▌     | 317/692 [00:07\u003c00:09, 40.90it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 320 Loss: 12.767328548431397 Accuracy: 0.052284711971879005:  46%|████▌     | 317/692 [00:07\u003c00:09, 40.90it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 320 Loss: 12.767328548431397 Accuracy: 0.052284711971879005:  47%|████▋     | 322/692 [00:07\u003c00:09, 40.65it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 320 Loss: 12.767328548431397 Accuracy: 0.052284711971879005:  47%|████▋     | 327/692 [00:08\u003c00:08, 40.95it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 330 Loss: 12.650710678100586 Accuracy: 0.054533394426107405:  47%|████▋     | 327/692 [00:08\u003c00:08, 40.95it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 330 Loss: 12.650710678100586 Accuracy: 0.054533394426107405:  48%|████▊     | 332/692 [00:08\u003c00:08, 40.66it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 330 Loss: 12.650710678100586 Accuracy: 0.054533394426107405:  49%|████▊     | 337/692 [00:08\u003c00:08, 40.96it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 340 Loss: 12.75038547515869 Accuracy: 0.05255865752696991:  49%|████▊     | 337/692 [00:08\u003c00:08, 40.96it/s]  \u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 340 Loss: 12.75038547515869 Accuracy: 0.05255865752696991:  49%|████▉     | 342/692 [00:08\u003c00:08, 40.66it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 340 Loss: 12.75038547515869 Accuracy: 0.05255865752696991:  50%|█████     | 347/692 [00:08\u003c00:08, 40.96it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 350 Loss: 12.71516399383545 Accuracy: 0.052533645927906034:  50%|█████     | 347/692 [00:08\u003c00:08, 40.96it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 350 Loss: 12.71516399383545 Accuracy: 0.052533645927906034:  51%|█████     | 352/692 [00:08\u003c00:08, 40.80it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 350 Loss: 12.71516399383545 Accuracy: 0.052533645927906034:  52%|█████▏    | 357/692 [00:08\u003c00:08, 41.01it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 360 Loss: 12.717102146148681 Accuracy: 0.05749349370598793:  52%|█████▏    | 357/692 [00:08\u003c00:08, 41.01it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 360 Loss: 12.717102146148681 Accuracy: 0.05749349370598793:  52%|█████▏    | 362/692 [00:08\u003c00:08, 40.77it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 360 Loss: 12.717102146148681 Accuracy: 0.05749349370598793:  53%|█████▎    | 367/692 [00:08\u003c00:07, 40.94it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 370 Loss: 12.7664475440979 Accuracy: 0.05101665481925011:  53%|█████▎    | 367/692 [00:09\u003c00:07, 40.94it/s]  \u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 370 Loss: 12.7664475440979 Accuracy: 0.05101665481925011:  54%|█████▍    | 372/692 [00:09\u003c00:07, 40.72it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 370 Loss: 12.7664475440979 Accuracy: 0.05101665481925011:  54%|█████▍    | 377/692 [00:09\u003c00:07, 40.98it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 380 Loss: 12.77363748550415 Accuracy: 0.05053943246603012:  54%|█████▍    | 377/692 [00:09\u003c00:07, 40.98it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 380 Loss: 12.77363748550415 Accuracy: 0.05053943246603012:  55%|█████▌    | 382/692 [00:09\u003c00:07, 40.78it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 380 Loss: 12.77363748550415 Accuracy: 0.05053943246603012:  56%|█████▌    | 387/692 [00:09\u003c00:07, 40.94it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 390 Loss: 12.706053256988525 Accuracy: 0.0552687767893076:  56%|█████▌    | 387/692 [00:09\u003c00:07, 40.94it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 390 Loss: 12.706053256988525 Accuracy: 0.0552687767893076:  57%|█████▋    | 392/692 [00:09\u003c00:07, 40.56it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 390 Loss: 12.706053256988525 Accuracy: 0.0552687767893076:  57%|█████▋    | 397/692 [00:09\u003c00:07, 40.75it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 400 Loss: 12.795675468444824 Accuracy: 0.054794353991746904:  57%|█████▋    | 397/692 [00:09\u003c00:07, 40.75it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 400 Loss: 12.795675468444824 Accuracy: 0.054794353991746904:  58%|█████▊    | 402/692 [00:09\u003c00:07, 40.57it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 400 Loss: 12.795675468444824 Accuracy: 0.054794353991746904:  59%|█████▉    | 407/692 [00:09\u003c00:06, 40.79it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 410 Loss: 12.693646812438965 Accuracy: 0.05187459141016006:  59%|█████▉    | 407/692 [00:10\u003c00:06, 40.79it/s] \u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 410 Loss: 12.693646812438965 Accuracy: 0.05187459141016006:  60%|█████▉    | 412/692 [00:10\u003c00:06, 40.42it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 410 Loss: 12.693646812438965 Accuracy: 0.05187459141016006:  60%|██████    | 417/692 [00:10\u003c00:06, 40.69it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 420 Loss: 12.882134914398193 Accuracy: 0.05446132011711598:  60%|██████    | 417/692 [00:10\u003c00:06, 40.69it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 420 Loss: 12.882134914398193 Accuracy: 0.05446132011711598:  61%|██████    | 422/692 [00:10\u003c00:06, 40.50it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 420 Loss: 12.882134914398193 Accuracy: 0.05446132011711598:  62%|██████▏   | 427/692 [00:10\u003c00:06, 40.73it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 430 Loss: 12.767895412445068 Accuracy: 0.05587891675531864:  62%|██████▏   | 427/692 [00:10\u003c00:06, 40.73it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 430 Loss: 12.767895412445068 Accuracy: 0.05587891675531864:  62%|██████▏   | 432/692 [00:10\u003c00:06, 40.41it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 430 Loss: 12.767895412445068 Accuracy: 0.05587891675531864:  63%|██████▎   | 437/692 [00:10\u003c00:06, 40.73it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 440 Loss: 12.638104248046876 Accuracy: 0.055237412452697754:  63%|██████▎   | 437/692 [00:10\u003c00:06, 40.73it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 440 Loss: 12.638104248046876 Accuracy: 0.055237412452697754:  64%|██████▍   | 442/692 [00:10\u003c00:06, 40.44it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 440 Loss: 12.638104248046876 Accuracy: 0.055237412452697754:  65%|██████▍   | 447/692 [00:10\u003c00:06, 40.57it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 450 Loss: 12.671505737304688 Accuracy: 0.05426566451787949:  65%|██████▍   | 447/692 [00:11\u003c00:06, 40.57it/s] \u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 450 Loss: 12.671505737304688 Accuracy: 0.05426566451787949:  65%|██████▌   | 452/692 [00:11\u003c00:05, 40.42it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 450 Loss: 12.671505737304688 Accuracy: 0.05426566451787949:  66%|██████▌   | 457/692 [00:11\u003c00:05, 40.66it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 460 Loss: 12.752573585510254 Accuracy: 0.054959073290228845:  66%|██████▌   | 457/692 [00:11\u003c00:05, 40.66it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 460 Loss: 12.752573585510254 Accuracy: 0.054959073290228845:  67%|██████▋   | 462/692 [00:11\u003c00:05, 40.56it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 460 Loss: 12.752573585510254 Accuracy: 0.054959073290228845:  67%|██████▋   | 467/692 [00:11\u003c00:05, 40.74it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 470 Loss: 12.661398315429688 Accuracy: 0.05327799916267395:  67%|██████▋   | 467/692 [00:11\u003c00:05, 40.74it/s] \u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 470 Loss: 12.661398315429688 Accuracy: 0.05327799916267395:  68%|██████▊   | 472/692 [00:11\u003c00:05, 40.61it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 470 Loss: 12.661398315429688 Accuracy: 0.05327799916267395:  69%|██████▉   | 477/692 [00:11\u003c00:05, 40.81it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 480 Loss: 12.797315216064453 Accuracy: 0.052241894975304605:  69%|██████▉   | 477/692 [00:11\u003c00:05, 40.81it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 480 Loss: 12.797315216064453 Accuracy: 0.052241894975304605:  70%|██████▉   | 482/692 [00:11\u003c00:05, 40.69it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 480 Loss: 12.797315216064453 Accuracy: 0.052241894975304605:  70%|███████   | 487/692 [00:11\u003c00:05, 40.86it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 490 Loss: 12.738812065124511 Accuracy: 0.05273996852338314:  70%|███████   | 487/692 [00:12\u003c00:05, 40.86it/s] \u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 490 Loss: 12.738812065124511 Accuracy: 0.05273996852338314:  71%|███████   | 492/692 [00:12\u003c00:04, 40.59it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 490 Loss: 12.738812065124511 Accuracy: 0.05273996852338314:  72%|███████▏  | 497/692 [00:12\u003c00:04, 40.68it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 500 Loss: 12.871101188659669 Accuracy: 0.05425973683595657:  72%|███████▏  | 497/692 [00:12\u003c00:04, 40.68it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 500 Loss: 12.871101188659669 Accuracy: 0.05425973683595657:  73%|███████▎  | 502/692 [00:12\u003c00:04, 40.61it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 500 Loss: 12.871101188659669 Accuracy: 0.05425973683595657:  73%|███████▎  | 507/692 [00:12\u003c00:04, 40.84it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 510 Loss: 12.833787631988525 Accuracy: 0.05048685856163502:  73%|███████▎  | 507/692 [00:12\u003c00:04, 40.84it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 510 Loss: 12.833787631988525 Accuracy: 0.05048685856163502:  74%|███████▍  | 512/692 [00:12\u003c00:04, 40.74it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 510 Loss: 12.833787631988525 Accuracy: 0.05048685856163502:  75%|███████▍  | 517/692 [00:12\u003c00:04, 40.98it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 520 Loss: 12.664875602722168 Accuracy: 0.05256221666932106:  75%|███████▍  | 517/692 [00:12\u003c00:04, 40.98it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 520 Loss: 12.664875602722168 Accuracy: 0.05256221666932106:  75%|███████▌  | 522/692 [00:12\u003c00:04, 40.62it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 520 Loss: 12.664875602722168 Accuracy: 0.05256221666932106:  76%|███████▌  | 527/692 [00:12\u003c00:04, 40.89it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 530 Loss: 12.510080242156983 Accuracy: 0.053476366028189656:  76%|███████▌  | 527/692 [00:13\u003c00:04, 40.89it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 530 Loss: 12.510080242156983 Accuracy: 0.053476366028189656:  77%|███████▋  | 532/692 [00:13\u003c00:03, 40.75it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 530 Loss: 12.510080242156983 Accuracy: 0.053476366028189656:  78%|███████▊  | 537/692 [00:13\u003c00:03, 40.89it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 540 Loss: 12.708214664459229 Accuracy: 0.05117730014026165:  78%|███████▊  | 537/692 [00:13\u003c00:03, 40.89it/s] \u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 540 Loss: 12.708214664459229 Accuracy: 0.05117730014026165:  78%|███████▊  | 542/692 [00:13\u003c00:03, 40.67it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 540 Loss: 12.708214664459229 Accuracy: 0.05117730014026165:  79%|███████▉  | 547/692 [00:13\u003c00:03, 40.94it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 550 Loss: 12.477083301544189 Accuracy: 0.05164437666535378:  79%|███████▉  | 547/692 [00:13\u003c00:03, 40.94it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 550 Loss: 12.477083301544189 Accuracy: 0.05164437666535378:  80%|███████▉  | 552/692 [00:13\u003c00:03, 40.84it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 550 Loss: 12.477083301544189 Accuracy: 0.05164437666535378:  80%|████████  | 557/692 [00:13\u003c00:03, 40.86it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 560 Loss: 12.728988647460938 Accuracy: 0.055753789469599725:  80%|████████  | 557/692 [00:13\u003c00:03, 40.86it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 560 Loss: 12.728988647460938 Accuracy: 0.055753789469599725:  81%|████████  | 562/692 [00:13\u003c00:03, 40.77it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 560 Loss: 12.728988647460938 Accuracy: 0.055753789469599725:  82%|████████▏ | 567/692 [00:13\u003c00:03, 40.94it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 570 Loss: 12.616395473480225 Accuracy: 0.05095301829278469:  82%|████████▏ | 567/692 [00:14\u003c00:03, 40.94it/s] \u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 570 Loss: 12.616395473480225 Accuracy: 0.05095301829278469:  83%|████████▎ | 572/692 [00:14\u003c00:02, 40.68it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 570 Loss: 12.616395473480225 Accuracy: 0.05095301829278469:  83%|████████▎ | 577/692 [00:14\u003c00:02, 40.88it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 580 Loss: 12.66907844543457 Accuracy: 0.053214342892169954:  83%|████████▎ | 577/692 [00:14\u003c00:02, 40.88it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 580 Loss: 12.66907844543457 Accuracy: 0.053214342892169954:  84%|████████▍ | 582/692 [00:14\u003c00:02, 40.77it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 580 Loss: 12.66907844543457 Accuracy: 0.053214342892169954:  85%|████████▍ | 587/692 [00:14\u003c00:02, 40.85it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 590 Loss: 12.763622093200684 Accuracy: 0.05359994731843472:  85%|████████▍ | 587/692 [00:14\u003c00:02, 40.85it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 590 Loss: 12.763622093200684 Accuracy: 0.05359994731843472:  86%|████████▌ | 592/692 [00:14\u003c00:02, 40.71it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 590 Loss: 12.763622093200684 Accuracy: 0.05359994731843472:  86%|████████▋ | 597/692 [00:14\u003c00:02, 40.86it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 600 Loss: 12.633392810821533 Accuracy: 0.05547122620046139:  86%|████████▋ | 597/692 [00:14\u003c00:02, 40.86it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 600 Loss: 12.633392810821533 Accuracy: 0.05547122620046139:  87%|████████▋ | 602/692 [00:14\u003c00:02, 40.59it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 600 Loss: 12.633392810821533 Accuracy: 0.05547122620046139:  88%|████████▊ | 607/692 [00:14\u003c00:02, 40.78it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 610 Loss: 12.579398918151856 Accuracy: 0.0529269203543663:  88%|████████▊ | 607/692 [00:14\u003c00:02, 40.78it/s] \u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 610 Loss: 12.579398918151856 Accuracy: 0.0529269203543663:  88%|████████▊ | 612/692 [00:15\u003c00:01, 40.52it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 610 Loss: 12.579398918151856 Accuracy: 0.0529269203543663:  89%|████████▉ | 617/692 [00:15\u003c00:01, 40.74it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 620 Loss: 12.655399131774903 Accuracy: 0.05517520718276501:  89%|████████▉ | 617/692 [00:15\u003c00:01, 40.74it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 620 Loss: 12.655399131774903 Accuracy: 0.05517520718276501:  90%|████████▉ | 622/692 [00:15\u003c00:01, 40.60it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 620 Loss: 12.655399131774903 Accuracy: 0.05517520718276501:  91%|█████████ | 627/692 [00:15\u003c00:01, 40.96it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 630 Loss: 12.626664066314698 Accuracy: 0.05285601131618023:  91%|█████████ | 627/692 [00:15\u003c00:01, 40.96it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 630 Loss: 12.626664066314698 Accuracy: 0.05285601131618023:  91%|█████████▏| 632/692 [00:15\u003c00:01, 40.67it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 630 Loss: 12.626664066314698 Accuracy: 0.05285601131618023:  92%|█████████▏| 637/692 [00:15\u003c00:01, 40.90it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 640 Loss: 12.79542646408081 Accuracy: 0.05446098633110523:  92%|█████████▏| 637/692 [00:15\u003c00:01, 40.90it/s] \u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 640 Loss: 12.79542646408081 Accuracy: 0.05446098633110523:  93%|█████████▎| 642/692 [00:15\u003c00:01, 40.69it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 640 Loss: 12.79542646408081 Accuracy: 0.05446098633110523:  93%|█████████▎| 647/692 [00:15\u003c00:01, 40.77it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 650 Loss: 12.87012357711792 Accuracy: 0.05042875856161118:  93%|█████████▎| 647/692 [00:15\u003c00:01, 40.77it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 650 Loss: 12.87012357711792 Accuracy: 0.05042875856161118:  94%|█████████▍| 652/692 [00:16\u003c00:00, 40.59it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 650 Loss: 12.87012357711792 Accuracy: 0.05042875856161118:  95%|█████████▍| 657/692 [00:16\u003c00:00, 40.91it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 660 Loss: 12.697500610351563 Accuracy: 0.05459744147956371:  95%|█████████▍| 657/692 [00:16\u003c00:00, 40.91it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 660 Loss: 12.697500610351563 Accuracy: 0.05459744147956371:  96%|█████████▌| 662/692 [00:16\u003c00:00, 40.66it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 660 Loss: 12.697500610351563 Accuracy: 0.05459744147956371:  96%|█████████▋| 667/692 [00:16\u003c00:00, 40.87it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 670 Loss: 12.661915493011474 Accuracy: 0.05460450351238251:  96%|█████████▋| 667/692 [00:16\u003c00:00, 40.87it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 670 Loss: 12.661915493011474 Accuracy: 0.05460450351238251:  97%|█████████▋| 672/692 [00:16\u003c00:00, 40.58it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 670 Loss: 12.661915493011474 Accuracy: 0.05460450351238251:  98%|█████████▊| 677/692 [00:16\u003c00:00, 40.89it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 680 Loss: 12.606476497650146 Accuracy: 0.05290141180157661:  98%|█████████▊| 677/692 [00:16\u003c00:00, 40.89it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 680 Loss: 12.606476497650146 Accuracy: 0.05290141180157661:  99%|█████████▊| 682/692 [00:16\u003c00:00, 40.80it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 680 Loss: 12.606476497650146 Accuracy: 0.05290141180157661:  99%|█████████▉| 687/692 [00:16\u003c00:00, 41.00it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 690 Loss: 12.616307258605957 Accuracy: 0.05061265155673027:  99%|█████████▉| 687/692 [00:16\u003c00:00, 41.00it/s]\u001b[A\u001b[A\n","\n","Epoch: 2 Iteration: 690 Loss: 12.616307258605957 Accuracy: 0.05061265155673027: 100%|██████████| 692/692 [00:16\u003c00:00, 40.76it/s]\n","\n","\n","  0%|          | 0/692 [00:00\u003c?, ?it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 0 Loss: 12.560483837127686 Accuracy: 0.05035495236515999:   0%|          | 0/692 [00:00\u003c?, ?it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 0 Loss: 12.560483837127686 Accuracy: 0.05035495236515999:   1%|          | 4/692 [00:00\u003c00:17, 39.54it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 0 Loss: 12.560483837127686 Accuracy: 0.05035495236515999:   1%|▏         | 9/692 [00:00\u003c00:17, 40.15it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 10 Loss: 12.800691032409668 Accuracy: 0.0556225098669529:   1%|▏         | 9/692 [00:00\u003c00:17, 40.15it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 10 Loss: 12.800691032409668 Accuracy: 0.0556225098669529:   2%|▏         | 13/692 [00:00\u003c00:17, 39.90it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 10 Loss: 12.800691032409668 Accuracy: 0.0556225098669529:   3%|▎         | 18/692 [00:00\u003c00:16, 40.30it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 20 Loss: 12.616719055175782 Accuracy: 0.05338950268924236:   3%|▎         | 18/692 [00:00\u003c00:16, 40.30it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 20 Loss: 12.616719055175782 Accuracy: 0.05338950268924236:   3%|▎         | 22/692 [00:00\u003c00:16, 40.17it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 20 Loss: 12.616719055175782 Accuracy: 0.05338950268924236:   4%|▍         | 27/692 [00:00\u003c00:16, 40.47it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 30 Loss: 12.747662544250488 Accuracy: 0.05281131081283093:   4%|▍         | 27/692 [00:00\u003c00:16, 40.47it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 30 Loss: 12.747662544250488 Accuracy: 0.05281131081283093:   5%|▍         | 32/692 [00:00\u003c00:16, 40.49it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 30 Loss: 12.747662544250488 Accuracy: 0.05281131081283093:   5%|▌         | 37/692 [00:00\u003c00:16, 40.74it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 40 Loss: 12.729359340667724 Accuracy: 0.04664753004908562:   5%|▌         | 37/692 [00:01\u003c00:16, 40.74it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 40 Loss: 12.729359340667724 Accuracy: 0.04664753004908562:   6%|▌         | 42/692 [00:01\u003c00:16, 40.61it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 40 Loss: 12.729359340667724 Accuracy: 0.04664753004908562:   7%|▋         | 47/692 [00:01\u003c00:15, 40.85it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 50 Loss: 12.593835163116456 Accuracy: 0.055246947705745696:   7%|▋         | 47/692 [00:01\u003c00:15, 40.85it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 50 Loss: 12.593835163116456 Accuracy: 0.055246947705745696:   8%|▊         | 52/692 [00:01\u003c00:15, 40.63it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 50 Loss: 12.593835163116456 Accuracy: 0.055246947705745696:   8%|▊         | 57/692 [00:01\u003c00:15, 40.84it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 60 Loss: 12.664655494689942 Accuracy: 0.05676824077963829:   8%|▊         | 57/692 [00:01\u003c00:15, 40.84it/s] \u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 60 Loss: 12.664655494689942 Accuracy: 0.05676824077963829:   9%|▉         | 62/692 [00:01\u003c00:15, 40.60it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 60 Loss: 12.664655494689942 Accuracy: 0.05676824077963829:  10%|▉         | 67/692 [00:01\u003c00:15, 40.92it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 70 Loss: 12.601146793365478 Accuracy: 0.054367874190211295:  10%|▉         | 67/692 [00:01\u003c00:15, 40.92it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 70 Loss: 12.601146793365478 Accuracy: 0.054367874190211295:  10%|█         | 72/692 [00:01\u003c00:15, 40.55it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 70 Loss: 12.601146793365478 Accuracy: 0.054367874190211295:  11%|█         | 77/692 [00:01\u003c00:15, 40.78it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 80 Loss: 12.596583080291747 Accuracy: 0.05140982307493687:  11%|█         | 77/692 [00:01\u003c00:15, 40.78it/s] \u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 80 Loss: 12.596583080291747 Accuracy: 0.05140982307493687:  12%|█▏        | 82/692 [00:02\u003c00:15, 40.63it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 80 Loss: 12.596583080291747 Accuracy: 0.05140982307493687:  13%|█▎        | 87/692 [00:02\u003c00:14, 40.81it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 90 Loss: 12.670079612731934 Accuracy: 0.052661313116550444:  13%|█▎        | 87/692 [00:02\u003c00:14, 40.81it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 90 Loss: 12.670079612731934 Accuracy: 0.052661313116550444:  13%|█▎        | 92/692 [00:02\u003c00:14, 40.68it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 90 Loss: 12.670079612731934 Accuracy: 0.052661313116550444:  14%|█▍        | 97/692 [00:02\u003c00:14, 40.83it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 100 Loss: 12.757014274597168 Accuracy: 0.05288487337529659:  14%|█▍        | 97/692 [00:02\u003c00:14, 40.83it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 100 Loss: 12.757014274597168 Accuracy: 0.05288487337529659:  15%|█▍        | 102/692 [00:02\u003c00:14, 40.74it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 100 Loss: 12.757014274597168 Accuracy: 0.05288487337529659:  15%|█▌        | 107/692 [00:02\u003c00:14, 41.08it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 110 Loss: 12.690418720245361 Accuracy: 0.05487042181193828:  15%|█▌        | 107/692 [00:02\u003c00:14, 41.08it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 110 Loss: 12.690418720245361 Accuracy: 0.05487042181193828:  16%|█▌        | 112/692 [00:02\u003c00:14, 40.76it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 110 Loss: 12.690418720245361 Accuracy: 0.05487042181193828:  17%|█▋        | 117/692 [00:02\u003c00:14, 40.72it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 120 Loss: 12.724915790557862 Accuracy: 0.053100839257240295:  17%|█▋        | 117/692 [00:02\u003c00:14, 40.72it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 120 Loss: 12.724915790557862 Accuracy: 0.053100839257240295:  18%|█▊        | 122/692 [00:02\u003c00:14, 40.50it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 120 Loss: 12.724915790557862 Accuracy: 0.053100839257240295:  18%|█▊        | 127/692 [00:03\u003c00:13, 40.92it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 130 Loss: 12.740764141082764 Accuracy: 0.05504263415932655:  18%|█▊        | 127/692 [00:03\u003c00:13, 40.92it/s] \u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 130 Loss: 12.740764141082764 Accuracy: 0.05504263415932655:  19%|█▉        | 132/692 [00:03\u003c00:13, 40.77it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 130 Loss: 12.740764141082764 Accuracy: 0.05504263415932655:  20%|█▉        | 137/692 [00:03\u003c00:13, 40.96it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 140 Loss: 12.58278293609619 Accuracy: 0.0526616383343935:  20%|█▉        | 137/692 [00:03\u003c00:13, 40.96it/s]  \u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 140 Loss: 12.58278293609619 Accuracy: 0.0526616383343935:  21%|██        | 142/692 [00:03\u003c00:13, 40.75it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 140 Loss: 12.58278293609619 Accuracy: 0.0526616383343935:  21%|██        | 147/692 [00:03\u003c00:13, 40.84it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 150 Loss: 12.640901565551758 Accuracy: 0.05721246637403965:  21%|██        | 147/692 [00:03\u003c00:13, 40.84it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 150 Loss: 12.640901565551758 Accuracy: 0.05721246637403965:  22%|██▏       | 152/692 [00:03\u003c00:13, 40.71it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 150 Loss: 12.640901565551758 Accuracy: 0.05721246637403965:  23%|██▎       | 157/692 [00:03\u003c00:13, 41.01it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 160 Loss: 12.801226615905762 Accuracy: 0.054428495839238165:  23%|██▎       | 157/692 [00:03\u003c00:13, 41.01it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 160 Loss: 12.801226615905762 Accuracy: 0.054428495839238165:  23%|██▎       | 162/692 [00:03\u003c00:12, 40.87it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 160 Loss: 12.801226615905762 Accuracy: 0.054428495839238165:  24%|██▍       | 167/692 [00:04\u003c00:12, 41.06it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 170 Loss: 12.697179698944092 Accuracy: 0.05487359240651131:  24%|██▍       | 167/692 [00:04\u003c00:12, 41.06it/s] \u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 170 Loss: 12.697179698944092 Accuracy: 0.05487359240651131:  25%|██▍       | 172/692 [00:04\u003c00:12, 40.76it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 170 Loss: 12.697179698944092 Accuracy: 0.05487359240651131:  26%|██▌       | 177/692 [00:04\u003c00:12, 40.94it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 180 Loss: 12.786151313781739 Accuracy: 0.05187919773161411:  26%|██▌       | 177/692 [00:04\u003c00:12, 40.94it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 180 Loss: 12.786151313781739 Accuracy: 0.05187919773161411:  26%|██▋       | 182/692 [00:04\u003c00:12, 40.69it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 180 Loss: 12.786151313781739 Accuracy: 0.05187919773161411:  27%|██▋       | 187/692 [00:04\u003c00:12, 40.76it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 190 Loss: 12.52415657043457 Accuracy: 0.05144765414297581:  27%|██▋       | 187/692 [00:04\u003c00:12, 40.76it/s] \u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 190 Loss: 12.52415657043457 Accuracy: 0.05144765414297581:  28%|██▊       | 192/692 [00:04\u003c00:12, 40.69it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 190 Loss: 12.52415657043457 Accuracy: 0.05144765414297581:  28%|██▊       | 197/692 [00:04\u003c00:12, 40.95it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 200 Loss: 12.624748516082764 Accuracy: 0.05667018927633762:  28%|██▊       | 197/692 [00:04\u003c00:12, 40.95it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 200 Loss: 12.624748516082764 Accuracy: 0.05667018927633762:  29%|██▉       | 202/692 [00:04\u003c00:12, 40.57it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 200 Loss: 12.624748516082764 Accuracy: 0.05667018927633762:  30%|██▉       | 207/692 [00:05\u003c00:11, 40.49it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 210 Loss: 12.778764820098877 Accuracy: 0.053601904213428496:  30%|██▉       | 207/692 [00:05\u003c00:11, 40.49it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 210 Loss: 12.778764820098877 Accuracy: 0.053601904213428496:  31%|███       | 212/692 [00:05\u003c00:11, 40.44it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 210 Loss: 12.778764820098877 Accuracy: 0.053601904213428496:  31%|███▏      | 217/692 [00:05\u003c00:11, 40.66it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 220 Loss: 12.77264404296875 Accuracy: 0.04956255704164505:  31%|███▏      | 217/692 [00:05\u003c00:11, 40.66it/s]  \u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 220 Loss: 12.77264404296875 Accuracy: 0.04956255704164505:  32%|███▏      | 222/692 [00:05\u003c00:11, 40.46it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 220 Loss: 12.77264404296875 Accuracy: 0.04956255704164505:  33%|███▎      | 227/692 [00:05\u003c00:11, 40.75it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 230 Loss: 12.713090705871583 Accuracy: 0.05209138356149197:  33%|███▎      | 227/692 [00:05\u003c00:11, 40.75it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 230 Loss: 12.713090705871583 Accuracy: 0.05209138356149197:  34%|███▎      | 232/692 [00:05\u003c00:11, 40.66it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 230 Loss: 12.713090705871583 Accuracy: 0.05209138356149197:  34%|███▍      | 237/692 [00:05\u003c00:11, 40.85it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 240 Loss: 12.835575675964355 Accuracy: 0.05166740193963051:  34%|███▍      | 237/692 [00:05\u003c00:11, 40.85it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 240 Loss: 12.835575675964355 Accuracy: 0.05166740193963051:  35%|███▍      | 242/692 [00:05\u003c00:11, 40.49it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 240 Loss: 12.835575675964355 Accuracy: 0.05166740193963051:  36%|███▌      | 247/692 [00:06\u003c00:10, 40.74it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 250 Loss: 12.727126979827881 Accuracy: 0.053120467066764834:  36%|███▌      | 247/692 [00:06\u003c00:10, 40.74it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 250 Loss: 12.727126979827881 Accuracy: 0.053120467066764834:  36%|███▋      | 252/692 [00:06\u003c00:10, 40.62it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 250 Loss: 12.727126979827881 Accuracy: 0.053120467066764834:  37%|███▋      | 257/692 [00:06\u003c00:10, 40.97it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 260 Loss: 12.574639797210693 Accuracy: 0.05212595984339714:  37%|███▋      | 257/692 [00:06\u003c00:10, 40.97it/s] \u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 260 Loss: 12.574639797210693 Accuracy: 0.05212595984339714:  38%|███▊      | 262/692 [00:06\u003c00:10, 40.71it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 260 Loss: 12.574639797210693 Accuracy: 0.05212595984339714:  39%|███▊      | 267/692 [00:06\u003c00:10, 40.85it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 270 Loss: 12.731130123138428 Accuracy: 0.05631418377161026:  39%|███▊      | 267/692 [00:06\u003c00:10, 40.85it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 270 Loss: 12.731130123138428 Accuracy: 0.05631418377161026:  39%|███▉      | 272/692 [00:06\u003c00:10, 40.57it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 270 Loss: 12.731130123138428 Accuracy: 0.05631418377161026:  40%|████      | 277/692 [00:06\u003c00:10, 40.72it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 280 Loss: 12.756066513061523 Accuracy: 0.05747435800731182:  40%|████      | 277/692 [00:06\u003c00:10, 40.72it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 280 Loss: 12.756066513061523 Accuracy: 0.05747435800731182:  41%|████      | 282/692 [00:06\u003c00:10, 40.68it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 280 Loss: 12.756066513061523 Accuracy: 0.05747435800731182:  41%|████▏     | 287/692 [00:07\u003c00:09, 40.86it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 290 Loss: 12.724289703369141 Accuracy: 0.053167454153299334:  41%|████▏     | 287/692 [00:07\u003c00:09, 40.86it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 290 Loss: 12.724289703369141 Accuracy: 0.053167454153299334:  42%|████▏     | 292/692 [00:07\u003c00:09, 40.63it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 290 Loss: 12.724289703369141 Accuracy: 0.053167454153299334:  43%|████▎     | 297/692 [00:07\u003c00:09, 40.82it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 300 Loss: 12.675229167938232 Accuracy: 0.05305245406925678:  43%|████▎     | 297/692 [00:07\u003c00:09, 40.82it/s] \u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 300 Loss: 12.675229167938232 Accuracy: 0.05305245406925678:  44%|████▎     | 302/692 [00:07\u003c00:09, 40.54it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 300 Loss: 12.675229167938232 Accuracy: 0.05305245406925678:  44%|████▍     | 307/692 [00:07\u003c00:09, 40.63it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 310 Loss: 12.750669384002686 Accuracy: 0.05353781916201115:  44%|████▍     | 307/692 [00:07\u003c00:09, 40.63it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 310 Loss: 12.750669384002686 Accuracy: 0.05353781916201115:  45%|████▌     | 312/692 [00:07\u003c00:09, 40.53it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 310 Loss: 12.750669384002686 Accuracy: 0.05353781916201115:  46%|████▌     | 317/692 [00:07\u003c00:09, 40.73it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 320 Loss: 12.792403507232667 Accuracy: 0.05667142122983933:  46%|████▌     | 317/692 [00:07\u003c00:09, 40.73it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 320 Loss: 12.792403507232667 Accuracy: 0.05667142122983933:  47%|████▋     | 322/692 [00:07\u003c00:09, 40.57it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 320 Loss: 12.792403507232667 Accuracy: 0.05667142122983933:  47%|████▋     | 327/692 [00:08\u003c00:08, 40.79it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 330 Loss: 12.837393379211425 Accuracy: 0.054154800996184346:  47%|████▋     | 327/692 [00:08\u003c00:08, 40.79it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 330 Loss: 12.837393379211425 Accuracy: 0.054154800996184346:  48%|████▊     | 332/692 [00:08\u003c00:08, 40.56it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 330 Loss: 12.837393379211425 Accuracy: 0.054154800996184346:  49%|████▊     | 337/692 [00:08\u003c00:08, 40.85it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 340 Loss: 12.773163604736329 Accuracy: 0.05598459281027317:  49%|████▊     | 337/692 [00:08\u003c00:08, 40.85it/s] \u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 340 Loss: 12.773163604736329 Accuracy: 0.05598459281027317:  49%|████▉     | 342/692 [00:08\u003c00:08, 40.56it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 340 Loss: 12.773163604736329 Accuracy: 0.05598459281027317:  50%|█████     | 347/692 [00:08\u003c00:08, 40.81it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 350 Loss: 12.609218120574951 Accuracy: 0.05146487168967724:  50%|█████     | 347/692 [00:08\u003c00:08, 40.81it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 350 Loss: 12.609218120574951 Accuracy: 0.05146487168967724:  51%|█████     | 352/692 [00:08\u003c00:08, 40.63it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 350 Loss: 12.609218120574951 Accuracy: 0.05146487168967724:  52%|█████▏    | 357/692 [00:08\u003c00:08, 40.87it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 360 Loss: 12.73993730545044 Accuracy: 0.053515872359275816:  52%|█████▏    | 357/692 [00:08\u003c00:08, 40.87it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 360 Loss: 12.73993730545044 Accuracy: 0.053515872359275816:  52%|█████▏    | 362/692 [00:08\u003c00:08, 40.74it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 360 Loss: 12.73993730545044 Accuracy: 0.053515872359275816:  53%|█████▎    | 367/692 [00:09\u003c00:07, 40.86it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 370 Loss: 12.709673404693604 Accuracy: 0.05229412950575352:  53%|█████▎    | 367/692 [00:09\u003c00:07, 40.86it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 370 Loss: 12.709673404693604 Accuracy: 0.05229412950575352:  54%|█████▍    | 372/692 [00:09\u003c00:07, 40.77it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 370 Loss: 12.709673404693604 Accuracy: 0.05229412950575352:  54%|█████▍    | 377/692 [00:09\u003c00:07, 40.99it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 380 Loss: 12.697078323364257 Accuracy: 0.05587448552250862:  54%|█████▍    | 377/692 [00:09\u003c00:07, 40.99it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 380 Loss: 12.697078323364257 Accuracy: 0.05587448552250862:  55%|█████▌    | 382/692 [00:09\u003c00:07, 40.62it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 380 Loss: 12.697078323364257 Accuracy: 0.05587448552250862:  56%|█████▌    | 387/692 [00:09\u003c00:07, 40.61it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 390 Loss: 12.719135570526124 Accuracy: 0.054892598092556:  56%|█████▌    | 387/692 [00:09\u003c00:07, 40.61it/s]  \u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 390 Loss: 12.719135570526124 Accuracy: 0.054892598092556:  57%|█████▋    | 392/692 [00:09\u003c00:07, 40.38it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 390 Loss: 12.719135570526124 Accuracy: 0.054892598092556:  57%|█████▋    | 397/692 [00:09\u003c00:07, 40.34it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 400 Loss: 12.835198497772216 Accuracy: 0.05288128405809402:  57%|█████▋    | 397/692 [00:09\u003c00:07, 40.34it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 400 Loss: 12.835198497772216 Accuracy: 0.05288128405809402:  58%|█████▊    | 402/692 [00:09\u003c00:07, 39.86it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 400 Loss: 12.835198497772216 Accuracy: 0.05288128405809402:  59%|█████▉    | 407/692 [00:10\u003c00:07, 40.14it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 410 Loss: 12.849392890930176 Accuracy: 0.05149106234312058:  59%|█████▉    | 407/692 [00:10\u003c00:07, 40.14it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 410 Loss: 12.849392890930176 Accuracy: 0.05149106234312058:  60%|█████▉    | 412/692 [00:10\u003c00:07, 39.80it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 410 Loss: 12.849392890930176 Accuracy: 0.05149106234312058:  60%|██████    | 417/692 [00:10\u003c00:06, 40.02it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 420 Loss: 12.631319141387939 Accuracy: 0.04997639991343021:  60%|██████    | 417/692 [00:10\u003c00:06, 40.02it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 420 Loss: 12.631319141387939 Accuracy: 0.04997639991343021:  61%|██████    | 422/692 [00:10\u003c00:06, 39.87it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 420 Loss: 12.631319141387939 Accuracy: 0.04997639991343021:  62%|██████▏   | 427/692 [00:10\u003c00:06, 40.02it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 430 Loss: 12.720993518829346 Accuracy: 0.052586861327290534:  62%|██████▏   | 427/692 [00:10\u003c00:06, 40.02it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 430 Loss: 12.720993518829346 Accuracy: 0.052586861327290534:  62%|██████▏   | 432/692 [00:10\u003c00:06, 39.88it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 430 Loss: 12.720993518829346 Accuracy: 0.052586861327290534:  63%|██████▎   | 437/692 [00:10\u003c00:06, 40.21it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 440 Loss: 12.647198581695557 Accuracy: 0.050701822713017465:  63%|██████▎   | 437/692 [00:10\u003c00:06, 40.21it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 440 Loss: 12.647198581695557 Accuracy: 0.050701822713017465:  64%|██████▍   | 442/692 [00:10\u003c00:06, 39.91it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 440 Loss: 12.647198581695557 Accuracy: 0.050701822713017465:  65%|██████▍   | 447/692 [00:11\u003c00:06, 40.22it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 450 Loss: 12.781535148620605 Accuracy: 0.05356593616306782:  65%|██████▍   | 447/692 [00:11\u003c00:06, 40.22it/s] \u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 450 Loss: 12.781535148620605 Accuracy: 0.05356593616306782:  65%|██████▌   | 452/692 [00:11\u003c00:05, 40.11it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 450 Loss: 12.781535148620605 Accuracy: 0.05356593616306782:  66%|██████▌   | 457/692 [00:11\u003c00:05, 40.45it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 460 Loss: 12.6197940826416 Accuracy: 0.05119475722312927:  66%|██████▌   | 457/692 [00:11\u003c00:05, 40.45it/s]  \u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 460 Loss: 12.6197940826416 Accuracy: 0.05119475722312927:  67%|██████▋   | 462/692 [00:11\u003c00:05, 40.25it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 460 Loss: 12.6197940826416 Accuracy: 0.05119475722312927:  67%|██████▋   | 467/692 [00:11\u003c00:05, 40.50it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 470 Loss: 12.779560375213624 Accuracy: 0.055246970430016515:  67%|██████▋   | 467/692 [00:11\u003c00:05, 40.50it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 470 Loss: 12.779560375213624 Accuracy: 0.055246970430016515:  68%|██████▊   | 472/692 [00:11\u003c00:05, 39.99it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 470 Loss: 12.779560375213624 Accuracy: 0.055246970430016515:  69%|██████▉   | 477/692 [00:11\u003c00:05, 40.32it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 480 Loss: 12.925778198242188 Accuracy: 0.050328349322080614:  69%|██████▉   | 477/692 [00:11\u003c00:05, 40.32it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 480 Loss: 12.925778198242188 Accuracy: 0.050328349322080614:  70%|██████▉   | 482/692 [00:11\u003c00:05, 40.24it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 480 Loss: 12.925778198242188 Accuracy: 0.050328349322080614:  70%|███████   | 487/692 [00:11\u003c00:05, 40.56it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 490 Loss: 12.676650428771973 Accuracy: 0.05472812056541443:  70%|███████   | 487/692 [00:12\u003c00:05, 40.56it/s] \u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 490 Loss: 12.676650428771973 Accuracy: 0.05472812056541443:  71%|███████   | 492/692 [00:12\u003c00:04, 40.13it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 490 Loss: 12.676650428771973 Accuracy: 0.05472812056541443:  72%|███████▏  | 497/692 [00:12\u003c00:04, 40.13it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 500 Loss: 12.721609115600586 Accuracy: 0.05426016412675381:  72%|███████▏  | 497/692 [00:12\u003c00:04, 40.13it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 500 Loss: 12.721609115600586 Accuracy: 0.05426016412675381:  73%|███████▎  | 502/692 [00:12\u003c00:04, 39.83it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 500 Loss: 12.721609115600586 Accuracy: 0.05426016412675381:  73%|███████▎  | 507/692 [00:12\u003c00:04, 40.12it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 510 Loss: 12.794641304016114 Accuracy: 0.053326663374900815:  73%|███████▎  | 507/692 [00:12\u003c00:04, 40.12it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 510 Loss: 12.794641304016114 Accuracy: 0.053326663374900815:  74%|███████▍  | 512/692 [00:12\u003c00:04, 39.98it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 510 Loss: 12.794641304016114 Accuracy: 0.053326663374900815:  75%|███████▍  | 517/692 [00:12\u003c00:04, 40.23it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 520 Loss: 12.687454891204833 Accuracy: 0.05512783750891685:  75%|███████▍  | 517/692 [00:12\u003c00:04, 40.23it/s] \u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 520 Loss: 12.687454891204833 Accuracy: 0.05512783750891685:  75%|███████▌  | 522/692 [00:12\u003c00:04, 39.98it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 520 Loss: 12.687454891204833 Accuracy: 0.05512783750891685:  76%|███████▌  | 527/692 [00:12\u003c00:04, 40.36it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 530 Loss: 12.711488342285156 Accuracy: 0.05217880755662918:  76%|███████▌  | 527/692 [00:13\u003c00:04, 40.36it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 530 Loss: 12.711488342285156 Accuracy: 0.05217880755662918:  77%|███████▋  | 532/692 [00:13\u003c00:03, 40.28it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 530 Loss: 12.711488342285156 Accuracy: 0.05217880755662918:  78%|███████▊  | 537/692 [00:13\u003c00:03, 40.47it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 540 Loss: 12.748448181152344 Accuracy: 0.05312041081488132:  78%|███████▊  | 537/692 [00:13\u003c00:03, 40.47it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 540 Loss: 12.748448181152344 Accuracy: 0.05312041081488132:  78%|███████▊  | 542/692 [00:13\u003c00:03, 40.41it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 540 Loss: 12.748448181152344 Accuracy: 0.05312041081488132:  79%|███████▉  | 547/692 [00:13\u003c00:03, 40.61it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 550 Loss: 12.820730113983155 Accuracy: 0.051774942129850385:  79%|███████▉  | 547/692 [00:13\u003c00:03, 40.61it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 550 Loss: 12.820730113983155 Accuracy: 0.051774942129850385:  80%|███████▉  | 552/692 [00:13\u003c00:03, 40.50it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 550 Loss: 12.820730113983155 Accuracy: 0.051774942129850385:  80%|████████  | 557/692 [00:13\u003c00:03, 40.71it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 560 Loss: 12.41655855178833 Accuracy: 0.0568638376891613:  80%|████████  | 557/692 [00:13\u003c00:03, 40.71it/s]   \u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 560 Loss: 12.41655855178833 Accuracy: 0.0568638376891613:  81%|████████  | 562/692 [00:13\u003c00:03, 40.59it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 560 Loss: 12.41655855178833 Accuracy: 0.0568638376891613:  82%|████████▏ | 567/692 [00:13\u003c00:03, 40.88it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 570 Loss: 12.604436683654786 Accuracy: 0.05552784875035286:  82%|████████▏ | 567/692 [00:14\u003c00:03, 40.88it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 570 Loss: 12.604436683654786 Accuracy: 0.05552784875035286:  83%|████████▎ | 572/692 [00:14\u003c00:02, 40.55it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 570 Loss: 12.604436683654786 Accuracy: 0.05552784875035286:  83%|████████▎ | 577/692 [00:14\u003c00:02, 40.47it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 580 Loss: 12.833435440063477 Accuracy: 0.05155390650033951:  83%|████████▎ | 577/692 [00:14\u003c00:02, 40.47it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 580 Loss: 12.833435440063477 Accuracy: 0.05155390650033951:  84%|████████▍ | 582/692 [00:14\u003c00:02, 40.51it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 580 Loss: 12.833435440063477 Accuracy: 0.05155390650033951:  85%|████████▍ | 587/692 [00:14\u003c00:02, 40.78it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 590 Loss: 12.65350866317749 Accuracy: 0.05439270734786987:  85%|████████▍ | 587/692 [00:14\u003c00:02, 40.78it/s] \u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 590 Loss: 12.65350866317749 Accuracy: 0.05439270734786987:  86%|████████▌ | 592/692 [00:14\u003c00:02, 40.55it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 590 Loss: 12.65350866317749 Accuracy: 0.05439270734786987:  86%|████████▋ | 597/692 [00:14\u003c00:02, 40.79it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 600 Loss: 12.827880001068115 Accuracy: 0.046599550917744634:  86%|████████▋ | 597/692 [00:14\u003c00:02, 40.79it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 600 Loss: 12.827880001068115 Accuracy: 0.046599550917744634:  87%|████████▋ | 602/692 [00:14\u003c00:02, 40.59it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 600 Loss: 12.827880001068115 Accuracy: 0.046599550917744634:  88%|████████▊ | 607/692 [00:14\u003c00:02, 40.85it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 610 Loss: 12.72657356262207 Accuracy: 0.054531675577163694:  88%|████████▊ | 607/692 [00:15\u003c00:02, 40.85it/s] \u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 610 Loss: 12.72657356262207 Accuracy: 0.054531675577163694:  88%|████████▊ | 612/692 [00:15\u003c00:01, 40.60it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 610 Loss: 12.72657356262207 Accuracy: 0.054531675577163694:  89%|████████▉ | 617/692 [00:15\u003c00:01, 40.82it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 620 Loss: 12.780707359313965 Accuracy: 0.04924345500767231:  89%|████████▉ | 617/692 [00:15\u003c00:01, 40.82it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 620 Loss: 12.780707359313965 Accuracy: 0.04924345500767231:  90%|████████▉ | 622/692 [00:15\u003c00:01, 40.63it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 620 Loss: 12.780707359313965 Accuracy: 0.04924345500767231:  91%|█████████ | 627/692 [00:15\u003c00:01, 40.86it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 630 Loss: 12.846758079528808 Accuracy: 0.05723499543964863:  91%|█████████ | 627/692 [00:15\u003c00:01, 40.86it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 630 Loss: 12.846758079528808 Accuracy: 0.05723499543964863:  91%|█████████▏| 632/692 [00:15\u003c00:01, 40.72it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 630 Loss: 12.846758079528808 Accuracy: 0.05723499543964863:  92%|█████████▏| 637/692 [00:15\u003c00:01, 40.90it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 640 Loss: 12.64080743789673 Accuracy: 0.05547510944306851:  92%|█████████▏| 637/692 [00:15\u003c00:01, 40.90it/s] \u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 640 Loss: 12.64080743789673 Accuracy: 0.05547510944306851:  93%|█████████▎| 642/692 [00:15\u003c00:01, 40.74it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 640 Loss: 12.64080743789673 Accuracy: 0.05547510944306851:  93%|█████████▎| 647/692 [00:15\u003c00:01, 40.91it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 650 Loss: 12.665838146209717 Accuracy: 0.05316593088209629:  93%|█████████▎| 647/692 [00:16\u003c00:01, 40.91it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 650 Loss: 12.665838146209717 Accuracy: 0.05316593088209629:  94%|█████████▍| 652/692 [00:16\u003c00:00, 40.67it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 650 Loss: 12.665838146209717 Accuracy: 0.05316593088209629:  95%|█████████▍| 657/692 [00:16\u003c00:00, 40.88it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 660 Loss: 12.511439800262451 Accuracy: 0.05144505687057972:  95%|█████████▍| 657/692 [00:16\u003c00:00, 40.88it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 660 Loss: 12.511439800262451 Accuracy: 0.05144505687057972:  96%|█████████▌| 662/692 [00:16\u003c00:00, 40.65it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 660 Loss: 12.511439800262451 Accuracy: 0.05144505687057972:  96%|█████████▋| 667/692 [00:16\u003c00:00, 40.90it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 670 Loss: 12.643196868896485 Accuracy: 0.05415666289627552:  96%|█████████▋| 667/692 [00:16\u003c00:00, 40.90it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 670 Loss: 12.643196868896485 Accuracy: 0.05415666289627552:  97%|█████████▋| 672/692 [00:16\u003c00:00, 40.62it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 670 Loss: 12.643196868896485 Accuracy: 0.05415666289627552:  98%|█████████▊| 677/692 [00:16\u003c00:00, 40.56it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 680 Loss: 12.655769157409669 Accuracy: 0.05116121545433998:  98%|█████████▊| 677/692 [00:16\u003c00:00, 40.56it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 680 Loss: 12.655769157409669 Accuracy: 0.05116121545433998:  99%|█████████▊| 682/692 [00:16\u003c00:00, 40.56it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 680 Loss: 12.655769157409669 Accuracy: 0.05116121545433998:  99%|█████████▉| 687/692 [00:16\u003c00:00, 40.74it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 690 Loss: 12.609708786010742 Accuracy: 0.053828368335962294:  99%|█████████▉| 687/692 [00:17\u003c00:00, 40.74it/s]\u001b[A\u001b[A\n","\n","Epoch: 3 Iteration: 690 Loss: 12.609708786010742 Accuracy: 0.053828368335962294: 100%|██████████| 692/692 [00:17\u003c00:00, 40.59it/s]\n","\n","\n","  0%|          | 0/692 [00:00\u003c?, ?it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 0 Loss: 12.673434162139893 Accuracy: 0.05362029112875462:   0%|          | 0/692 [00:00\u003c?, ?it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 0 Loss: 12.673434162139893 Accuracy: 0.05362029112875462:   1%|          | 4/692 [00:00\u003c00:17, 39.71it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 0 Loss: 12.673434162139893 Accuracy: 0.05362029112875462:   1%|▏         | 9/692 [00:00\u003c00:16, 40.24it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 10 Loss: 12.539170742034912 Accuracy: 0.052795940265059474:   1%|▏         | 9/692 [00:00\u003c00:16, 40.24it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 10 Loss: 12.539170742034912 Accuracy: 0.052795940265059474:   2%|▏         | 14/692 [00:00\u003c00:16, 40.35it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 10 Loss: 12.539170742034912 Accuracy: 0.052795940265059474:   3%|▎         | 19/692 [00:00\u003c00:16, 40.67it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 20 Loss: 12.902285861968995 Accuracy: 0.05349198430776596:   3%|▎         | 19/692 [00:00\u003c00:16, 40.67it/s] \u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 20 Loss: 12.902285861968995 Accuracy: 0.05349198430776596:   3%|▎         | 23/692 [00:00\u003c00:16, 40.29it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 20 Loss: 12.902285861968995 Accuracy: 0.05349198430776596:   4%|▍         | 28/692 [00:00\u003c00:16, 40.56it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 30 Loss: 12.634966850280762 Accuracy: 0.05346323885023594:   4%|▍         | 28/692 [00:00\u003c00:16, 40.56it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 30 Loss: 12.634966850280762 Accuracy: 0.05346323885023594:   5%|▍         | 32/692 [00:00\u003c00:16, 40.22it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 30 Loss: 12.634966850280762 Accuracy: 0.05346323885023594:   5%|▌         | 37/692 [00:00\u003c00:16, 40.52it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 40 Loss: 12.68912992477417 Accuracy: 0.051405898109078405:   5%|▌         | 37/692 [00:01\u003c00:16, 40.52it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 40 Loss: 12.68912992477417 Accuracy: 0.051405898109078405:   6%|▌         | 42/692 [00:01\u003c00:16, 40.35it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 40 Loss: 12.68912992477417 Accuracy: 0.051405898109078405:   7%|▋         | 47/692 [00:01\u003c00:15, 40.65it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 50 Loss: 12.656461048126221 Accuracy: 0.05099915601313114:   7%|▋         | 47/692 [00:01\u003c00:15, 40.65it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 50 Loss: 12.656461048126221 Accuracy: 0.05099915601313114:   8%|▊         | 52/692 [00:01\u003c00:15, 40.61it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 50 Loss: 12.656461048126221 Accuracy: 0.05099915601313114:   8%|▊         | 57/692 [00:01\u003c00:15, 40.85it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 60 Loss: 12.838836574554444 Accuracy: 0.053093739598989484:   8%|▊         | 57/692 [00:01\u003c00:15, 40.85it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 60 Loss: 12.838836574554444 Accuracy: 0.053093739598989484:   9%|▉         | 62/692 [00:01\u003c00:15, 40.51it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 60 Loss: 12.838836574554444 Accuracy: 0.053093739598989484:  10%|▉         | 67/692 [00:01\u003c00:15, 40.81it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 70 Loss: 12.48984727859497 Accuracy: 0.055261262133717536:  10%|▉         | 67/692 [00:01\u003c00:15, 40.81it/s] \u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 70 Loss: 12.48984727859497 Accuracy: 0.055261262133717536:  10%|█         | 72/692 [00:01\u003c00:15, 40.72it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 70 Loss: 12.48984727859497 Accuracy: 0.055261262133717536:  11%|█         | 77/692 [00:01\u003c00:15, 40.91it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 80 Loss: 12.950187397003173 Accuracy: 0.051590701937675475:  11%|█         | 77/692 [00:01\u003c00:15, 40.91it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 80 Loss: 12.950187397003173 Accuracy: 0.051590701937675475:  12%|█▏        | 82/692 [00:02\u003c00:14, 40.77it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 80 Loss: 12.950187397003173 Accuracy: 0.051590701937675475:  13%|█▎        | 87/692 [00:02\u003c00:14, 40.95it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 90 Loss: 12.876619434356689 Accuracy: 0.05330784358084202:  13%|█▎        | 87/692 [00:02\u003c00:14, 40.95it/s] \u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 90 Loss: 12.876619434356689 Accuracy: 0.05330784358084202:  13%|█▎        | 92/692 [00:02\u003c00:14, 40.78it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 90 Loss: 12.876619434356689 Accuracy: 0.05330784358084202:  14%|█▍        | 97/692 [00:02\u003c00:14, 40.48it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 100 Loss: 12.578376770019531 Accuracy: 0.05382509827613831:  14%|█▍        | 97/692 [00:02\u003c00:14, 40.48it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 100 Loss: 12.578376770019531 Accuracy: 0.05382509827613831:  15%|█▍        | 102/692 [00:02\u003c00:14, 40.43it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 100 Loss: 12.578376770019531 Accuracy: 0.05382509827613831:  15%|█▌        | 107/692 [00:02\u003c00:14, 40.74it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 110 Loss: 12.6321946144104 Accuracy: 0.05547509342432022:  15%|█▌        | 107/692 [00:02\u003c00:14, 40.74it/s]  \u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 110 Loss: 12.6321946144104 Accuracy: 0.05547509342432022:  16%|█▌        | 112/692 [00:02\u003c00:14, 40.55it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 110 Loss: 12.6321946144104 Accuracy: 0.05547509342432022:  17%|█▋        | 117/692 [00:02\u003c00:14, 40.82it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 120 Loss: 12.733357906341553 Accuracy: 0.05498512275516987:  17%|█▋        | 117/692 [00:02\u003c00:14, 40.82it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 120 Loss: 12.733357906341553 Accuracy: 0.05498512275516987:  18%|█▊        | 122/692 [00:03\u003c00:14, 40.58it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 120 Loss: 12.733357906341553 Accuracy: 0.05498512275516987:  18%|█▊        | 127/692 [00:03\u003c00:13, 40.85it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 130 Loss: 12.919427108764648 Accuracy: 0.05505428686738014:  18%|█▊        | 127/692 [00:03\u003c00:13, 40.85it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 130 Loss: 12.919427108764648 Accuracy: 0.05505428686738014:  19%|█▉        | 132/692 [00:03\u003c00:13, 40.52it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 130 Loss: 12.919427108764648 Accuracy: 0.05505428686738014:  20%|█▉        | 137/692 [00:03\u003c00:13, 40.82it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 140 Loss: 12.79290075302124 Accuracy: 0.05084982179105282:  20%|█▉        | 137/692 [00:03\u003c00:13, 40.82it/s] \u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 140 Loss: 12.79290075302124 Accuracy: 0.05084982179105282:  21%|██        | 142/692 [00:03\u003c00:13, 40.76it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 140 Loss: 12.79290075302124 Accuracy: 0.05084982179105282:  21%|██        | 147/692 [00:03\u003c00:13, 40.88it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 150 Loss: 12.643338012695313 Accuracy: 0.05455201640725136:  21%|██        | 147/692 [00:03\u003c00:13, 40.88it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 150 Loss: 12.643338012695313 Accuracy: 0.05455201640725136:  22%|██▏       | 152/692 [00:03\u003c00:13, 40.72it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 150 Loss: 12.643338012695313 Accuracy: 0.05455201640725136:  23%|██▎       | 157/692 [00:03\u003c00:13, 40.93it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 160 Loss: 12.879793643951416 Accuracy: 0.054833780974149704:  23%|██▎       | 157/692 [00:03\u003c00:13, 40.93it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 160 Loss: 12.879793643951416 Accuracy: 0.054833780974149704:  23%|██▎       | 162/692 [00:03\u003c00:13, 40.51it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 160 Loss: 12.879793643951416 Accuracy: 0.054833780974149704:  24%|██▍       | 167/692 [00:04\u003c00:12, 40.79it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 170 Loss: 12.727093315124511 Accuracy: 0.05300941541790962:  24%|██▍       | 167/692 [00:04\u003c00:12, 40.79it/s] \u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 170 Loss: 12.727093315124511 Accuracy: 0.05300941541790962:  25%|██▍       | 172/692 [00:04\u003c00:12, 40.61it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 170 Loss: 12.727093315124511 Accuracy: 0.05300941541790962:  26%|██▌       | 177/692 [00:04\u003c00:12, 40.86it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 180 Loss: 12.720663356781007 Accuracy: 0.0541771724820137:  26%|██▌       | 177/692 [00:04\u003c00:12, 40.86it/s] \u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 180 Loss: 12.720663356781007 Accuracy: 0.0541771724820137:  26%|██▋       | 182/692 [00:04\u003c00:12, 40.73it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 180 Loss: 12.720663356781007 Accuracy: 0.0541771724820137:  27%|██▋       | 187/692 [00:04\u003c00:12, 40.82it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 190 Loss: 12.679221057891846 Accuracy: 0.052305808663368224:  27%|██▋       | 187/692 [00:04\u003c00:12, 40.82it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 190 Loss: 12.679221057891846 Accuracy: 0.052305808663368224:  28%|██▊       | 192/692 [00:04\u003c00:12, 40.37it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 190 Loss: 12.679221057891846 Accuracy: 0.052305808663368224:  28%|██▊       | 197/692 [00:04\u003c00:12, 40.40it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 200 Loss: 12.582900047302246 Accuracy: 0.05470815487205982:  28%|██▊       | 197/692 [00:04\u003c00:12, 40.40it/s] \u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 200 Loss: 12.582900047302246 Accuracy: 0.05470815487205982:  29%|██▉       | 202/692 [00:04\u003c00:12, 39.70it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 200 Loss: 12.582900047302246 Accuracy: 0.05470815487205982:  30%|██▉       | 206/692 [00:05\u003c00:12, 39.35it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 200 Loss: 12.582900047302246 Accuracy: 0.05470815487205982:  30%|███       | 210/692 [00:05\u003c00:12, 39.54it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 210 Loss: 12.604677772521972 Accuracy: 0.05301825404167175:  30%|███       | 210/692 [00:05\u003c00:12, 39.54it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 210 Loss: 12.604677772521972 Accuracy: 0.05301825404167175:  31%|███       | 214/692 [00:05\u003c00:12, 39.14it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 210 Loss: 12.604677772521972 Accuracy: 0.05301825404167175:  32%|███▏      | 218/692 [00:05\u003c00:12, 39.38it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 220 Loss: 12.794434642791748 Accuracy: 0.05200592540204525:  32%|███▏      | 218/692 [00:05\u003c00:12, 39.38it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 220 Loss: 12.794434642791748 Accuracy: 0.05200592540204525:  32%|███▏      | 222/692 [00:05\u003c00:11, 39.25it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 220 Loss: 12.794434642791748 Accuracy: 0.05200592540204525:  33%|███▎      | 227/692 [00:05\u003c00:11, 39.83it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 230 Loss: 12.717507362365723 Accuracy: 0.054093777760863306:  33%|███▎      | 227/692 [00:05\u003c00:11, 39.83it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 230 Loss: 12.717507362365723 Accuracy: 0.054093777760863306:  34%|███▎      | 232/692 [00:05\u003c00:11, 39.91it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 230 Loss: 12.717507362365723 Accuracy: 0.054093777760863306:  34%|███▍      | 237/692 [00:05\u003c00:11, 40.35it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 240 Loss: 12.695661544799805 Accuracy: 0.05401204749941826:  34%|███▍      | 237/692 [00:05\u003c00:11, 40.35it/s] \u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 240 Loss: 12.695661544799805 Accuracy: 0.05401204749941826:  35%|███▍      | 242/692 [00:05\u003c00:11, 40.30it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 240 Loss: 12.695661544799805 Accuracy: 0.05401204749941826:  36%|███▌      | 247/692 [00:06\u003c00:10, 40.55it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 250 Loss: 12.846409511566161 Accuracy: 0.05242240503430366:  36%|███▌      | 247/692 [00:06\u003c00:10, 40.55it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 250 Loss: 12.846409511566161 Accuracy: 0.05242240503430366:  36%|███▋      | 252/692 [00:06\u003c00:10, 40.32it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 250 Loss: 12.846409511566161 Accuracy: 0.05242240503430366:  37%|███▋      | 257/692 [00:06\u003c00:10, 40.58it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 260 Loss: 12.660505676269532 Accuracy: 0.05688063353300095:  37%|███▋      | 257/692 [00:06\u003c00:10, 40.58it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 260 Loss: 12.660505676269532 Accuracy: 0.05688063353300095:  38%|███▊      | 262/692 [00:06\u003c00:10, 40.46it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 260 Loss: 12.660505676269532 Accuracy: 0.05688063353300095:  39%|███▊      | 267/692 [00:06\u003c00:10, 40.70it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 270 Loss: 12.746766185760498 Accuracy: 0.054307376593351366:  39%|███▊      | 267/692 [00:06\u003c00:10, 40.70it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 270 Loss: 12.746766185760498 Accuracy: 0.054307376593351366:  39%|███▉      | 272/692 [00:06\u003c00:10, 40.46it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 270 Loss: 12.746766185760498 Accuracy: 0.054307376593351366:  40%|████      | 277/692 [00:06\u003c00:10, 40.72it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 280 Loss: 12.672284030914307 Accuracy: 0.05531815215945244:  40%|████      | 277/692 [00:06\u003c00:10, 40.72it/s] \u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 280 Loss: 12.672284030914307 Accuracy: 0.05531815215945244:  41%|████      | 282/692 [00:06\u003c00:10, 40.47it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 280 Loss: 12.672284030914307 Accuracy: 0.05531815215945244:  41%|████▏     | 287/692 [00:07\u003c00:09, 40.66it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 290 Loss: 12.688909721374511 Accuracy: 0.054201573878526685:  41%|████▏     | 287/692 [00:07\u003c00:09, 40.66it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 290 Loss: 12.688909721374511 Accuracy: 0.054201573878526685:  42%|████▏     | 292/692 [00:07\u003c00:09, 40.53it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 290 Loss: 12.688909721374511 Accuracy: 0.054201573878526685:  43%|████▎     | 297/692 [00:07\u003c00:09, 40.68it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 300 Loss: 12.441288471221924 Accuracy: 0.05374716855585575:  43%|████▎     | 297/692 [00:07\u003c00:09, 40.68it/s] \u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 300 Loss: 12.441288471221924 Accuracy: 0.05374716855585575:  44%|████▎     | 302/692 [00:07\u003c00:09, 40.67it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 300 Loss: 12.441288471221924 Accuracy: 0.05374716855585575:  44%|████▍     | 307/692 [00:07\u003c00:09, 40.83it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 310 Loss: 12.681433200836182 Accuracy: 0.054163556173443796:  44%|████▍     | 307/692 [00:07\u003c00:09, 40.83it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 310 Loss: 12.681433200836182 Accuracy: 0.054163556173443796:  45%|████▌     | 312/692 [00:07\u003c00:09, 40.35it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 310 Loss: 12.681433200836182 Accuracy: 0.054163556173443796:  46%|████▌     | 317/692 [00:07\u003c00:09, 40.62it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 320 Loss: 12.665937900543213 Accuracy: 0.05673939883708954:  46%|████▌     | 317/692 [00:07\u003c00:09, 40.62it/s] \u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 320 Loss: 12.665937900543213 Accuracy: 0.05673939883708954:  47%|████▋     | 322/692 [00:07\u003c00:09, 40.52it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 320 Loss: 12.665937900543213 Accuracy: 0.05673939883708954:  47%|████▋     | 327/692 [00:08\u003c00:08, 40.76it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 330 Loss: 12.692328643798827 Accuracy: 0.05656747668981552:  47%|████▋     | 327/692 [00:08\u003c00:08, 40.76it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 330 Loss: 12.692328643798827 Accuracy: 0.05656747668981552:  48%|████▊     | 332/692 [00:08\u003c00:08, 40.58it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 330 Loss: 12.692328643798827 Accuracy: 0.05656747668981552:  49%|████▊     | 337/692 [00:08\u003c00:08, 40.81it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 340 Loss: 12.733717346191407 Accuracy: 0.050889378413558006:  49%|████▊     | 337/692 [00:08\u003c00:08, 40.81it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 340 Loss: 12.733717346191407 Accuracy: 0.050889378413558006:  49%|████▉     | 342/692 [00:08\u003c00:08, 40.62it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 340 Loss: 12.733717346191407 Accuracy: 0.050889378413558006:  50%|█████     | 347/692 [00:08\u003c00:08, 40.70it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 350 Loss: 12.751084423065185 Accuracy: 0.05350177362561226:  50%|█████     | 347/692 [00:08\u003c00:08, 40.70it/s] \u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 350 Loss: 12.751084423065185 Accuracy: 0.05350177362561226:  51%|█████     | 352/692 [00:08\u003c00:08, 40.23it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 350 Loss: 12.751084423065185 Accuracy: 0.05350177362561226:  52%|█████▏    | 357/692 [00:08\u003c00:08, 40.31it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 360 Loss: 12.491141891479492 Accuracy: 0.05365355536341667:  52%|█████▏    | 357/692 [00:08\u003c00:08, 40.31it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 360 Loss: 12.491141891479492 Accuracy: 0.05365355536341667:  52%|█████▏    | 362/692 [00:08\u003c00:08, 39.95it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 360 Loss: 12.491141891479492 Accuracy: 0.05365355536341667:  53%|█████▎    | 367/692 [00:09\u003c00:08, 40.18it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 370 Loss: 12.79382619857788 Accuracy: 0.05363154225051403:  53%|█████▎    | 367/692 [00:09\u003c00:08, 40.18it/s] \u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 370 Loss: 12.79382619857788 Accuracy: 0.05363154225051403:  54%|█████▍    | 372/692 [00:09\u003c00:08, 39.88it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 370 Loss: 12.79382619857788 Accuracy: 0.05363154225051403:  54%|█████▍    | 377/692 [00:09\u003c00:07, 40.06it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 380 Loss: 12.64590950012207 Accuracy: 0.052169119194149974:  54%|█████▍    | 377/692 [00:09\u003c00:07, 40.06it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 380 Loss: 12.64590950012207 Accuracy: 0.052169119194149974:  55%|█████▌    | 382/692 [00:09\u003c00:07, 39.77it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 380 Loss: 12.64590950012207 Accuracy: 0.052169119194149974:  56%|█████▌    | 387/692 [00:09\u003c00:07, 40.04it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 390 Loss: 12.797311592102051 Accuracy: 0.05166478417813778:  56%|█████▌    | 387/692 [00:09\u003c00:07, 40.04it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 390 Loss: 12.797311592102051 Accuracy: 0.05166478417813778:  57%|█████▋    | 392/692 [00:09\u003c00:07, 39.90it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 390 Loss: 12.797311592102051 Accuracy: 0.05166478417813778:  57%|█████▋    | 397/692 [00:09\u003c00:07, 40.29it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 400 Loss: 12.883151626586914 Accuracy: 0.052617476880550386:  57%|█████▋    | 397/692 [00:09\u003c00:07, 40.29it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 400 Loss: 12.883151626586914 Accuracy: 0.052617476880550386:  58%|█████▊    | 402/692 [00:09\u003c00:07, 40.18it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 400 Loss: 12.883151626586914 Accuracy: 0.052617476880550386:  59%|█████▉    | 407/692 [00:10\u003c00:07, 40.37it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 410 Loss: 12.774128437042236 Accuracy: 0.05030869953334331:  59%|█████▉    | 407/692 [00:10\u003c00:07, 40.37it/s] \u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 410 Loss: 12.774128437042236 Accuracy: 0.05030869953334331:  60%|█████▉    | 412/692 [00:10\u003c00:06, 40.17it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 410 Loss: 12.774128437042236 Accuracy: 0.05030869953334331:  60%|██████    | 417/692 [00:10\u003c00:06, 40.48it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 420 Loss: 12.661833381652832 Accuracy: 0.052884587273001674:  60%|██████    | 417/692 [00:10\u003c00:06, 40.48it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 420 Loss: 12.661833381652832 Accuracy: 0.052884587273001674:  61%|██████    | 422/692 [00:10\u003c00:06, 40.25it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 420 Loss: 12.661833381652832 Accuracy: 0.052884587273001674:  62%|██████▏   | 427/692 [00:10\u003c00:06, 40.43it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 430 Loss: 12.706063652038575 Accuracy: 0.05181113705039024:  62%|██████▏   | 427/692 [00:10\u003c00:06, 40.43it/s] \u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 430 Loss: 12.706063652038575 Accuracy: 0.05181113705039024:  62%|██████▏   | 432/692 [00:10\u003c00:06, 40.23it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 430 Loss: 12.706063652038575 Accuracy: 0.05181113705039024:  63%|██████▎   | 437/692 [00:10\u003c00:06, 40.50it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 440 Loss: 12.800287437438964 Accuracy: 0.05474926456809044:  63%|██████▎   | 437/692 [00:10\u003c00:06, 40.50it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 440 Loss: 12.800287437438964 Accuracy: 0.05474926456809044:  64%|██████▍   | 442/692 [00:10\u003c00:06, 40.39it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 440 Loss: 12.800287437438964 Accuracy: 0.05474926456809044:  65%|██████▍   | 447/692 [00:11\u003c00:06, 40.45it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 450 Loss: 12.766949653625488 Accuracy: 0.05512988232076168:  65%|██████▍   | 447/692 [00:11\u003c00:06, 40.45it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 450 Loss: 12.766949653625488 Accuracy: 0.05512988232076168:  65%|██████▌   | 452/692 [00:11\u003c00:06, 39.98it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 450 Loss: 12.766949653625488 Accuracy: 0.05512988232076168:  66%|██████▌   | 457/692 [00:11\u003c00:05, 40.28it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 460 Loss: 12.601655673980712 Accuracy: 0.05271195881068706:  66%|██████▌   | 457/692 [00:11\u003c00:05, 40.28it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 460 Loss: 12.601655673980712 Accuracy: 0.05271195881068706:  67%|██████▋   | 462/692 [00:11\u003c00:05, 40.16it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 460 Loss: 12.601655673980712 Accuracy: 0.05271195881068706:  67%|██████▋   | 467/692 [00:11\u003c00:05, 40.43it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 470 Loss: 12.623702335357667 Accuracy: 0.05117178857326508:  67%|██████▋   | 467/692 [00:11\u003c00:05, 40.43it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 470 Loss: 12.623702335357667 Accuracy: 0.05117178857326508:  68%|██████▊   | 472/692 [00:11\u003c00:05, 40.34it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 470 Loss: 12.623702335357667 Accuracy: 0.05117178857326508:  69%|██████▉   | 477/692 [00:11\u003c00:05, 40.67it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 480 Loss: 12.663322067260742 Accuracy: 0.05420497804880142:  69%|██████▉   | 477/692 [00:11\u003c00:05, 40.67it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 480 Loss: 12.663322067260742 Accuracy: 0.05420497804880142:  70%|██████▉   | 482/692 [00:11\u003c00:05, 40.41it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 480 Loss: 12.663322067260742 Accuracy: 0.05420497804880142:  70%|███████   | 487/692 [00:12\u003c00:05, 40.61it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 490 Loss: 12.764198303222656 Accuracy: 0.0528361614793539:  70%|███████   | 487/692 [00:12\u003c00:05, 40.61it/s] \u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 490 Loss: 12.764198303222656 Accuracy: 0.0528361614793539:  71%|███████   | 492/692 [00:12\u003c00:04, 40.38it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 490 Loss: 12.764198303222656 Accuracy: 0.0528361614793539:  72%|███████▏  | 497/692 [00:12\u003c00:04, 40.65it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 500 Loss: 12.807895374298095 Accuracy: 0.05306629575788975:  72%|███████▏  | 497/692 [00:12\u003c00:04, 40.65it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 500 Loss: 12.807895374298095 Accuracy: 0.05306629575788975:  73%|███████▎  | 502/692 [00:12\u003c00:04, 40.53it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 500 Loss: 12.807895374298095 Accuracy: 0.05306629575788975:  73%|███████▎  | 507/692 [00:12\u003c00:04, 40.73it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 510 Loss: 12.714939785003661 Accuracy: 0.05562707111239433:  73%|███████▎  | 507/692 [00:12\u003c00:04, 40.73it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 510 Loss: 12.714939785003661 Accuracy: 0.05562707111239433:  74%|███████▍  | 512/692 [00:12\u003c00:04, 40.47it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 510 Loss: 12.714939785003661 Accuracy: 0.05562707111239433:  75%|███████▍  | 517/692 [00:12\u003c00:04, 40.71it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 520 Loss: 12.564633560180663 Accuracy: 0.052507640048861506:  75%|███████▍  | 517/692 [00:12\u003c00:04, 40.71it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 520 Loss: 12.564633560180663 Accuracy: 0.052507640048861506:  75%|███████▌  | 522/692 [00:12\u003c00:04, 40.39it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 520 Loss: 12.564633560180663 Accuracy: 0.052507640048861506:  76%|███████▌  | 527/692 [00:13\u003c00:04, 40.54it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 530 Loss: 12.521070766448975 Accuracy: 0.052602197229862216:  76%|███████▌  | 527/692 [00:13\u003c00:04, 40.54it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 530 Loss: 12.521070766448975 Accuracy: 0.052602197229862216:  77%|███████▋  | 532/692 [00:13\u003c00:03, 40.27it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 530 Loss: 12.521070766448975 Accuracy: 0.052602197229862216:  78%|███████▊  | 537/692 [00:13\u003c00:03, 40.48it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 540 Loss: 12.722332191467284 Accuracy: 0.05465046539902687:  78%|███████▊  | 537/692 [00:13\u003c00:03, 40.48it/s] \u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 540 Loss: 12.722332191467284 Accuracy: 0.05465046539902687:  78%|███████▊  | 542/692 [00:13\u003c00:03, 39.99it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 540 Loss: 12.722332191467284 Accuracy: 0.05465046539902687:  79%|███████▉  | 547/692 [00:13\u003c00:03, 40.33it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 550 Loss: 12.758279991149902 Accuracy: 0.05161342285573482:  79%|███████▉  | 547/692 [00:13\u003c00:03, 40.33it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 550 Loss: 12.758279991149902 Accuracy: 0.05161342285573482:  80%|███████▉  | 552/692 [00:13\u003c00:03, 40.04it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 550 Loss: 12.758279991149902 Accuracy: 0.05161342285573482:  80%|████████  | 557/692 [00:13\u003c00:03, 40.24it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 560 Loss: 12.785963153839111 Accuracy: 0.05347217917442322:  80%|████████  | 557/692 [00:13\u003c00:03, 40.24it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 560 Loss: 12.785963153839111 Accuracy: 0.05347217917442322:  81%|████████  | 562/692 [00:13\u003c00:03, 40.03it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 560 Loss: 12.785963153839111 Accuracy: 0.05347217917442322:  82%|████████▏ | 567/692 [00:14\u003c00:03, 40.35it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 570 Loss: 12.674757480621338 Accuracy: 0.053792594000697136:  82%|████████▏ | 567/692 [00:14\u003c00:03, 40.35it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 570 Loss: 12.674757480621338 Accuracy: 0.053792594000697136:  83%|████████▎ | 572/692 [00:14\u003c00:02, 40.23it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 570 Loss: 12.674757480621338 Accuracy: 0.053792594000697136:  83%|████████▎ | 577/692 [00:14\u003c00:02, 40.47it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 580 Loss: 12.709845066070557 Accuracy: 0.054716286808252336:  83%|████████▎ | 577/692 [00:14\u003c00:02, 40.47it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 580 Loss: 12.709845066070557 Accuracy: 0.054716286808252336:  84%|████████▍ | 582/692 [00:14\u003c00:02, 39.91it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 580 Loss: 12.709845066070557 Accuracy: 0.054716286808252336:  85%|████████▍ | 587/692 [00:14\u003c00:02, 40.22it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 590 Loss: 12.882056045532227 Accuracy: 0.053963954001665114:  85%|████████▍ | 587/692 [00:14\u003c00:02, 40.22it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 590 Loss: 12.882056045532227 Accuracy: 0.053963954001665114:  86%|████████▌ | 592/692 [00:14\u003c00:02, 39.93it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 590 Loss: 12.882056045532227 Accuracy: 0.053963954001665114:  86%|████████▋ | 597/692 [00:14\u003c00:02, 40.05it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 600 Loss: 12.701248073577881 Accuracy: 0.05155373476445675:  86%|████████▋ | 597/692 [00:14\u003c00:02, 40.05it/s] \u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 600 Loss: 12.701248073577881 Accuracy: 0.05155373476445675:  87%|████████▋ | 602/692 [00:14\u003c00:02, 39.81it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 600 Loss: 12.701248073577881 Accuracy: 0.05155373476445675:  88%|████████▊ | 607/692 [00:15\u003c00:02, 40.03it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 610 Loss: 12.516255187988282 Accuracy: 0.0514836922287941:  88%|████████▊ | 607/692 [00:15\u003c00:02, 40.03it/s] \u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 610 Loss: 12.516255187988282 Accuracy: 0.0514836922287941:  88%|████████▊ | 612/692 [00:15\u003c00:02, 39.58it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 610 Loss: 12.516255187988282 Accuracy: 0.0514836922287941:  89%|████████▉ | 616/692 [00:15\u003c00:01, 39.46it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 610 Loss: 12.516255187988282 Accuracy: 0.0514836922287941:  90%|████████▉ | 620/692 [00:15\u003c00:01, 39.51it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 620 Loss: 12.607370853424072 Accuracy: 0.05327707156538963:  90%|████████▉ | 620/692 [00:15\u003c00:01, 39.51it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 620 Loss: 12.607370853424072 Accuracy: 0.05327707156538963:  90%|█████████ | 624/692 [00:15\u003c00:01, 39.18it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 620 Loss: 12.607370853424072 Accuracy: 0.05327707156538963:  91%|█████████ | 629/692 [00:15\u003c00:01, 39.61it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 630 Loss: 12.699490642547607 Accuracy: 0.05246070995926857:  91%|█████████ | 629/692 [00:15\u003c00:01, 39.61it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 630 Loss: 12.699490642547607 Accuracy: 0.05246070995926857:  91%|█████████▏| 633/692 [00:15\u003c00:01, 39.41it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 630 Loss: 12.699490642547607 Accuracy: 0.05246070995926857:  92%|█████████▏| 638/692 [00:15\u003c00:01, 39.80it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 640 Loss: 12.640835571289063 Accuracy: 0.051572256907820704:  92%|█████████▏| 638/692 [00:15\u003c00:01, 39.80it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 640 Loss: 12.640835571289063 Accuracy: 0.051572256907820704:  93%|█████████▎| 642/692 [00:15\u003c00:01, 39.56it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 640 Loss: 12.640835571289063 Accuracy: 0.051572256907820704:  93%|█████████▎| 647/692 [00:16\u003c00:01, 40.09it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 650 Loss: 12.705878448486327 Accuracy: 0.05460800789296627:  93%|█████████▎| 647/692 [00:16\u003c00:01, 40.09it/s] \u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 650 Loss: 12.705878448486327 Accuracy: 0.05460800789296627:  94%|█████████▍| 652/692 [00:16\u003c00:00, 40.06it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 650 Loss: 12.705878448486327 Accuracy: 0.05460800789296627:  95%|█████████▍| 657/692 [00:16\u003c00:00, 40.35it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 660 Loss: 12.838945293426514 Accuracy: 0.05352580323815346:  95%|█████████▍| 657/692 [00:16\u003c00:00, 40.35it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 660 Loss: 12.838945293426514 Accuracy: 0.05352580323815346:  96%|█████████▌| 662/692 [00:16\u003c00:00, 40.11it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 660 Loss: 12.838945293426514 Accuracy: 0.05352580323815346:  96%|█████████▋| 667/692 [00:16\u003c00:00, 40.41it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 670 Loss: 12.68925428390503 Accuracy: 0.05397695042192936:  96%|█████████▋| 667/692 [00:16\u003c00:00, 40.41it/s] \u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 670 Loss: 12.68925428390503 Accuracy: 0.05397695042192936:  97%|█████████▋| 672/692 [00:16\u003c00:00, 40.27it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 670 Loss: 12.68925428390503 Accuracy: 0.05397695042192936:  98%|█████████▊| 677/692 [00:16\u003c00:00, 40.47it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 680 Loss: 12.833970737457275 Accuracy: 0.05034023262560368:  98%|█████████▊| 677/692 [00:16\u003c00:00, 40.47it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 680 Loss: 12.833970737457275 Accuracy: 0.05034023262560368:  99%|█████████▊| 682/692 [00:16\u003c00:00, 40.41it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 680 Loss: 12.833970737457275 Accuracy: 0.05034023262560368:  99%|█████████▉| 687/692 [00:17\u003c00:00, 40.71it/s]\u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 690 Loss: 12.71026029586792 Accuracy: 0.05162058062851429:  99%|█████████▉| 687/692 [00:17\u003c00:00, 40.71it/s] \u001b[A\u001b[A\n","\n","Epoch: 4 Iteration: 690 Loss: 12.71026029586792 Accuracy: 0.05162058062851429: 100%|██████████| 692/692 [00:17\u003c00:00, 40.37it/s]\n","\n","\n","  0%|          | 0/692 [00:00\u003c?, ?it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 0 Loss: 12.761066246032716 Accuracy: 0.05203485079109669:   0%|          | 0/692 [00:00\u003c?, ?it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 0 Loss: 12.761066246032716 Accuracy: 0.05203485079109669:   1%|          | 4/692 [00:00\u003c00:17, 39.37it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 0 Loss: 12.761066246032716 Accuracy: 0.05203485079109669:   1%|▏         | 9/692 [00:00\u003c00:17, 39.88it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 10 Loss: 12.739105224609375 Accuracy: 0.05123918354511261:   1%|▏         | 9/692 [00:00\u003c00:17, 39.88it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 10 Loss: 12.739105224609375 Accuracy: 0.05123918354511261:   2%|▏         | 13/692 [00:00\u003c00:17, 39.87it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 10 Loss: 12.739105224609375 Accuracy: 0.05123918354511261:   3%|▎         | 18/692 [00:00\u003c00:16, 40.35it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 20 Loss: 12.58294153213501 Accuracy: 0.054305301234126094:   3%|▎         | 18/692 [00:00\u003c00:16, 40.35it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 20 Loss: 12.58294153213501 Accuracy: 0.054305301234126094:   3%|▎         | 22/692 [00:00\u003c00:16, 39.89it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 20 Loss: 12.58294153213501 Accuracy: 0.054305301234126094:   4%|▍         | 27/692 [00:00\u003c00:16, 40.27it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 30 Loss: 12.843224334716798 Accuracy: 0.053932488709688184:   4%|▍         | 27/692 [00:00\u003c00:16, 40.27it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 30 Loss: 12.843224334716798 Accuracy: 0.053932488709688184:   5%|▍         | 32/692 [00:00\u003c00:16, 40.25it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 30 Loss: 12.843224334716798 Accuracy: 0.053932488709688184:   5%|▌         | 37/692 [00:00\u003c00:16, 40.52it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 40 Loss: 12.773433113098145 Accuracy: 0.05465878285467625:   5%|▌         | 37/692 [00:01\u003c00:16, 40.52it/s] \u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 40 Loss: 12.773433113098145 Accuracy: 0.05465878285467625:   6%|▌         | 41/692 [00:01\u003c00:16, 40.30it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 40 Loss: 12.773433113098145 Accuracy: 0.05465878285467625:   7%|▋         | 45/692 [00:01\u003c00:16, 40.20it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 40 Loss: 12.773433113098145 Accuracy: 0.05465878285467625:   7%|▋         | 50/692 [00:01\u003c00:15, 40.49it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 50 Loss: 12.79403018951416 Accuracy: 0.056580746173858644:   7%|▋         | 50/692 [00:01\u003c00:15, 40.49it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 50 Loss: 12.79403018951416 Accuracy: 0.056580746173858644:   8%|▊         | 54/692 [00:01\u003c00:15, 39.92it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 50 Loss: 12.79403018951416 Accuracy: 0.056580746173858644:   9%|▊         | 59/692 [00:01\u003c00:15, 40.30it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 60 Loss: 12.777904510498047 Accuracy: 0.052924585342407224:   9%|▊         | 59/692 [00:01\u003c00:15, 40.30it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 60 Loss: 12.777904510498047 Accuracy: 0.052924585342407224:   9%|▉         | 63/692 [00:01\u003c00:15, 40.08it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 60 Loss: 12.777904510498047 Accuracy: 0.052924585342407224:  10%|▉         | 68/692 [00:01\u003c00:15, 40.44it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 70 Loss: 12.737911415100097 Accuracy: 0.05154339335858822:  10%|▉         | 68/692 [00:01\u003c00:15, 40.44it/s] \u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 70 Loss: 12.737911415100097 Accuracy: 0.05154339335858822:  11%|█         | 73/692 [00:01\u003c00:15, 40.10it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 70 Loss: 12.737911415100097 Accuracy: 0.05154339335858822:  11%|█▏        | 78/692 [00:01\u003c00:15, 40.40it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 80 Loss: 12.764828109741211 Accuracy: 0.05638219639658928:  11%|█▏        | 78/692 [00:02\u003c00:15, 40.40it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 80 Loss: 12.764828109741211 Accuracy: 0.05638219639658928:  12%|█▏        | 83/692 [00:02\u003c00:15, 40.38it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 80 Loss: 12.764828109741211 Accuracy: 0.05638219639658928:  13%|█▎        | 88/692 [00:02\u003c00:14, 40.60it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 90 Loss: 12.69804801940918 Accuracy: 0.05430212691426277:  13%|█▎        | 88/692 [00:02\u003c00:14, 40.60it/s] \u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 90 Loss: 12.69804801940918 Accuracy: 0.05430212691426277:  13%|█▎        | 93/692 [00:02\u003c00:14, 40.56it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 90 Loss: 12.69804801940918 Accuracy: 0.05430212691426277:  14%|█▍        | 98/692 [00:02\u003c00:14, 40.84it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 100 Loss: 12.789028072357178 Accuracy: 0.05272828862071037:  14%|█▍        | 98/692 [00:02\u003c00:14, 40.84it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 100 Loss: 12.789028072357178 Accuracy: 0.05272828862071037:  15%|█▍        | 103/692 [00:02\u003c00:14, 40.63it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 100 Loss: 12.789028072357178 Accuracy: 0.05272828862071037:  16%|█▌        | 108/692 [00:02\u003c00:14, 40.86it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 110 Loss: 12.70124273300171 Accuracy: 0.05716964825987816:  16%|█▌        | 108/692 [00:02\u003c00:14, 40.86it/s] \u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 110 Loss: 12.70124273300171 Accuracy: 0.05716964825987816:  16%|█▋        | 113/692 [00:02\u003c00:14, 40.72it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 110 Loss: 12.70124273300171 Accuracy: 0.05716964825987816:  17%|█▋        | 118/692 [00:02\u003c00:14, 40.92it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 120 Loss: 12.69505558013916 Accuracy: 0.05300990007817745:  17%|█▋        | 118/692 [00:02\u003c00:14, 40.92it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 120 Loss: 12.69505558013916 Accuracy: 0.05300990007817745:  18%|█▊        | 123/692 [00:03\u003c00:14, 40.64it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 120 Loss: 12.69505558013916 Accuracy: 0.05300990007817745:  18%|█▊        | 128/692 [00:03\u003c00:13, 40.89it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 130 Loss: 12.690250587463378 Accuracy: 0.05460446067154408:  18%|█▊        | 128/692 [00:03\u003c00:13, 40.89it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 130 Loss: 12.690250587463378 Accuracy: 0.05460446067154408:  19%|█▉        | 133/692 [00:03\u003c00:13, 40.81it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 130 Loss: 12.690250587463378 Accuracy: 0.05460446067154408:  20%|█▉        | 138/692 [00:03\u003c00:13, 40.98it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 140 Loss: 12.649523162841797 Accuracy: 0.05484934188425541:  20%|█▉        | 138/692 [00:03\u003c00:13, 40.98it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 140 Loss: 12.649523162841797 Accuracy: 0.05484934188425541:  21%|██        | 143/692 [00:03\u003c00:13, 40.76it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 140 Loss: 12.649523162841797 Accuracy: 0.05484934188425541:  21%|██▏       | 148/692 [00:03\u003c00:13, 40.92it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 150 Loss: 12.834110736846924 Accuracy: 0.04636012241244316:  21%|██▏       | 148/692 [00:03\u003c00:13, 40.92it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 150 Loss: 12.834110736846924 Accuracy: 0.04636012241244316:  22%|██▏       | 153/692 [00:03\u003c00:13, 40.75it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 150 Loss: 12.834110736846924 Accuracy: 0.04636012241244316:  23%|██▎       | 158/692 [00:03\u003c00:13, 40.96it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 160 Loss: 12.561551380157471 Accuracy: 0.052853754907846454:  23%|██▎       | 158/692 [00:03\u003c00:13, 40.96it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 160 Loss: 12.561551380157471 Accuracy: 0.052853754907846454:  24%|██▎       | 163/692 [00:04\u003c00:12, 40.90it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 160 Loss: 12.561551380157471 Accuracy: 0.052853754907846454:  24%|██▍       | 168/692 [00:04\u003c00:12, 41.08it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 170 Loss: 12.771412754058838 Accuracy: 0.05553955137729645:  24%|██▍       | 168/692 [00:04\u003c00:12, 41.08it/s] \u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 170 Loss: 12.771412754058838 Accuracy: 0.05553955137729645:  25%|██▌       | 173/692 [00:04\u003c00:12, 40.80it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 170 Loss: 12.771412754058838 Accuracy: 0.05553955137729645:  26%|██▌       | 178/692 [00:04\u003c00:12, 40.92it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 180 Loss: 12.601272678375244 Accuracy: 0.0540950607508421:  26%|██▌       | 178/692 [00:04\u003c00:12, 40.92it/s] \u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 180 Loss: 12.601272678375244 Accuracy: 0.0540950607508421:  26%|██▋       | 183/692 [00:04\u003c00:12, 40.72it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 180 Loss: 12.601272678375244 Accuracy: 0.0540950607508421:  27%|██▋       | 188/692 [00:04\u003c00:12, 40.82it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 190 Loss: 12.600100708007812 Accuracy: 0.055425965785980226:  27%|██▋       | 188/692 [00:04\u003c00:12, 40.82it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 190 Loss: 12.600100708007812 Accuracy: 0.055425965785980226:  28%|██▊       | 193/692 [00:04\u003c00:12, 40.60it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 190 Loss: 12.600100708007812 Accuracy: 0.055425965785980226:  29%|██▊       | 198/692 [00:04\u003c00:12, 40.79it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 200 Loss: 12.801739406585693 Accuracy: 0.05509808212518692:  29%|██▊       | 198/692 [00:04\u003c00:12, 40.79it/s] \u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 200 Loss: 12.801739406585693 Accuracy: 0.05509808212518692:  29%|██▉       | 203/692 [00:04\u003c00:12, 40.47it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 200 Loss: 12.801739406585693 Accuracy: 0.05509808212518692:  30%|███       | 208/692 [00:05\u003c00:11, 40.58it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 210 Loss: 12.61919641494751 Accuracy: 0.05396486483514309:  30%|███       | 208/692 [00:05\u003c00:11, 40.58it/s] \u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 210 Loss: 12.61919641494751 Accuracy: 0.05396486483514309:  31%|███       | 213/692 [00:05\u003c00:11, 40.46it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 210 Loss: 12.61919641494751 Accuracy: 0.05396486483514309:  32%|███▏      | 218/692 [00:05\u003c00:11, 40.67it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 220 Loss: 12.62270450592041 Accuracy: 0.05304088816046715:  32%|███▏      | 218/692 [00:05\u003c00:11, 40.67it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 220 Loss: 12.62270450592041 Accuracy: 0.05304088816046715:  32%|███▏      | 223/692 [00:05\u003c00:11, 40.57it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 220 Loss: 12.62270450592041 Accuracy: 0.05304088816046715:  33%|███▎      | 228/692 [00:05\u003c00:11, 40.81it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 230 Loss: 12.797535037994384 Accuracy: 0.05225101448595524:  33%|███▎      | 228/692 [00:05\u003c00:11, 40.81it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 230 Loss: 12.797535037994384 Accuracy: 0.05225101448595524:  34%|███▎      | 233/692 [00:05\u003c00:11, 40.70it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 230 Loss: 12.797535037994384 Accuracy: 0.05225101448595524:  34%|███▍      | 238/692 [00:05\u003c00:11, 40.91it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 240 Loss: 12.55114812850952 Accuracy: 0.05468507371842861:  34%|███▍      | 238/692 [00:05\u003c00:11, 40.91it/s] \u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 240 Loss: 12.55114812850952 Accuracy: 0.05468507371842861:  35%|███▌      | 243/692 [00:05\u003c00:11, 40.53it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 240 Loss: 12.55114812850952 Accuracy: 0.05468507371842861:  36%|███▌      | 248/692 [00:06\u003c00:10, 40.78it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 250 Loss: 12.678998756408692 Accuracy: 0.05357492938637733:  36%|███▌      | 248/692 [00:06\u003c00:10, 40.78it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 250 Loss: 12.678998756408692 Accuracy: 0.05357492938637733:  37%|███▋      | 253/692 [00:06\u003c00:10, 40.58it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 250 Loss: 12.678998756408692 Accuracy: 0.05357492938637733:  37%|███▋      | 258/692 [00:06\u003c00:10, 40.72it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 260 Loss: 12.74653205871582 Accuracy: 0.05442289635539055:  37%|███▋      | 258/692 [00:06\u003c00:10, 40.72it/s] \u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 260 Loss: 12.74653205871582 Accuracy: 0.05442289635539055:  38%|███▊      | 263/692 [00:06\u003c00:10, 40.60it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 260 Loss: 12.74653205871582 Accuracy: 0.05442289635539055:  39%|███▊      | 268/692 [00:06\u003c00:10, 40.68it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 270 Loss: 12.910405540466309 Accuracy: 0.05432920567691326:  39%|███▊      | 268/692 [00:06\u003c00:10, 40.68it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 270 Loss: 12.910405540466309 Accuracy: 0.05432920567691326:  39%|███▉      | 273/692 [00:06\u003c00:10, 40.49it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 270 Loss: 12.910405540466309 Accuracy: 0.05432920567691326:  40%|████      | 278/692 [00:06\u003c00:10, 40.73it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 280 Loss: 12.681752014160157 Accuracy: 0.049620942771434785:  40%|████      | 278/692 [00:06\u003c00:10, 40.73it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 280 Loss: 12.681752014160157 Accuracy: 0.049620942771434785:  41%|████      | 283/692 [00:06\u003c00:10, 40.57it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 280 Loss: 12.681752014160157 Accuracy: 0.049620942771434785:  42%|████▏     | 288/692 [00:07\u003c00:09, 40.86it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 290 Loss: 12.901236057281494 Accuracy: 0.05351901762187481:  42%|████▏     | 288/692 [00:07\u003c00:09, 40.86it/s] \u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 290 Loss: 12.901236057281494 Accuracy: 0.05351901762187481:  42%|████▏     | 293/692 [00:07\u003c00:09, 40.68it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 290 Loss: 12.901236057281494 Accuracy: 0.05351901762187481:  43%|████▎     | 298/692 [00:07\u003c00:09, 40.90it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 300 Loss: 12.687535667419434 Accuracy: 0.05551062561571598:  43%|████▎     | 298/692 [00:07\u003c00:09, 40.90it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 300 Loss: 12.687535667419434 Accuracy: 0.05551062561571598:  44%|████▍     | 303/692 [00:07\u003c00:09, 40.84it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 300 Loss: 12.687535667419434 Accuracy: 0.05551062561571598:  45%|████▍     | 308/692 [00:07\u003c00:09, 40.88it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 310 Loss: 12.651233768463134 Accuracy: 0.05162251852452755:  45%|████▍     | 308/692 [00:07\u003c00:09, 40.88it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 310 Loss: 12.651233768463134 Accuracy: 0.05162251852452755:  45%|████▌     | 313/692 [00:07\u003c00:09, 40.63it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 310 Loss: 12.651233768463134 Accuracy: 0.05162251852452755:  46%|████▌     | 318/692 [00:07\u003c00:09, 40.95it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 320 Loss: 12.776344585418702 Accuracy: 0.05731155574321747:  46%|████▌     | 318/692 [00:07\u003c00:09, 40.95it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 320 Loss: 12.776344585418702 Accuracy: 0.05731155574321747:  47%|████▋     | 323/692 [00:07\u003c00:09, 40.69it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 320 Loss: 12.776344585418702 Accuracy: 0.05731155574321747:  47%|████▋     | 328/692 [00:08\u003c00:08, 40.92it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 330 Loss: 12.63052282333374 Accuracy: 0.051338955760002136:  47%|████▋     | 328/692 [00:08\u003c00:08, 40.92it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 330 Loss: 12.63052282333374 Accuracy: 0.051338955760002136:  48%|████▊     | 333/692 [00:08\u003c00:08, 40.73it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 330 Loss: 12.63052282333374 Accuracy: 0.051338955760002136:  49%|████▉     | 338/692 [00:08\u003c00:08, 40.78it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 340 Loss: 12.648682403564454 Accuracy: 0.052111684903502466:  49%|████▉     | 338/692 [00:08\u003c00:08, 40.78it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 340 Loss: 12.648682403564454 Accuracy: 0.052111684903502466:  50%|████▉     | 343/692 [00:08\u003c00:08, 40.61it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 340 Loss: 12.648682403564454 Accuracy: 0.052111684903502466:  50%|█████     | 348/692 [00:08\u003c00:08, 40.87it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 350 Loss: 12.595675849914551 Accuracy: 0.05279945805668831:  50%|█████     | 348/692 [00:08\u003c00:08, 40.87it/s] \u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 350 Loss: 12.595675849914551 Accuracy: 0.05279945805668831:  51%|█████     | 353/692 [00:08\u003c00:08, 40.65it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 350 Loss: 12.595675849914551 Accuracy: 0.05279945805668831:  52%|█████▏    | 358/692 [00:08\u003c00:08, 40.85it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 360 Loss: 12.669930553436279 Accuracy: 0.05278298370540142:  52%|█████▏    | 358/692 [00:08\u003c00:08, 40.85it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 360 Loss: 12.669930553436279 Accuracy: 0.05278298370540142:  52%|█████▏    | 363/692 [00:08\u003c00:08, 40.57it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 360 Loss: 12.669930553436279 Accuracy: 0.05278298370540142:  53%|█████▎    | 368/692 [00:09\u003c00:07, 40.74it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 370 Loss: 12.71878490447998 Accuracy: 0.0576481819152832:  53%|█████▎    | 368/692 [00:09\u003c00:07, 40.74it/s]  \u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 370 Loss: 12.71878490447998 Accuracy: 0.0576481819152832:  54%|█████▍    | 373/692 [00:09\u003c00:07, 40.70it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 370 Loss: 12.71878490447998 Accuracy: 0.0576481819152832:  55%|█████▍    | 378/692 [00:09\u003c00:07, 40.83it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 380 Loss: 12.80263900756836 Accuracy: 0.05161837376654148:  55%|█████▍    | 378/692 [00:09\u003c00:07, 40.83it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 380 Loss: 12.80263900756836 Accuracy: 0.05161837376654148:  55%|█████▌    | 383/692 [00:09\u003c00:07, 40.64it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 380 Loss: 12.80263900756836 Accuracy: 0.05161837376654148:  56%|█████▌    | 388/692 [00:09\u003c00:07, 40.90it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 390 Loss: 12.714462757110596 Accuracy: 0.05109759531915188:  56%|█████▌    | 388/692 [00:09\u003c00:07, 40.90it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 390 Loss: 12.714462757110596 Accuracy: 0.05109759531915188:  57%|█████▋    | 393/692 [00:09\u003c00:07, 40.66it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 390 Loss: 12.714462757110596 Accuracy: 0.05109759531915188:  58%|█████▊    | 398/692 [00:09\u003c00:07, 40.81it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 400 Loss: 12.852086067199707 Accuracy: 0.05141292624175549:  58%|█████▊    | 398/692 [00:09\u003c00:07, 40.81it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 400 Loss: 12.852086067199707 Accuracy: 0.05141292624175549:  58%|█████▊    | 403/692 [00:09\u003c00:07, 40.50it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 400 Loss: 12.852086067199707 Accuracy: 0.05141292624175549:  59%|█████▉    | 408/692 [00:10\u003c00:06, 40.69it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 410 Loss: 12.710125637054443 Accuracy: 0.05331382863223553:  59%|█████▉    | 408/692 [00:10\u003c00:06, 40.69it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 410 Loss: 12.710125637054443 Accuracy: 0.05331382863223553:  60%|█████▉    | 413/692 [00:10\u003c00:06, 40.18it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 410 Loss: 12.710125637054443 Accuracy: 0.05331382863223553:  60%|██████    | 418/692 [00:10\u003c00:06, 40.32it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 420 Loss: 12.661238288879394 Accuracy: 0.05100245475769043:  60%|██████    | 418/692 [00:10\u003c00:06, 40.32it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 420 Loss: 12.661238288879394 Accuracy: 0.05100245475769043:  61%|██████    | 423/692 [00:10\u003c00:06, 40.05it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 420 Loss: 12.661238288879394 Accuracy: 0.05100245475769043:  62%|██████▏   | 428/692 [00:10\u003c00:06, 40.23it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 430 Loss: 12.756572437286376 Accuracy: 0.05387508235871792:  62%|██████▏   | 428/692 [00:10\u003c00:06, 40.23it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 430 Loss: 12.756572437286376 Accuracy: 0.05387508235871792:  63%|██████▎   | 433/692 [00:10\u003c00:06, 40.13it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 430 Loss: 12.756572437286376 Accuracy: 0.05387508235871792:  63%|██████▎   | 438/692 [00:10\u003c00:06, 40.48it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 440 Loss: 12.737721061706543 Accuracy: 0.049009981006383894:  63%|██████▎   | 438/692 [00:10\u003c00:06, 40.48it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 440 Loss: 12.737721061706543 Accuracy: 0.049009981006383894:  64%|██████▍   | 443/692 [00:10\u003c00:06, 40.51it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 440 Loss: 12.737721061706543 Accuracy: 0.049009981006383894:  65%|██████▍   | 448/692 [00:11\u003c00:05, 40.78it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 450 Loss: 12.761417865753174 Accuracy: 0.051889951527118686:  65%|██████▍   | 448/692 [00:11\u003c00:05, 40.78it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 450 Loss: 12.761417865753174 Accuracy: 0.051889951527118686:  65%|██████▌   | 453/692 [00:11\u003c00:05, 40.63it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 450 Loss: 12.761417865753174 Accuracy: 0.051889951527118686:  66%|██████▌   | 458/692 [00:11\u003c00:05, 41.00it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 460 Loss: 12.709909152984618 Accuracy: 0.054569756239652635:  66%|██████▌   | 458/692 [00:11\u003c00:05, 41.00it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 460 Loss: 12.709909152984618 Accuracy: 0.054569756239652635:  67%|██████▋   | 463/692 [00:11\u003c00:05, 40.88it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 460 Loss: 12.709909152984618 Accuracy: 0.054569756239652635:  68%|██████▊   | 468/692 [00:11\u003c00:05, 41.03it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 470 Loss: 12.780317497253417 Accuracy: 0.05345798470079899:  68%|██████▊   | 468/692 [00:11\u003c00:05, 41.03it/s] \u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 470 Loss: 12.780317497253417 Accuracy: 0.05345798470079899:  68%|██████▊   | 473/692 [00:11\u003c00:05, 40.68it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 470 Loss: 12.780317497253417 Accuracy: 0.05345798470079899:  69%|██████▉   | 478/692 [00:11\u003c00:05, 40.87it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 480 Loss: 12.544483852386474 Accuracy: 0.05690091960132122:  69%|██████▉   | 478/692 [00:11\u003c00:05, 40.87it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 480 Loss: 12.544483852386474 Accuracy: 0.05690091960132122:  70%|██████▉   | 483/692 [00:11\u003c00:05, 40.66it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 480 Loss: 12.544483852386474 Accuracy: 0.05690091960132122:  71%|███████   | 488/692 [00:12\u003c00:04, 40.91it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 490 Loss: 12.637052917480469 Accuracy: 0.053787394985556604:  71%|███████   | 488/692 [00:12\u003c00:04, 40.91it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 490 Loss: 12.637052917480469 Accuracy: 0.053787394985556604:  71%|███████   | 493/692 [00:12\u003c00:04, 40.70it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 490 Loss: 12.637052917480469 Accuracy: 0.053787394985556604:  72%|███████▏  | 498/692 [00:12\u003c00:04, 40.92it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 500 Loss: 12.733972358703614 Accuracy: 0.05224307104945183:  72%|███████▏  | 498/692 [00:12\u003c00:04, 40.92it/s] \u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 500 Loss: 12.733972358703614 Accuracy: 0.05224307104945183:  73%|███████▎  | 503/692 [00:12\u003c00:04, 40.71it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 500 Loss: 12.733972358703614 Accuracy: 0.05224307104945183:  73%|███████▎  | 508/692 [00:12\u003c00:04, 40.91it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 510 Loss: 12.83700933456421 Accuracy: 0.053504306450486185:  73%|███████▎  | 508/692 [00:12\u003c00:04, 40.91it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 510 Loss: 12.83700933456421 Accuracy: 0.053504306450486185:  74%|███████▍  | 513/692 [00:12\u003c00:04, 40.68it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 510 Loss: 12.83700933456421 Accuracy: 0.053504306450486185:  75%|███████▍  | 518/692 [00:12\u003c00:04, 40.99it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 520 Loss: 12.587994861602784 Accuracy: 0.05350904166698456:  75%|███████▍  | 518/692 [00:12\u003c00:04, 40.99it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 520 Loss: 12.587994861602784 Accuracy: 0.05350904166698456:  76%|███████▌  | 523/692 [00:12\u003c00:04, 40.73it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 520 Loss: 12.587994861602784 Accuracy: 0.05350904166698456:  76%|███████▋  | 528/692 [00:12\u003c00:04, 40.70it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 530 Loss: 12.669683647155761 Accuracy: 0.05267922058701515:  76%|███████▋  | 528/692 [00:13\u003c00:04, 40.70it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 530 Loss: 12.669683647155761 Accuracy: 0.05267922058701515:  77%|███████▋  | 533/692 [00:13\u003c00:03, 40.53it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 530 Loss: 12.669683647155761 Accuracy: 0.05267922058701515:  78%|███████▊  | 538/692 [00:13\u003c00:03, 40.54it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 540 Loss: 12.710444259643555 Accuracy: 0.0569677758961916:  78%|███████▊  | 538/692 [00:13\u003c00:03, 40.54it/s] \u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 540 Loss: 12.710444259643555 Accuracy: 0.0569677758961916:  78%|███████▊  | 543/692 [00:13\u003c00:03, 40.48it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 540 Loss: 12.710444259643555 Accuracy: 0.0569677758961916:  79%|███████▉  | 548/692 [00:13\u003c00:03, 40.82it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 550 Loss: 12.601205444335937 Accuracy: 0.05245094746351242:  79%|███████▉  | 548/692 [00:13\u003c00:03, 40.82it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 550 Loss: 12.601205444335937 Accuracy: 0.05245094746351242:  80%|███████▉  | 553/692 [00:13\u003c00:03, 40.77it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 550 Loss: 12.601205444335937 Accuracy: 0.05245094746351242:  81%|████████  | 558/692 [00:13\u003c00:03, 40.92it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 560 Loss: 12.77642002105713 Accuracy: 0.050634632259607314:  81%|████████  | 558/692 [00:13\u003c00:03, 40.92it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 560 Loss: 12.77642002105713 Accuracy: 0.050634632259607314:  81%|████████▏ | 563/692 [00:13\u003c00:03, 40.72it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 560 Loss: 12.77642002105713 Accuracy: 0.050634632259607314:  82%|████████▏ | 568/692 [00:13\u003c00:03, 40.72it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 570 Loss: 12.679731369018555 Accuracy: 0.054114536941051485:  82%|████████▏ | 568/692 [00:14\u003c00:03, 40.72it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 570 Loss: 12.679731369018555 Accuracy: 0.054114536941051485:  83%|████████▎ | 573/692 [00:14\u003c00:02, 40.40it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 570 Loss: 12.679731369018555 Accuracy: 0.054114536941051485:  84%|████████▎ | 578/692 [00:14\u003c00:02, 40.63it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 580 Loss: 12.63429660797119 Accuracy: 0.05533159077167511:  84%|████████▎ | 578/692 [00:14\u003c00:02, 40.63it/s]  \u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 580 Loss: 12.63429660797119 Accuracy: 0.05533159077167511:  84%|████████▍ | 583/692 [00:14\u003c00:02, 40.38it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 580 Loss: 12.63429660797119 Accuracy: 0.05533159077167511:  85%|████████▍ | 588/692 [00:14\u003c00:02, 40.59it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 590 Loss: 12.645385456085204 Accuracy: 0.05215350091457367:  85%|████████▍ | 588/692 [00:14\u003c00:02, 40.59it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 590 Loss: 12.645385456085204 Accuracy: 0.05215350091457367:  86%|████████▌ | 593/692 [00:14\u003c00:02, 40.35it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 590 Loss: 12.645385456085204 Accuracy: 0.05215350091457367:  86%|████████▋ | 598/692 [00:14\u003c00:02, 40.66it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 600 Loss: 12.948521900177003 Accuracy: 0.05320277437567711:  86%|████████▋ | 598/692 [00:14\u003c00:02, 40.66it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 600 Loss: 12.948521900177003 Accuracy: 0.05320277437567711:  87%|████████▋ | 603/692 [00:14\u003c00:02, 40.41it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 600 Loss: 12.948521900177003 Accuracy: 0.05320277437567711:  88%|████████▊ | 608/692 [00:14\u003c00:02, 40.58it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 610 Loss: 12.7569655418396 Accuracy: 0.05445916764438152:  88%|████████▊ | 608/692 [00:15\u003c00:02, 40.58it/s]  \u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 610 Loss: 12.7569655418396 Accuracy: 0.05445916764438152:  89%|████████▊ | 613/692 [00:15\u003c00:01, 40.54it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 610 Loss: 12.7569655418396 Accuracy: 0.05445916764438152:  89%|████████▉ | 618/692 [00:15\u003c00:01, 40.78it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 620 Loss: 12.735569286346436 Accuracy: 0.052615711092948915:  89%|████████▉ | 618/692 [00:15\u003c00:01, 40.78it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 620 Loss: 12.735569286346436 Accuracy: 0.052615711092948915:  90%|█████████ | 623/692 [00:15\u003c00:01, 40.66it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 620 Loss: 12.735569286346436 Accuracy: 0.052615711092948915:  91%|█████████ | 628/692 [00:15\u003c00:01, 40.91it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 630 Loss: 12.618505859375 Accuracy: 0.052953457459807396:  91%|█████████ | 628/692 [00:15\u003c00:01, 40.91it/s]   \u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 630 Loss: 12.618505859375 Accuracy: 0.052953457459807396:  91%|█████████▏| 633/692 [00:15\u003c00:01, 40.74it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 630 Loss: 12.618505859375 Accuracy: 0.052953457459807396:  92%|█████████▏| 638/692 [00:15\u003c00:01, 40.81it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 640 Loss: 12.656498527526855 Accuracy: 0.050518158823251724:  92%|█████████▏| 638/692 [00:15\u003c00:01, 40.81it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 640 Loss: 12.656498527526855 Accuracy: 0.050518158823251724:  93%|█████████▎| 643/692 [00:15\u003c00:01, 40.72it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 640 Loss: 12.656498527526855 Accuracy: 0.050518158823251724:  94%|█████████▎| 648/692 [00:15\u003c00:01, 41.04it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 650 Loss: 12.767590427398682 Accuracy: 0.050811583548784255:  94%|█████████▎| 648/692 [00:16\u003c00:01, 41.04it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 650 Loss: 12.767590427398682 Accuracy: 0.050811583548784255:  94%|█████████▍| 653/692 [00:16\u003c00:00, 40.70it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 650 Loss: 12.767590427398682 Accuracy: 0.050811583548784255:  95%|█████████▌| 658/692 [00:16\u003c00:00, 40.92it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 660 Loss: 12.798294353485108 Accuracy: 0.05299886018037796:  95%|█████████▌| 658/692 [00:16\u003c00:00, 40.92it/s] \u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 660 Loss: 12.798294353485108 Accuracy: 0.05299886018037796:  96%|█████████▌| 663/692 [00:16\u003c00:00, 40.81it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 660 Loss: 12.798294353485108 Accuracy: 0.05299886018037796:  97%|█████████▋| 668/692 [00:16\u003c00:00, 41.04it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 670 Loss: 12.632334899902343 Accuracy: 0.05066146925091743:  97%|█████████▋| 668/692 [00:16\u003c00:00, 41.04it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 670 Loss: 12.632334899902343 Accuracy: 0.05066146925091743:  97%|█████████▋| 673/692 [00:16\u003c00:00, 40.82it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 670 Loss: 12.632334899902343 Accuracy: 0.05066146925091743:  98%|█████████▊| 678/692 [00:16\u003c00:00, 41.08it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 680 Loss: 12.62978754043579 Accuracy: 0.0545304823666811:  98%|█████████▊| 678/692 [00:16\u003c00:00, 41.08it/s]  \u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 680 Loss: 12.62978754043579 Accuracy: 0.0545304823666811:  99%|█████████▊| 683/692 [00:16\u003c00:00, 40.83it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 680 Loss: 12.62978754043579 Accuracy: 0.0545304823666811:  99%|█████████▉| 688/692 [00:16\u003c00:00, 41.05it/s]\u001b[A\u001b[A\n","\n","Epoch: 5 Iteration: 690 Loss: 12.523897075653077 Accuracy: 0.05302048847079277: 100%|██████████| 692/692 [00:17\u003c00:00, 40.68it/s]\n","\n","\n","  0%|          | 0/692 [00:00\u003c?, ?it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 0 Loss: 12.499029159545898 Accuracy: 0.053653665259480475:   0%|          | 0/692 [00:00\u003c?, ?it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 0 Loss: 12.499029159545898 Accuracy: 0.053653665259480475:   1%|          | 4/692 [00:00\u003c00:17, 39.23it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 0 Loss: 12.499029159545898 Accuracy: 0.053653665259480475:   1%|▏         | 9/692 [00:00\u003c00:17, 39.83it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 10 Loss: 12.809915733337402 Accuracy: 0.05110018290579319:   1%|▏         | 9/692 [00:00\u003c00:17, 39.83it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 10 Loss: 12.809915733337402 Accuracy: 0.05110018290579319:   2%|▏         | 14/692 [00:00\u003c00:16, 40.09it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 10 Loss: 12.809915733337402 Accuracy: 0.05110018290579319:   3%|▎         | 19/692 [00:00\u003c00:16, 40.56it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 20 Loss: 12.642776012420654 Accuracy: 0.05222560986876488:   3%|▎         | 19/692 [00:00\u003c00:16, 40.56it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 20 Loss: 12.642776012420654 Accuracy: 0.05222560986876488:   3%|▎         | 23/692 [00:00\u003c00:16, 40.35it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 20 Loss: 12.642776012420654 Accuracy: 0.05222560986876488:   4%|▍         | 28/692 [00:00\u003c00:16, 40.66it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 30 Loss: 12.7579815864563 Accuracy: 0.05566623136401176:   4%|▍         | 28/692 [00:00\u003c00:16, 40.66it/s]  \u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 30 Loss: 12.7579815864563 Accuracy: 0.05566623136401176:   5%|▍         | 32/692 [00:00\u003c00:16, 40.34it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 30 Loss: 12.7579815864563 Accuracy: 0.05566623136401176:   5%|▌         | 37/692 [00:00\u003c00:16, 40.70it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 40 Loss: 12.67550449371338 Accuracy: 0.05166964642703533:   5%|▌         | 37/692 [00:01\u003c00:16, 40.70it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 40 Loss: 12.67550449371338 Accuracy: 0.05166964642703533:   6%|▌         | 42/692 [00:01\u003c00:16, 40.47it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 40 Loss: 12.67550449371338 Accuracy: 0.05166964642703533:   7%|▋         | 47/692 [00:01\u003c00:15, 40.63it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 50 Loss: 12.686967468261718 Accuracy: 0.05220600292086601:   7%|▋         | 47/692 [00:01\u003c00:15, 40.63it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 50 Loss: 12.686967468261718 Accuracy: 0.05220600292086601:   8%|▊         | 52/692 [00:01\u003c00:15, 40.49it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 50 Loss: 12.686967468261718 Accuracy: 0.05220600292086601:   8%|▊         | 57/692 [00:01\u003c00:15, 40.79it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 60 Loss: 12.592142868041993 Accuracy: 0.05561053715646267:   8%|▊         | 57/692 [00:01\u003c00:15, 40.79it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 60 Loss: 12.592142868041993 Accuracy: 0.05561053715646267:   9%|▉         | 62/692 [00:01\u003c00:15, 40.50it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 60 Loss: 12.592142868041993 Accuracy: 0.05561053715646267:  10%|▉         | 67/692 [00:01\u003c00:15, 40.83it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 70 Loss: 12.690741348266602 Accuracy: 0.05547410473227501:  10%|▉         | 67/692 [00:01\u003c00:15, 40.83it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 70 Loss: 12.690741348266602 Accuracy: 0.05547410473227501:  10%|█         | 72/692 [00:01\u003c00:15, 40.73it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 70 Loss: 12.690741348266602 Accuracy: 0.05547410473227501:  11%|█         | 77/692 [00:01\u003c00:15, 40.91it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 80 Loss: 12.75621519088745 Accuracy: 0.05529836155474186:  11%|█         | 77/692 [00:01\u003c00:15, 40.91it/s] \u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 80 Loss: 12.75621519088745 Accuracy: 0.05529836155474186:  12%|█▏        | 82/692 [00:02\u003c00:15, 40.58it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 80 Loss: 12.75621519088745 Accuracy: 0.05529836155474186:  13%|█▎        | 87/692 [00:02\u003c00:14, 40.74it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 90 Loss: 12.64277629852295 Accuracy: 0.05621495209634304:  13%|█▎        | 87/692 [00:02\u003c00:14, 40.74it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 90 Loss: 12.64277629852295 Accuracy: 0.05621495209634304:  13%|█▎        | 92/692 [00:02\u003c00:14, 40.60it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 90 Loss: 12.64277629852295 Accuracy: 0.05621495209634304:  14%|█▍        | 97/692 [00:02\u003c00:14, 40.81it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 100 Loss: 12.874675846099853 Accuracy: 0.051985925808548925:  14%|█▍        | 97/692 [00:02\u003c00:14, 40.81it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 100 Loss: 12.874675846099853 Accuracy: 0.051985925808548925:  15%|█▍        | 102/692 [00:02\u003c00:14, 40.60it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 100 Loss: 12.874675846099853 Accuracy: 0.051985925808548925:  15%|█▌        | 107/692 [00:02\u003c00:14, 40.68it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 110 Loss: 12.837774658203125 Accuracy: 0.04916575886309147:  15%|█▌        | 107/692 [00:02\u003c00:14, 40.68it/s] \u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 110 Loss: 12.837774658203125 Accuracy: 0.04916575886309147:  16%|█▌        | 112/692 [00:02\u003c00:14, 40.49it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 110 Loss: 12.837774658203125 Accuracy: 0.04916575886309147:  17%|█▋        | 117/692 [00:02\u003c00:14, 40.78it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 120 Loss: 12.685093402862549 Accuracy: 0.05540076047182083:  17%|█▋        | 117/692 [00:02\u003c00:14, 40.78it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 120 Loss: 12.685093402862549 Accuracy: 0.05540076047182083:  18%|█▊        | 122/692 [00:02\u003c00:14, 40.63it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 120 Loss: 12.685093402862549 Accuracy: 0.05540076047182083:  18%|█▊        | 127/692 [00:03\u003c00:13, 40.87it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 130 Loss: 12.643748378753662 Accuracy: 0.05373695306479931:  18%|█▊        | 127/692 [00:03\u003c00:13, 40.87it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 130 Loss: 12.643748378753662 Accuracy: 0.05373695306479931:  19%|█▉        | 132/692 [00:03\u003c00:13, 40.69it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 130 Loss: 12.643748378753662 Accuracy: 0.05373695306479931:  20%|█▉        | 137/692 [00:03\u003c00:13, 40.85it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 140 Loss: 12.762001895904541 Accuracy: 0.05136975161731243:  20%|█▉        | 137/692 [00:03\u003c00:13, 40.85it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 140 Loss: 12.762001895904541 Accuracy: 0.05136975161731243:  21%|██        | 142/692 [00:03\u003c00:13, 40.75it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 140 Loss: 12.762001895904541 Accuracy: 0.05136975161731243:  21%|██        | 147/692 [00:03\u003c00:13, 40.99it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 150 Loss: 12.759982013702393 Accuracy: 0.05199732333421707:  21%|██        | 147/692 [00:03\u003c00:13, 40.99it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 150 Loss: 12.759982013702393 Accuracy: 0.05199732333421707:  22%|██▏       | 152/692 [00:03\u003c00:13, 40.65it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 150 Loss: 12.759982013702393 Accuracy: 0.05199732333421707:  23%|██▎       | 157/692 [00:03\u003c00:13, 40.81it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 160 Loss: 12.759444522857667 Accuracy: 0.054752227291464804:  23%|██▎       | 157/692 [00:03\u003c00:13, 40.81it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 160 Loss: 12.759444522857667 Accuracy: 0.054752227291464804:  23%|██▎       | 162/692 [00:03\u003c00:13, 40.39it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 160 Loss: 12.759444522857667 Accuracy: 0.054752227291464804:  24%|██▍       | 167/692 [00:04\u003c00:12, 40.60it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 170 Loss: 12.651726245880127 Accuracy: 0.05415379367768765:  24%|██▍       | 167/692 [00:04\u003c00:12, 40.60it/s] \u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 170 Loss: 12.651726245880127 Accuracy: 0.05415379367768765:  25%|██▍       | 172/692 [00:04\u003c00:12, 40.24it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 170 Loss: 12.651726245880127 Accuracy: 0.05415379367768765:  26%|██▌       | 177/692 [00:04\u003c00:12, 40.65it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 180 Loss: 12.636100769042969 Accuracy: 0.05116059295833111:  26%|██▌       | 177/692 [00:04\u003c00:12, 40.65it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 180 Loss: 12.636100769042969 Accuracy: 0.05116059295833111:  26%|██▋       | 182/692 [00:04\u003c00:12, 40.56it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 180 Loss: 12.636100769042969 Accuracy: 0.05116059295833111:  27%|██▋       | 187/692 [00:04\u003c00:12, 40.86it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 190 Loss: 12.67167100906372 Accuracy: 0.05204887427389622:  27%|██▋       | 187/692 [00:04\u003c00:12, 40.86it/s] \u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 190 Loss: 12.67167100906372 Accuracy: 0.05204887427389622:  28%|██▊       | 192/692 [00:04\u003c00:12, 40.76it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 190 Loss: 12.67167100906372 Accuracy: 0.05204887427389622:  28%|██▊       | 197/692 [00:04\u003c00:12, 41.00it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 200 Loss: 12.62378978729248 Accuracy: 0.05306386612355709:  28%|██▊       | 197/692 [00:04\u003c00:12, 41.00it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 200 Loss: 12.62378978729248 Accuracy: 0.05306386612355709:  29%|██▉       | 202/692 [00:04\u003c00:12, 40.47it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 200 Loss: 12.62378978729248 Accuracy: 0.05306386612355709:  30%|██▉       | 207/692 [00:05\u003c00:11, 40.57it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 210 Loss: 12.597752857208253 Accuracy: 0.051231924816966055:  30%|██▉       | 207/692 [00:05\u003c00:11, 40.57it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 210 Loss: 12.597752857208253 Accuracy: 0.051231924816966055:  31%|███       | 212/692 [00:05\u003c00:11, 40.31it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 210 Loss: 12.597752857208253 Accuracy: 0.051231924816966055:  31%|███▏      | 217/692 [00:05\u003c00:11, 40.67it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 220 Loss: 12.749685764312744 Accuracy: 0.05328378416597843:  31%|███▏      | 217/692 [00:05\u003c00:11, 40.67it/s] \u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 220 Loss: 12.749685764312744 Accuracy: 0.05328378416597843:  32%|███▏      | 222/692 [00:05\u003c00:11, 40.45it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 220 Loss: 12.749685764312744 Accuracy: 0.05328378416597843:  33%|███▎      | 227/692 [00:05\u003c00:11, 40.74it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 230 Loss: 12.69476547241211 Accuracy: 0.05292797461152077:  33%|███▎      | 227/692 [00:05\u003c00:11, 40.74it/s] \u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 230 Loss: 12.69476547241211 Accuracy: 0.05292797461152077:  34%|███▎      | 232/692 [00:05\u003c00:11, 40.34it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 230 Loss: 12.69476547241211 Accuracy: 0.05292797461152077:  34%|███▍      | 237/692 [00:05\u003c00:11, 40.56it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 240 Loss: 12.676484966278077 Accuracy: 0.05492919683456421:  34%|███▍      | 237/692 [00:05\u003c00:11, 40.56it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 240 Loss: 12.676484966278077 Accuracy: 0.05492919683456421:  35%|███▍      | 242/692 [00:05\u003c00:11, 40.29it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 240 Loss: 12.676484966278077 Accuracy: 0.05492919683456421:  36%|███▌      | 247/692 [00:06\u003c00:11, 40.21it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 250 Loss: 12.811168098449707 Accuracy: 0.05034646578133106:  36%|███▌      | 247/692 [00:06\u003c00:11, 40.21it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 250 Loss: 12.811168098449707 Accuracy: 0.05034646578133106:  36%|███▋      | 252/692 [00:06\u003c00:11, 39.89it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 250 Loss: 12.811168098449707 Accuracy: 0.05034646578133106:  37%|███▋      | 257/692 [00:06\u003c00:10, 40.31it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 260 Loss: 12.542522621154784 Accuracy: 0.05311898961663246:  37%|███▋      | 257/692 [00:06\u003c00:10, 40.31it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 260 Loss: 12.542522621154784 Accuracy: 0.05311898961663246:  38%|███▊      | 262/692 [00:06\u003c00:10, 40.02it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 260 Loss: 12.542522621154784 Accuracy: 0.05311898961663246:  39%|███▊      | 267/692 [00:06\u003c00:10, 40.22it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 270 Loss: 12.988272190093994 Accuracy: 0.04681654237210751:  39%|███▊      | 267/692 [00:06\u003c00:10, 40.22it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 270 Loss: 12.988272190093994 Accuracy: 0.04681654237210751:  39%|███▉      | 272/692 [00:06\u003c00:10, 40.03it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 270 Loss: 12.988272190093994 Accuracy: 0.04681654237210751:  40%|████      | 277/692 [00:06\u003c00:10, 40.22it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 280 Loss: 12.780582046508789 Accuracy: 0.05363128148019314:  40%|████      | 277/692 [00:06\u003c00:10, 40.22it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 280 Loss: 12.780582046508789 Accuracy: 0.05363128148019314:  41%|████      | 282/692 [00:06\u003c00:10, 40.28it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 280 Loss: 12.780582046508789 Accuracy: 0.05363128148019314:  41%|████▏     | 287/692 [00:07\u003c00:09, 40.55it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 290 Loss: 12.696910095214843 Accuracy: 0.053079815953969954:  41%|████▏     | 287/692 [00:07\u003c00:09, 40.55it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 290 Loss: 12.696910095214843 Accuracy: 0.053079815953969954:  42%|████▏     | 292/692 [00:07\u003c00:09, 40.44it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 290 Loss: 12.696910095214843 Accuracy: 0.053079815953969954:  43%|████▎     | 297/692 [00:07\u003c00:09, 40.67it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 300 Loss: 12.574166774749756 Accuracy: 0.05474382899701595:  43%|████▎     | 297/692 [00:07\u003c00:09, 40.67it/s] \u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 300 Loss: 12.574166774749756 Accuracy: 0.05474382899701595:  44%|████▎     | 302/692 [00:07\u003c00:09, 40.58it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 300 Loss: 12.574166774749756 Accuracy: 0.05474382899701595:  44%|████▍     | 307/692 [00:07\u003c00:09, 40.72it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 310 Loss: 12.722672748565675 Accuracy: 0.05512405298650265:  44%|████▍     | 307/692 [00:07\u003c00:09, 40.72it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 310 Loss: 12.722672748565675 Accuracy: 0.05512405298650265:  45%|████▌     | 312/692 [00:07\u003c00:09, 40.42it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 310 Loss: 12.722672748565675 Accuracy: 0.05512405298650265:  46%|████▌     | 317/692 [00:07\u003c00:09, 40.60it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 320 Loss: 12.74688491821289 Accuracy: 0.05086514763534069:  46%|████▌     | 317/692 [00:07\u003c00:09, 40.60it/s] \u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 320 Loss: 12.74688491821289 Accuracy: 0.05086514763534069:  47%|████▋     | 322/692 [00:07\u003c00:09, 40.53it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 320 Loss: 12.74688491821289 Accuracy: 0.05086514763534069:  47%|████▋     | 327/692 [00:08\u003c00:08, 40.68it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 330 Loss: 12.671982288360596 Accuracy: 0.05364769957959652:  47%|████▋     | 327/692 [00:08\u003c00:08, 40.68it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 330 Loss: 12.671982288360596 Accuracy: 0.05364769957959652:  48%|████▊     | 332/692 [00:08\u003c00:08, 40.44it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 330 Loss: 12.671982288360596 Accuracy: 0.05364769957959652:  49%|████▊     | 337/692 [00:08\u003c00:08, 40.69it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 340 Loss: 12.75181884765625 Accuracy: 0.05450639352202415:  49%|████▊     | 337/692 [00:08\u003c00:08, 40.69it/s] \u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 340 Loss: 12.75181884765625 Accuracy: 0.05450639352202415:  49%|████▉     | 342/692 [00:08\u003c00:08, 40.56it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 340 Loss: 12.75181884765625 Accuracy: 0.05450639352202415:  50%|█████     | 347/692 [00:08\u003c00:08, 40.83it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 350 Loss: 12.704461669921875 Accuracy: 0.0513039156794548:  50%|█████     | 347/692 [00:08\u003c00:08, 40.83it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 350 Loss: 12.704461669921875 Accuracy: 0.0513039156794548:  51%|█████     | 352/692 [00:08\u003c00:08, 40.74it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 350 Loss: 12.704461669921875 Accuracy: 0.0513039156794548:  52%|█████▏    | 357/692 [00:08\u003c00:08, 40.85it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 360 Loss: 12.850245666503906 Accuracy: 0.0530907578766346:  52%|█████▏    | 357/692 [00:08\u003c00:08, 40.85it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 360 Loss: 12.850245666503906 Accuracy: 0.0530907578766346:  52%|█████▏    | 362/692 [00:08\u003c00:08, 40.67it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 360 Loss: 12.850245666503906 Accuracy: 0.0530907578766346:  53%|█████▎    | 367/692 [00:09\u003c00:07, 40.80it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 370 Loss: 12.498008823394775 Accuracy: 0.052005039900541304:  53%|█████▎    | 367/692 [00:09\u003c00:07, 40.80it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 370 Loss: 12.498008823394775 Accuracy: 0.052005039900541304:  54%|█████▍    | 372/692 [00:09\u003c00:07, 40.47it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 370 Loss: 12.498008823394775 Accuracy: 0.052005039900541304:  54%|█████▍    | 377/692 [00:09\u003c00:07, 40.72it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 380 Loss: 12.670328712463379 Accuracy: 0.05467342361807823:  54%|█████▍    | 377/692 [00:09\u003c00:07, 40.72it/s] \u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 380 Loss: 12.670328712463379 Accuracy: 0.05467342361807823:  55%|█████▌    | 382/692 [00:09\u003c00:07, 40.52it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 380 Loss: 12.670328712463379 Accuracy: 0.05467342361807823:  56%|█████▌    | 387/692 [00:09\u003c00:07, 40.88it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 390 Loss: 12.685906410217285 Accuracy: 0.0505135502666235:  56%|█████▌    | 387/692 [00:09\u003c00:07, 40.88it/s] \u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 390 Loss: 12.685906410217285 Accuracy: 0.0505135502666235:  57%|█████▋    | 392/692 [00:09\u003c00:07, 40.50it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 390 Loss: 12.685906410217285 Accuracy: 0.0505135502666235:  57%|█████▋    | 397/692 [00:09\u003c00:07, 40.61it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 400 Loss: 12.853302478790283 Accuracy: 0.053065604716539386:  57%|█████▋    | 397/692 [00:09\u003c00:07, 40.61it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 400 Loss: 12.853302478790283 Accuracy: 0.053065604716539386:  58%|█████▊    | 402/692 [00:09\u003c00:07, 40.13it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 400 Loss: 12.853302478790283 Accuracy: 0.053065604716539386:  59%|█████▉    | 407/692 [00:10\u003c00:07, 40.25it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 410 Loss: 12.80471067428589 Accuracy: 0.05431216396391392:  59%|█████▉    | 407/692 [00:10\u003c00:07, 40.25it/s]  \u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 410 Loss: 12.80471067428589 Accuracy: 0.05431216396391392:  60%|█████▉    | 412/692 [00:10\u003c00:06, 40.07it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 410 Loss: 12.80471067428589 Accuracy: 0.05431216396391392:  60%|██████    | 417/692 [00:10\u003c00:06, 40.42it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 420 Loss: 12.53397102355957 Accuracy: 0.05216508843004704:  60%|██████    | 417/692 [00:10\u003c00:06, 40.42it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 420 Loss: 12.53397102355957 Accuracy: 0.05216508843004704:  61%|██████    | 422/692 [00:10\u003c00:06, 40.41it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 420 Loss: 12.53397102355957 Accuracy: 0.05216508843004704:  62%|██████▏   | 427/692 [00:10\u003c00:06, 40.71it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 430 Loss: 12.655214214324952 Accuracy: 0.05476362742483616:  62%|██████▏   | 427/692 [00:10\u003c00:06, 40.71it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 430 Loss: 12.655214214324952 Accuracy: 0.05476362742483616:  62%|██████▏   | 432/692 [00:10\u003c00:06, 40.49it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 430 Loss: 12.655214214324952 Accuracy: 0.05476362742483616:  63%|██████▎   | 437/692 [00:10\u003c00:06, 40.71it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 440 Loss: 12.76659631729126 Accuracy: 0.05280518420040607:  63%|██████▎   | 437/692 [00:10\u003c00:06, 40.71it/s] \u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 440 Loss: 12.76659631729126 Accuracy: 0.05280518420040607:  64%|██████▍   | 442/692 [00:10\u003c00:06, 40.53it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 440 Loss: 12.76659631729126 Accuracy: 0.05280518420040607:  65%|██████▍   | 447/692 [00:11\u003c00:06, 40.77it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 450 Loss: 12.798246383666992 Accuracy: 0.05291441045701504:  65%|██████▍   | 447/692 [00:11\u003c00:06, 40.77it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 450 Loss: 12.798246383666992 Accuracy: 0.05291441045701504:  65%|██████▌   | 452/692 [00:11\u003c00:05, 40.68it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 450 Loss: 12.798246383666992 Accuracy: 0.05291441045701504:  66%|██████▌   | 457/692 [00:11\u003c00:05, 40.78it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 460 Loss: 12.706592082977295 Accuracy: 0.050326444953680036:  66%|██████▌   | 457/692 [00:11\u003c00:05, 40.78it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 460 Loss: 12.706592082977295 Accuracy: 0.050326444953680036:  67%|██████▋   | 462/692 [00:11\u003c00:05, 40.55it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 460 Loss: 12.706592082977295 Accuracy: 0.050326444953680036:  67%|██████▋   | 467/692 [00:11\u003c00:05, 40.73it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 470 Loss: 12.662879276275635 Accuracy: 0.056110455468297:  67%|██████▋   | 467/692 [00:11\u003c00:05, 40.73it/s]   \u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 470 Loss: 12.662879276275635 Accuracy: 0.056110455468297:  68%|██████▊   | 472/692 [00:11\u003c00:05, 40.45it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 470 Loss: 12.662879276275635 Accuracy: 0.056110455468297:  69%|██████▉   | 477/692 [00:11\u003c00:05, 40.74it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 480 Loss: 12.693833065032958 Accuracy: 0.05358774326741696:  69%|██████▉   | 477/692 [00:11\u003c00:05, 40.74it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 480 Loss: 12.693833065032958 Accuracy: 0.05358774326741696:  70%|██████▉   | 482/692 [00:11\u003c00:05, 40.47it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 480 Loss: 12.693833065032958 Accuracy: 0.05358774326741696:  70%|███████   | 487/692 [00:12\u003c00:05, 40.64it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 490 Loss: 12.584970951080322 Accuracy: 0.05324365720152855:  70%|███████   | 487/692 [00:12\u003c00:05, 40.64it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 490 Loss: 12.584970951080322 Accuracy: 0.05324365720152855:  71%|███████   | 492/692 [00:12\u003c00:04, 40.29it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 490 Loss: 12.584970951080322 Accuracy: 0.05324365720152855:  72%|███████▏  | 497/692 [00:12\u003c00:04, 40.41it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 500 Loss: 12.555948734283447 Accuracy: 0.05451898276805878:  72%|███████▏  | 497/692 [00:12\u003c00:04, 40.41it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 500 Loss: 12.555948734283447 Accuracy: 0.05451898276805878:  73%|███████▎  | 502/692 [00:12\u003c00:04, 40.11it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 500 Loss: 12.555948734283447 Accuracy: 0.05451898276805878:  73%|███████▎  | 507/692 [00:12\u003c00:04, 40.39it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 510 Loss: 12.751928901672363 Accuracy: 0.05841075368225575:  73%|███████▎  | 507/692 [00:12\u003c00:04, 40.39it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 510 Loss: 12.751928901672363 Accuracy: 0.05841075368225575:  74%|███████▍  | 512/692 [00:12\u003c00:04, 39.96it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 510 Loss: 12.751928901672363 Accuracy: 0.05841075368225575:  75%|███████▍  | 517/692 [00:12\u003c00:04, 40.28it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 520 Loss: 12.719772148132325 Accuracy: 0.05519986934959888:  75%|███████▍  | 517/692 [00:12\u003c00:04, 40.28it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 520 Loss: 12.719772148132325 Accuracy: 0.05519986934959888:  75%|███████▌  | 522/692 [00:12\u003c00:04, 40.34it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 520 Loss: 12.719772148132325 Accuracy: 0.05519986934959888:  76%|███████▌  | 527/692 [00:12\u003c00:04, 40.68it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 530 Loss: 12.746448230743407 Accuracy: 0.052817003428936006:  76%|███████▌  | 527/692 [00:13\u003c00:04, 40.68it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 530 Loss: 12.746448230743407 Accuracy: 0.052817003428936006:  77%|███████▋  | 532/692 [00:13\u003c00:03, 40.40it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 530 Loss: 12.746448230743407 Accuracy: 0.052817003428936006:  78%|███████▊  | 537/692 [00:13\u003c00:03, 40.71it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 540 Loss: 12.600186347961426 Accuracy: 0.05883773826062679:  78%|███████▊  | 537/692 [00:13\u003c00:03, 40.71it/s] \u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 540 Loss: 12.600186347961426 Accuracy: 0.05883773826062679:  78%|███████▊  | 542/692 [00:13\u003c00:03, 40.56it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 540 Loss: 12.600186347961426 Accuracy: 0.05883773826062679:  79%|███████▉  | 547/692 [00:13\u003c00:03, 40.78it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 550 Loss: 12.680327892303467 Accuracy: 0.052544520050287244:  79%|███████▉  | 547/692 [00:13\u003c00:03, 40.78it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 550 Loss: 12.680327892303467 Accuracy: 0.052544520050287244:  80%|███████▉  | 552/692 [00:13\u003c00:03, 40.54it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 550 Loss: 12.680327892303467 Accuracy: 0.052544520050287244:  80%|████████  | 557/692 [00:13\u003c00:03, 40.73it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 560 Loss: 12.847017097473145 Accuracy: 0.05161631107330322:  80%|████████  | 557/692 [00:13\u003c00:03, 40.73it/s] \u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 560 Loss: 12.847017097473145 Accuracy: 0.05161631107330322:  81%|████████  | 562/692 [00:13\u003c00:03, 40.45it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 560 Loss: 12.847017097473145 Accuracy: 0.05161631107330322:  82%|████████▏ | 567/692 [00:13\u003c00:03, 40.63it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 570 Loss: 12.62434787750244 Accuracy: 0.0557943556457758:  82%|████████▏ | 567/692 [00:14\u003c00:03, 40.63it/s]  \u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 570 Loss: 12.62434787750244 Accuracy: 0.0557943556457758:  83%|████████▎ | 572/692 [00:14\u003c00:02, 40.29it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 570 Loss: 12.62434787750244 Accuracy: 0.0557943556457758:  83%|████████▎ | 577/692 [00:14\u003c00:02, 40.61it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 580 Loss: 12.703626823425292 Accuracy: 0.055902159214019774:  83%|████████▎ | 577/692 [00:14\u003c00:02, 40.61it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 580 Loss: 12.703626823425292 Accuracy: 0.055902159214019774:  84%|████████▍ | 582/692 [00:14\u003c00:02, 40.45it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 580 Loss: 12.703626823425292 Accuracy: 0.055902159214019774:  85%|████████▍ | 587/692 [00:14\u003c00:02, 40.55it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 590 Loss: 12.694943809509278 Accuracy: 0.053040291741490365:  85%|████████▍ | 587/692 [00:14\u003c00:02, 40.55it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 590 Loss: 12.694943809509278 Accuracy: 0.053040291741490365:  86%|████████▌ | 592/692 [00:14\u003c00:02, 40.34it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 590 Loss: 12.694943809509278 Accuracy: 0.053040291741490365:  86%|████████▋ | 597/692 [00:14\u003c00:02, 40.64it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 600 Loss: 12.81440896987915 Accuracy: 0.05600307136774063:  86%|████████▋ | 597/692 [00:14\u003c00:02, 40.64it/s]  \u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 600 Loss: 12.81440896987915 Accuracy: 0.05600307136774063:  87%|████████▋ | 602/692 [00:14\u003c00:02, 40.42it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 600 Loss: 12.81440896987915 Accuracy: 0.05600307136774063:  88%|████████▊ | 607/692 [00:14\u003c00:02, 40.76it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 610 Loss: 12.810384368896484 Accuracy: 0.05348545275628567:  88%|████████▊ | 607/692 [00:15\u003c00:02, 40.76it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 610 Loss: 12.810384368896484 Accuracy: 0.05348545275628567:  88%|████████▊ | 612/692 [00:15\u003c00:01, 40.74it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 610 Loss: 12.810384368896484 Accuracy: 0.05348545275628567:  89%|████████▉ | 617/692 [00:15\u003c00:01, 40.93it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 620 Loss: 12.827768707275391 Accuracy: 0.05399386659264564:  89%|████████▉ | 617/692 [00:15\u003c00:01, 40.93it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 620 Loss: 12.827768707275391 Accuracy: 0.05399386659264564:  90%|████████▉ | 622/692 [00:15\u003c00:01, 40.50it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 620 Loss: 12.827768707275391 Accuracy: 0.05399386659264564:  91%|█████████ | 627/692 [00:15\u003c00:01, 40.82it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 630 Loss: 12.661429405212402 Accuracy: 0.05330319292843342:  91%|█████████ | 627/692 [00:15\u003c00:01, 40.82it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 630 Loss: 12.661429405212402 Accuracy: 0.05330319292843342:  91%|█████████▏| 632/692 [00:15\u003c00:01, 40.54it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 630 Loss: 12.661429405212402 Accuracy: 0.05330319292843342:  92%|█████████▏| 637/692 [00:15\u003c00:01, 40.81it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 640 Loss: 12.656134605407715 Accuracy: 0.05098482929170132:  92%|█████████▏| 637/692 [00:15\u003c00:01, 40.81it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 640 Loss: 12.656134605407715 Accuracy: 0.05098482929170132:  93%|█████████▎| 642/692 [00:15\u003c00:01, 40.54it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 640 Loss: 12.656134605407715 Accuracy: 0.05098482929170132:  93%|█████████▎| 647/692 [00:15\u003c00:01, 40.66it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 650 Loss: 12.745135402679443 Accuracy: 0.050609645619988444:  93%|█████████▎| 647/692 [00:16\u003c00:01, 40.66it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 650 Loss: 12.745135402679443 Accuracy: 0.050609645619988444:  94%|█████████▍| 652/692 [00:16\u003c00:00, 40.48it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 650 Loss: 12.745135402679443 Accuracy: 0.050609645619988444:  95%|█████████▍| 657/692 [00:16\u003c00:00, 40.80it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 660 Loss: 12.733057403564453 Accuracy: 0.056715428829193115:  95%|█████████▍| 657/692 [00:16\u003c00:00, 40.80it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 660 Loss: 12.733057403564453 Accuracy: 0.056715428829193115:  96%|█████████▌| 662/692 [00:16\u003c00:00, 40.70it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 660 Loss: 12.733057403564453 Accuracy: 0.056715428829193115:  96%|█████████▋| 667/692 [00:16\u003c00:00, 40.75it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 670 Loss: 12.850161170959472 Accuracy: 0.05208292193710804:  96%|█████████▋| 667/692 [00:16\u003c00:00, 40.75it/s] \u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 670 Loss: 12.850161170959472 Accuracy: 0.05208292193710804:  97%|█████████▋| 672/692 [00:16\u003c00:00, 40.53it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 670 Loss: 12.850161170959472 Accuracy: 0.05208292193710804:  98%|█████████▊| 677/692 [00:16\u003c00:00, 40.79it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 680 Loss: 12.716904258728027 Accuracy: 0.05359850749373436:  98%|█████████▊| 677/692 [00:16\u003c00:00, 40.79it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 680 Loss: 12.716904258728027 Accuracy: 0.05359850749373436:  99%|█████████▊| 682/692 [00:16\u003c00:00, 40.14it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 680 Loss: 12.716904258728027 Accuracy: 0.05359850749373436:  99%|█████████▉| 687/692 [00:16\u003c00:00, 40.42it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 690 Loss: 12.627077865600587 Accuracy: 0.05427884347736835:  99%|█████████▉| 687/692 [00:17\u003c00:00, 40.42it/s]\u001b[A\u001b[A\n","\n","Epoch: 6 Iteration: 690 Loss: 12.627077865600587 Accuracy: 0.05427884347736835: 100%|██████████| 692/692 [00:17\u003c00:00, 40.56it/s]\n","\n","\n","  0%|          | 0/692 [00:00\u003c?, ?it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 0 Loss: 12.636592674255372 Accuracy: 0.05290267132222652:   0%|          | 0/692 [00:00\u003c?, ?it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 0 Loss: 12.636592674255372 Accuracy: 0.05290267132222652:   1%|          | 4/692 [00:00\u003c00:17, 39.92it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 0 Loss: 12.636592674255372 Accuracy: 0.05290267132222652:   1%|▏         | 9/692 [00:00\u003c00:16, 40.22it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 10 Loss: 12.513829898834228 Accuracy: 0.05232035890221596:   1%|▏         | 9/692 [00:00\u003c00:16, 40.22it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 10 Loss: 12.513829898834228 Accuracy: 0.05232035890221596:   2%|▏         | 13/692 [00:00\u003c00:17, 39.89it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 10 Loss: 12.513829898834228 Accuracy: 0.05232035890221596:   3%|▎         | 18/692 [00:00\u003c00:16, 40.33it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 20 Loss: 12.693144607543946 Accuracy: 0.05563004091382027:   3%|▎         | 18/692 [00:00\u003c00:16, 40.33it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 20 Loss: 12.693144607543946 Accuracy: 0.05563004091382027:   3%|▎         | 22/692 [00:00\u003c00:16, 39.89it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 20 Loss: 12.693144607543946 Accuracy: 0.05563004091382027:   4%|▍         | 27/692 [00:00\u003c00:16, 40.28it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 30 Loss: 12.683506774902344 Accuracy: 0.05310625918209553:   4%|▍         | 27/692 [00:00\u003c00:16, 40.28it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 30 Loss: 12.683506774902344 Accuracy: 0.05310625918209553:   4%|▍         | 31/692 [00:00\u003c00:16, 40.17it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 30 Loss: 12.683506774902344 Accuracy: 0.05310625918209553:   5%|▌         | 36/692 [00:00\u003c00:16, 40.30it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 40 Loss: 12.771651935577392 Accuracy: 0.05272793956100941:   5%|▌         | 36/692 [00:01\u003c00:16, 40.30it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 40 Loss: 12.771651935577392 Accuracy: 0.05272793956100941:   6%|▌         | 41/692 [00:01\u003c00:16, 40.36it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 40 Loss: 12.771651935577392 Accuracy: 0.05272793956100941:   7%|▋         | 46/692 [00:01\u003c00:15, 40.45it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 50 Loss: 12.864748001098633 Accuracy: 0.053104322776198386:   7%|▋         | 46/692 [00:01\u003c00:15, 40.45it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 50 Loss: 12.864748001098633 Accuracy: 0.053104322776198386:   7%|▋         | 51/692 [00:01\u003c00:15, 40.49it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 50 Loss: 12.864748001098633 Accuracy: 0.053104322776198386:   8%|▊         | 55/692 [00:01\u003c00:15, 40.34it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 50 Loss: 12.864748001098633 Accuracy: 0.053104322776198386:   9%|▊         | 60/692 [00:01\u003c00:15, 40.76it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 60 Loss: 12.720426273345947 Accuracy: 0.0540933720767498:   9%|▊         | 60/692 [00:01\u003c00:15, 40.76it/s]  \u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 60 Loss: 12.720426273345947 Accuracy: 0.0540933720767498:   9%|▉         | 65/692 [00:01\u003c00:15, 40.52it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 60 Loss: 12.720426273345947 Accuracy: 0.0540933720767498:  10%|█         | 70/692 [00:01\u003c00:15, 40.63it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 70 Loss: 12.743801498413086 Accuracy: 0.053564108535647394:  10%|█         | 70/692 [00:01\u003c00:15, 40.63it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 70 Loss: 12.743801498413086 Accuracy: 0.053564108535647394:  11%|█         | 75/692 [00:01\u003c00:15, 40.39it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 70 Loss: 12.743801498413086 Accuracy: 0.053564108535647394:  12%|█▏        | 80/692 [00:01\u003c00:15, 40.59it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 80 Loss: 12.809567546844482 Accuracy: 0.05083845369517803:  12%|█▏        | 80/692 [00:02\u003c00:15, 40.59it/s] \u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 80 Loss: 12.809567546844482 Accuracy: 0.05083845369517803:  12%|█▏        | 85/692 [00:02\u003c00:15, 40.33it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 80 Loss: 12.809567546844482 Accuracy: 0.05083845369517803:  13%|█▎        | 90/692 [00:02\u003c00:14, 40.48it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 90 Loss: 12.6144624710083 Accuracy: 0.05116716846823692:  13%|█▎        | 90/692 [00:02\u003c00:14, 40.48it/s]  \u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 90 Loss: 12.6144624710083 Accuracy: 0.05116716846823692:  14%|█▎        | 95/692 [00:02\u003c00:14, 40.18it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 90 Loss: 12.6144624710083 Accuracy: 0.05116716846823692:  14%|█▍        | 100/692 [00:02\u003c00:14, 40.47it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 100 Loss: 12.620603561401367 Accuracy: 0.055044913291931154:  14%|█▍        | 100/692 [00:02\u003c00:14, 40.47it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 100 Loss: 12.620603561401367 Accuracy: 0.055044913291931154:  15%|█▌        | 105/692 [00:02\u003c00:14, 40.33it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 100 Loss: 12.620603561401367 Accuracy: 0.055044913291931154:  16%|█▌        | 110/692 [00:02\u003c00:14, 40.54it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 110 Loss: 12.540579986572265 Accuracy: 0.05486838296055794:  16%|█▌        | 110/692 [00:02\u003c00:14, 40.54it/s] \u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 110 Loss: 12.540579986572265 Accuracy: 0.05486838296055794:  17%|█▋        | 115/692 [00:02\u003c00:14, 40.43it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 110 Loss: 12.540579986572265 Accuracy: 0.05486838296055794:  17%|█▋        | 120/692 [00:02\u003c00:14, 40.61it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 120 Loss: 12.718511962890625 Accuracy: 0.0531363096088171:  17%|█▋        | 120/692 [00:02\u003c00:14, 40.61it/s] \u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 120 Loss: 12.718511962890625 Accuracy: 0.0531363096088171:  18%|█▊        | 125/692 [00:03\u003c00:14, 40.44it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 120 Loss: 12.718511962890625 Accuracy: 0.0531363096088171:  19%|█▉        | 130/692 [00:03\u003c00:13, 40.71it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 130 Loss: 12.55183391571045 Accuracy: 0.05457486808300018:  19%|█▉        | 130/692 [00:03\u003c00:13, 40.71it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 130 Loss: 12.55183391571045 Accuracy: 0.05457486808300018:  20%|█▉        | 135/692 [00:03\u003c00:13, 40.62it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 130 Loss: 12.55183391571045 Accuracy: 0.05457486808300018:  20%|██        | 140/692 [00:03\u003c00:13, 40.73it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 140 Loss: 12.842790699005127 Accuracy: 0.05145792439579964:  20%|██        | 140/692 [00:03\u003c00:13, 40.73it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 140 Loss: 12.842790699005127 Accuracy: 0.05145792439579964:  21%|██        | 145/692 [00:03\u003c00:13, 40.57it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 140 Loss: 12.842790699005127 Accuracy: 0.05145792439579964:  22%|██▏       | 150/692 [00:03\u003c00:13, 40.80it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 150 Loss: 12.626258087158202 Accuracy: 0.051931881532073024:  22%|██▏       | 150/692 [00:03\u003c00:13, 40.80it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 150 Loss: 12.626258087158202 Accuracy: 0.051931881532073024:  22%|██▏       | 155/692 [00:03\u003c00:13, 40.72it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 150 Loss: 12.626258087158202 Accuracy: 0.051931881532073024:  23%|██▎       | 160/692 [00:03\u003c00:13, 40.87it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 160 Loss: 12.727600193023681 Accuracy: 0.05330180041491985:  23%|██▎       | 160/692 [00:03\u003c00:13, 40.87it/s] \u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 160 Loss: 12.727600193023681 Accuracy: 0.05330180041491985:  24%|██▍       | 165/692 [00:04\u003c00:13, 40.52it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 160 Loss: 12.727600193023681 Accuracy: 0.05330180041491985:  25%|██▍       | 170/692 [00:04\u003c00:12, 40.70it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 170 Loss: 12.65474328994751 Accuracy: 0.054144302010536195:  25%|██▍       | 170/692 [00:04\u003c00:12, 40.70it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 170 Loss: 12.65474328994751 Accuracy: 0.054144302010536195:  25%|██▌       | 175/692 [00:04\u003c00:12, 40.58it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 170 Loss: 12.65474328994751 Accuracy: 0.054144302010536195:  26%|██▌       | 180/692 [00:04\u003c00:12, 40.60it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 180 Loss: 12.558301830291748 Accuracy: 0.054190977662801745:  26%|██▌       | 180/692 [00:04\u003c00:12, 40.60it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 180 Loss: 12.558301830291748 Accuracy: 0.054190977662801745:  27%|██▋       | 185/692 [00:04\u003c00:12, 40.50it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 180 Loss: 12.558301830291748 Accuracy: 0.054190977662801745:  27%|██▋       | 190/692 [00:04\u003c00:12, 40.81it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 190 Loss: 12.504281997680664 Accuracy: 0.055131880566477776:  27%|██▋       | 190/692 [00:04\u003c00:12, 40.81it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 190 Loss: 12.504281997680664 Accuracy: 0.055131880566477776:  28%|██▊       | 195/692 [00:04\u003c00:12, 40.33it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 190 Loss: 12.504281997680664 Accuracy: 0.055131880566477776:  29%|██▉       | 200/692 [00:04\u003c00:12, 40.38it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 200 Loss: 12.727410125732423 Accuracy: 0.0521175455302:  29%|██▉       | 200/692 [00:04\u003c00:12, 40.38it/s]     \u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 200 Loss: 12.727410125732423 Accuracy: 0.0521175455302:  30%|██▉       | 205/692 [00:05\u003c00:12, 40.03it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 200 Loss: 12.727410125732423 Accuracy: 0.0521175455302:  30%|███       | 210/692 [00:05\u003c00:11, 40.26it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 210 Loss: 12.810090637207031 Accuracy: 0.05473674945533276:  30%|███       | 210/692 [00:05\u003c00:11, 40.26it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 210 Loss: 12.810090637207031 Accuracy: 0.05473674945533276:  31%|███       | 215/692 [00:05\u003c00:11, 40.00it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 210 Loss: 12.810090637207031 Accuracy: 0.05473674945533276:  32%|███▏      | 220/692 [00:05\u003c00:11, 40.34it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 220 Loss: 12.612920761108398 Accuracy: 0.052153171971440315:  32%|███▏      | 220/692 [00:05\u003c00:11, 40.34it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 220 Loss: 12.612920761108398 Accuracy: 0.052153171971440315:  33%|███▎      | 225/692 [00:05\u003c00:11, 40.08it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 220 Loss: 12.612920761108398 Accuracy: 0.052153171971440315:  33%|███▎      | 230/692 [00:05\u003c00:11, 40.44it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 230 Loss: 12.726102066040038 Accuracy: 0.05452214702963829:  33%|███▎      | 230/692 [00:05\u003c00:11, 40.44it/s] \u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 230 Loss: 12.726102066040038 Accuracy: 0.05452214702963829:  34%|███▍      | 235/692 [00:05\u003c00:11, 40.25it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 230 Loss: 12.726102066040038 Accuracy: 0.05452214702963829:  35%|███▍      | 240/692 [00:05\u003c00:11, 40.56it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 240 Loss: 12.595082092285157 Accuracy: 0.052433288842439654:  35%|███▍      | 240/692 [00:05\u003c00:11, 40.56it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 240 Loss: 12.595082092285157 Accuracy: 0.052433288842439654:  35%|███▌      | 245/692 [00:06\u003c00:11, 40.25it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 240 Loss: 12.595082092285157 Accuracy: 0.052433288842439654:  36%|███▌      | 250/692 [00:06\u003c00:10, 40.35it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 250 Loss: 12.504791355133056 Accuracy: 0.05168757624924183:  36%|███▌      | 250/692 [00:06\u003c00:10, 40.35it/s] \u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 250 Loss: 12.504791355133056 Accuracy: 0.05168757624924183:  37%|███▋      | 255/692 [00:06\u003c00:10, 40.12it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 250 Loss: 12.504791355133056 Accuracy: 0.05168757624924183:  38%|███▊      | 260/692 [00:06\u003c00:10, 40.57it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 260 Loss: 12.861426830291748 Accuracy: 0.05361808910965919:  38%|███▊      | 260/692 [00:06\u003c00:10, 40.57it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 260 Loss: 12.861426830291748 Accuracy: 0.05361808910965919:  38%|███▊      | 265/692 [00:06\u003c00:10, 40.44it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 260 Loss: 12.861426830291748 Accuracy: 0.05361808910965919:  39%|███▉      | 270/692 [00:06\u003c00:10, 40.68it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 270 Loss: 12.724805927276611 Accuracy: 0.049087611585855485:  39%|███▉      | 270/692 [00:06\u003c00:10, 40.68it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 270 Loss: 12.724805927276611 Accuracy: 0.049087611585855485:  40%|███▉      | 275/692 [00:06\u003c00:10, 40.33it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 270 Loss: 12.724805927276611 Accuracy: 0.049087611585855485:  40%|████      | 280/692 [00:06\u003c00:10, 40.53it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 280 Loss: 12.742756175994874 Accuracy: 0.04899505525827408:  40%|████      | 280/692 [00:06\u003c00:10, 40.53it/s] \u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 280 Loss: 12.742756175994874 Accuracy: 0.04899505525827408:  41%|████      | 285/692 [00:07\u003c00:10, 40.55it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 280 Loss: 12.742756175994874 Accuracy: 0.04899505525827408:  42%|████▏     | 290/692 [00:07\u003c00:09, 40.64it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 290 Loss: 12.674226570129395 Accuracy: 0.05398439355194569:  42%|████▏     | 290/692 [00:07\u003c00:09, 40.64it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 290 Loss: 12.674226570129395 Accuracy: 0.05398439355194569:  43%|████▎     | 295/692 [00:07\u003c00:09, 40.45it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 290 Loss: 12.674226570129395 Accuracy: 0.05398439355194569:  43%|████▎     | 300/692 [00:07\u003c00:09, 40.70it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 300 Loss: 12.843006038665772 Accuracy: 0.05341117866337299:  43%|████▎     | 300/692 [00:07\u003c00:09, 40.70it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 300 Loss: 12.843006038665772 Accuracy: 0.05341117866337299:  44%|████▍     | 305/692 [00:07\u003c00:09, 40.49it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 300 Loss: 12.843006038665772 Accuracy: 0.05341117866337299:  45%|████▍     | 310/692 [00:07\u003c00:09, 40.62it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 310 Loss: 12.549323177337646 Accuracy: 0.0553562130779028:  45%|████▍     | 310/692 [00:07\u003c00:09, 40.62it/s] \u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 310 Loss: 12.549323177337646 Accuracy: 0.0553562130779028:  46%|████▌     | 315/692 [00:07\u003c00:09, 40.37it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 310 Loss: 12.549323177337646 Accuracy: 0.0553562130779028:  46%|████▌     | 320/692 [00:07\u003c00:09, 40.48it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 320 Loss: 12.848216438293457 Accuracy: 0.05411133654415608:  46%|████▌     | 320/692 [00:07\u003c00:09, 40.48it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 320 Loss: 12.848216438293457 Accuracy: 0.05411133654415608:  47%|████▋     | 325/692 [00:08\u003c00:09, 40.34it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 320 Loss: 12.848216438293457 Accuracy: 0.05411133654415608:  48%|████▊     | 330/692 [00:08\u003c00:08, 40.54it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 330 Loss: 12.743786811828613 Accuracy: 0.05394404865801335:  48%|████▊     | 330/692 [00:08\u003c00:08, 40.54it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 330 Loss: 12.743786811828613 Accuracy: 0.05394404865801335:  48%|████▊     | 335/692 [00:08\u003c00:08, 40.36it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 330 Loss: 12.743786811828613 Accuracy: 0.05394404865801335:  49%|████▉     | 340/692 [00:08\u003c00:08, 40.60it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 340 Loss: 12.802715587615968 Accuracy: 0.05191931985318661:  49%|████▉     | 340/692 [00:08\u003c00:08, 40.60it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 340 Loss: 12.802715587615968 Accuracy: 0.05191931985318661:  50%|████▉     | 345/692 [00:08\u003c00:08, 40.46it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 340 Loss: 12.802715587615968 Accuracy: 0.05191931985318661:  51%|█████     | 350/692 [00:08\u003c00:08, 40.68it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 350 Loss: 12.77140121459961 Accuracy: 0.05448420271277428:  51%|█████     | 350/692 [00:08\u003c00:08, 40.68it/s] \u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 350 Loss: 12.77140121459961 Accuracy: 0.05448420271277428:  51%|█████▏    | 355/692 [00:08\u003c00:08, 40.54it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 350 Loss: 12.77140121459961 Accuracy: 0.05448420271277428:  52%|█████▏    | 360/692 [00:08\u003c00:08, 40.75it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 360 Loss: 12.901960182189942 Accuracy: 0.051753546297550204:  52%|█████▏    | 360/692 [00:08\u003c00:08, 40.75it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 360 Loss: 12.901960182189942 Accuracy: 0.051753546297550204:  53%|█████▎    | 365/692 [00:09\u003c00:08, 40.39it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 360 Loss: 12.901960182189942 Accuracy: 0.051753546297550204:  53%|█████▎    | 370/692 [00:09\u003c00:07, 40.73it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 370 Loss: 12.69840145111084 Accuracy: 0.05453104451298714:  53%|█████▎    | 370/692 [00:09\u003c00:07, 40.73it/s]  \u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 370 Loss: 12.69840145111084 Accuracy: 0.05453104451298714:  54%|█████▍    | 375/692 [00:09\u003c00:07, 40.47it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 370 Loss: 12.69840145111084 Accuracy: 0.05453104451298714:  55%|█████▍    | 380/692 [00:09\u003c00:07, 40.56it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 380 Loss: 12.542016124725341 Accuracy: 0.054009102284908295:  55%|█████▍    | 380/692 [00:09\u003c00:07, 40.56it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 380 Loss: 12.542016124725341 Accuracy: 0.054009102284908295:  56%|█████▌    | 385/692 [00:09\u003c00:07, 40.20it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 380 Loss: 12.542016124725341 Accuracy: 0.054009102284908295:  56%|█████▋    | 390/692 [00:09\u003c00:07, 40.49it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 390 Loss: 12.618409824371337 Accuracy: 0.05633647367358208:  56%|█████▋    | 390/692 [00:09\u003c00:07, 40.49it/s] \u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 390 Loss: 12.618409824371337 Accuracy: 0.05633647367358208:  57%|█████▋    | 395/692 [00:09\u003c00:07, 40.18it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 390 Loss: 12.618409824371337 Accuracy: 0.05633647367358208:  58%|█████▊    | 400/692 [00:09\u003c00:07, 40.50it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 400 Loss: 12.883224201202392 Accuracy: 0.05163817033171654:  58%|█████▊    | 400/692 [00:09\u003c00:07, 40.50it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 400 Loss: 12.883224201202392 Accuracy: 0.05163817033171654:  59%|█████▊    | 405/692 [00:10\u003c00:07, 40.15it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 400 Loss: 12.883224201202392 Accuracy: 0.05163817033171654:  59%|█████▉    | 410/692 [00:10\u003c00:06, 40.36it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 410 Loss: 12.589979267120361 Accuracy: 0.050453423708677295:  59%|█████▉    | 410/692 [00:10\u003c00:06, 40.36it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 410 Loss: 12.589979267120361 Accuracy: 0.050453423708677295:  60%|█████▉    | 415/692 [00:10\u003c00:06, 40.25it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 410 Loss: 12.589979267120361 Accuracy: 0.050453423708677295:  61%|██████    | 420/692 [00:10\u003c00:06, 40.53it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 420 Loss: 12.768091773986816 Accuracy: 0.05227452367544174:  61%|██████    | 420/692 [00:10\u003c00:06, 40.53it/s] \u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 420 Loss: 12.768091773986816 Accuracy: 0.05227452367544174:  61%|██████▏   | 425/692 [00:10\u003c00:06, 40.34it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 420 Loss: 12.768091773986816 Accuracy: 0.05227452367544174:  62%|██████▏   | 430/692 [00:10\u003c00:06, 40.56it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 430 Loss: 12.511158466339111 Accuracy: 0.053697682172060016:  62%|██████▏   | 430/692 [00:10\u003c00:06, 40.56it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 430 Loss: 12.511158466339111 Accuracy: 0.053697682172060016:  63%|██████▎   | 435/692 [00:10\u003c00:06, 40.46it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 430 Loss: 12.511158466339111 Accuracy: 0.053697682172060016:  64%|██████▎   | 440/692 [00:10\u003c00:06, 40.81it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 440 Loss: 12.828574752807617 Accuracy: 0.04949405863881111:  64%|██████▎   | 440/692 [00:10\u003c00:06, 40.81it/s] \u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 440 Loss: 12.828574752807617 Accuracy: 0.04949405863881111:  64%|██████▍   | 445/692 [00:10\u003c00:06, 40.61it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 440 Loss: 12.828574752807617 Accuracy: 0.04949405863881111:  65%|██████▌   | 450/692 [00:11\u003c00:05, 40.92it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 450 Loss: 12.628734493255616 Accuracy: 0.05481361486017704:  65%|██████▌   | 450/692 [00:11\u003c00:05, 40.92it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 450 Loss: 12.628734493255616 Accuracy: 0.05481361486017704:  66%|██████▌   | 455/692 [00:11\u003c00:05, 40.38it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 450 Loss: 12.628734493255616 Accuracy: 0.05481361486017704:  66%|██████▋   | 460/692 [00:11\u003c00:05, 40.67it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 460 Loss: 12.746454524993897 Accuracy: 0.05752636454999447:  66%|██████▋   | 460/692 [00:11\u003c00:05, 40.67it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 460 Loss: 12.746454524993897 Accuracy: 0.05752636454999447:  67%|██████▋   | 465/692 [00:11\u003c00:05, 40.58it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 460 Loss: 12.746454524993897 Accuracy: 0.05752636454999447:  68%|██████▊   | 470/692 [00:11\u003c00:05, 40.79it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 470 Loss: 12.661415576934814 Accuracy: 0.05101206861436367:  68%|██████▊   | 470/692 [00:11\u003c00:05, 40.79it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 470 Loss: 12.661415576934814 Accuracy: 0.05101206861436367:  69%|██████▊   | 475/692 [00:11\u003c00:05, 40.49it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 470 Loss: 12.661415576934814 Accuracy: 0.05101206861436367:  69%|██████▉   | 480/692 [00:11\u003c00:05, 40.76it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 480 Loss: 12.769553947448731 Accuracy: 0.051030271127820014:  69%|██████▉   | 480/692 [00:11\u003c00:05, 40.76it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 480 Loss: 12.769553947448731 Accuracy: 0.051030271127820014:  70%|███████   | 485/692 [00:11\u003c00:05, 40.49it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 480 Loss: 12.769553947448731 Accuracy: 0.051030271127820014:  71%|███████   | 490/692 [00:12\u003c00:04, 40.81it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 490 Loss: 12.754133129119873 Accuracy: 0.05369662269949913:  71%|███████   | 490/692 [00:12\u003c00:04, 40.81it/s] \u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 490 Loss: 12.754133129119873 Accuracy: 0.05369662269949913:  72%|███████▏  | 495/692 [00:12\u003c00:04, 40.78it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 490 Loss: 12.754133129119873 Accuracy: 0.05369662269949913:  72%|███████▏  | 500/692 [00:12\u003c00:04, 40.91it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 500 Loss: 12.707635021209716 Accuracy: 0.058588335663080214:  72%|███████▏  | 500/692 [00:12\u003c00:04, 40.91it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 500 Loss: 12.707635021209716 Accuracy: 0.058588335663080214:  73%|███████▎  | 505/692 [00:12\u003c00:04, 40.50it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 500 Loss: 12.707635021209716 Accuracy: 0.058588335663080214:  74%|███████▎  | 510/692 [00:12\u003c00:04, 40.60it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 510 Loss: 12.894558525085449 Accuracy: 0.053382234275341035:  74%|███████▎  | 510/692 [00:12\u003c00:04, 40.60it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 510 Loss: 12.894558525085449 Accuracy: 0.053382234275341035:  74%|███████▍  | 515/692 [00:12\u003c00:04, 40.39it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 510 Loss: 12.894558525085449 Accuracy: 0.053382234275341035:  75%|███████▌  | 520/692 [00:12\u003c00:04, 40.51it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 520 Loss: 12.795043849945069 Accuracy: 0.05336865894496441:  75%|███████▌  | 520/692 [00:12\u003c00:04, 40.51it/s] \u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 520 Loss: 12.795043849945069 Accuracy: 0.05336865894496441:  76%|███████▌  | 525/692 [00:12\u003c00:04, 40.45it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 520 Loss: 12.795043849945069 Accuracy: 0.05336865894496441:  77%|███████▋  | 530/692 [00:13\u003c00:03, 40.68it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 530 Loss: 12.745354270935058 Accuracy: 0.05511523932218552:  77%|███████▋  | 530/692 [00:13\u003c00:03, 40.68it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 530 Loss: 12.745354270935058 Accuracy: 0.05511523932218552:  77%|███████▋  | 535/692 [00:13\u003c00:03, 40.60it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 530 Loss: 12.745354270935058 Accuracy: 0.05511523932218552:  78%|███████▊  | 540/692 [00:13\u003c00:03, 40.61it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 540 Loss: 12.807437515258789 Accuracy: 0.056077225133776665:  78%|███████▊  | 540/692 [00:13\u003c00:03, 40.61it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 540 Loss: 12.807437515258789 Accuracy: 0.056077225133776665:  79%|███████▉  | 545/692 [00:13\u003c00:03, 40.28it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 540 Loss: 12.807437515258789 Accuracy: 0.056077225133776665:  79%|███████▉  | 550/692 [00:13\u003c00:03, 40.56it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 550 Loss: 12.662178325653077 Accuracy: 0.055509456619620326:  79%|███████▉  | 550/692 [00:13\u003c00:03, 40.56it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 550 Loss: 12.662178325653077 Accuracy: 0.055509456619620326:  80%|████████  | 555/692 [00:13\u003c00:03, 40.40it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 550 Loss: 12.662178325653077 Accuracy: 0.055509456619620326:  81%|████████  | 560/692 [00:13\u003c00:03, 40.81it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 560 Loss: 12.809469223022461 Accuracy: 0.05377121865749359:  81%|████████  | 560/692 [00:13\u003c00:03, 40.81it/s] \u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 560 Loss: 12.809469223022461 Accuracy: 0.05377121865749359:  82%|████████▏ | 565/692 [00:13\u003c00:03, 40.65it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 560 Loss: 12.809469223022461 Accuracy: 0.05377121865749359:  82%|████████▏ | 570/692 [00:14\u003c00:02, 40.92it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 570 Loss: 12.763552951812745 Accuracy: 0.055223758518695834:  82%|████████▏ | 570/692 [00:14\u003c00:02, 40.92it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 570 Loss: 12.763552951812745 Accuracy: 0.055223758518695834:  83%|████████▎ | 575/692 [00:14\u003c00:02, 40.49it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 570 Loss: 12.763552951812745 Accuracy: 0.055223758518695834:  84%|████████▍ | 580/692 [00:14\u003c00:02, 40.62it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 580 Loss: 12.617027282714844 Accuracy: 0.056314509361982346:  84%|████████▍ | 580/692 [00:14\u003c00:02, 40.62it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 580 Loss: 12.617027282714844 Accuracy: 0.056314509361982346:  85%|████████▍ | 585/692 [00:14\u003c00:02, 40.46it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 580 Loss: 12.617027282714844 Accuracy: 0.056314509361982346:  85%|████████▌ | 590/692 [00:14\u003c00:02, 40.69it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 590 Loss: 12.680407238006591 Accuracy: 0.05221052058041096:  85%|████████▌ | 590/692 [00:14\u003c00:02, 40.69it/s] \u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 590 Loss: 12.680407238006591 Accuracy: 0.05221052058041096:  86%|████████▌ | 595/692 [00:14\u003c00:02, 40.50it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 590 Loss: 12.680407238006591 Accuracy: 0.05221052058041096:  87%|████████▋ | 600/692 [00:14\u003c00:02, 40.84it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 600 Loss: 12.62754201889038 Accuracy: 0.054234423115849494:  87%|████████▋ | 600/692 [00:14\u003c00:02, 40.84it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 600 Loss: 12.62754201889038 Accuracy: 0.054234423115849494:  87%|████████▋ | 605/692 [00:14\u003c00:02, 40.48it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 600 Loss: 12.62754201889038 Accuracy: 0.054234423115849494:  88%|████████▊ | 610/692 [00:15\u003c00:02, 40.78it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 610 Loss: 12.665321922302246 Accuracy: 0.052765211835503575:  88%|████████▊ | 610/692 [00:15\u003c00:02, 40.78it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 610 Loss: 12.665321922302246 Accuracy: 0.052765211835503575:  89%|████████▉ | 615/692 [00:15\u003c00:01, 40.58it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 610 Loss: 12.665321922302246 Accuracy: 0.052765211835503575:  90%|████████▉ | 620/692 [00:15\u003c00:01, 40.71it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 620 Loss: 12.722045707702637 Accuracy: 0.05383204631507397:  90%|████████▉ | 620/692 [00:15\u003c00:01, 40.71it/s] \u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 620 Loss: 12.722045707702637 Accuracy: 0.05383204631507397:  90%|█████████ | 625/692 [00:15\u003c00:01, 40.63it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 620 Loss: 12.722045707702637 Accuracy: 0.05383204631507397:  91%|█████████ | 630/692 [00:15\u003c00:01, 40.87it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 630 Loss: 12.665154266357423 Accuracy: 0.05165923237800598:  91%|█████████ | 630/692 [00:15\u003c00:01, 40.87it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 630 Loss: 12.665154266357423 Accuracy: 0.05165923237800598:  92%|█████████▏| 635/692 [00:15\u003c00:01, 40.59it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 630 Loss: 12.665154266357423 Accuracy: 0.05165923237800598:  92%|█████████▏| 640/692 [00:15\u003c00:01, 40.66it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 640 Loss: 12.910154819488525 Accuracy: 0.05375680774450302:  92%|█████████▏| 640/692 [00:15\u003c00:01, 40.66it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 640 Loss: 12.910154819488525 Accuracy: 0.05375680774450302:  93%|█████████▎| 645/692 [00:15\u003c00:01, 40.45it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 640 Loss: 12.910154819488525 Accuracy: 0.05375680774450302:  94%|█████████▍| 650/692 [00:16\u003c00:01, 40.53it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 650 Loss: 12.798843669891358 Accuracy: 0.054538074508309366:  94%|█████████▍| 650/692 [00:16\u003c00:01, 40.53it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 650 Loss: 12.798843669891358 Accuracy: 0.054538074508309366:  95%|█████████▍| 655/692 [00:16\u003c00:00, 40.57it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 650 Loss: 12.798843669891358 Accuracy: 0.054538074508309366:  95%|█████████▌| 660/692 [00:16\u003c00:00, 40.68it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 660 Loss: 12.709198570251464 Accuracy: 0.05177858732640743:  95%|█████████▌| 660/692 [00:16\u003c00:00, 40.68it/s] \u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 660 Loss: 12.709198570251464 Accuracy: 0.05177858732640743:  96%|█████████▌| 665/692 [00:16\u003c00:00, 40.50it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 660 Loss: 12.709198570251464 Accuracy: 0.05177858732640743:  97%|█████████▋| 670/692 [00:16\u003c00:00, 40.75it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 670 Loss: 12.671801090240479 Accuracy: 0.04999401979148388:  97%|█████████▋| 670/692 [00:16\u003c00:00, 40.75it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 670 Loss: 12.671801090240479 Accuracy: 0.04999401979148388:  98%|█████████▊| 675/692 [00:16\u003c00:00, 40.49it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 670 Loss: 12.671801090240479 Accuracy: 0.04999401979148388:  98%|█████████▊| 680/692 [00:16\u003c00:00, 40.52it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 680 Loss: 12.70179271697998 Accuracy: 0.05232505314052105:  98%|█████████▊| 680/692 [00:16\u003c00:00, 40.52it/s] \u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 680 Loss: 12.70179271697998 Accuracy: 0.05232505314052105:  99%|█████████▉| 685/692 [00:16\u003c00:00, 40.35it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 680 Loss: 12.70179271697998 Accuracy: 0.05232505314052105: 100%|█████████▉| 690/692 [00:17\u003c00:00, 40.83it/s]\u001b[A\u001b[A\n","\n","Epoch: 7 Iteration: 690 Loss: 12.827110290527344 Accuracy: 0.053923101350665095: 100%|██████████| 692/692 [00:17\u003c00:00, 40.52it/s]\n","\n","\n","  0%|          | 0/692 [00:00\u003c?, ?it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 0 Loss: 12.831565856933594 Accuracy: 0.05352161228656769:   0%|          | 0/692 [00:00\u003c?, ?it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 0 Loss: 12.831565856933594 Accuracy: 0.05352161228656769:   1%|          | 4/692 [00:00\u003c00:17, 39.83it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 0 Loss: 12.831565856933594 Accuracy: 0.05352161228656769:   1%|▏         | 9/692 [00:00\u003c00:16, 40.21it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 10 Loss: 12.710015678405762 Accuracy: 0.056875625625252724:   1%|▏         | 9/692 [00:00\u003c00:16, 40.21it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 10 Loss: 12.710015678405762 Accuracy: 0.056875625625252724:   2%|▏         | 13/692 [00:00\u003c00:17, 39.90it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 10 Loss: 12.710015678405762 Accuracy: 0.056875625625252724:   3%|▎         | 18/692 [00:00\u003c00:16, 40.35it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 20 Loss: 12.769204711914062 Accuracy: 0.052151371538639066:   3%|▎         | 18/692 [00:00\u003c00:16, 40.35it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 20 Loss: 12.769204711914062 Accuracy: 0.052151371538639066:   3%|▎         | 22/692 [00:00\u003c00:16, 40.13it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 20 Loss: 12.769204711914062 Accuracy: 0.052151371538639066:   4%|▍         | 27/692 [00:00\u003c00:16, 40.44it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 30 Loss: 12.74726448059082 Accuracy: 0.05351161658763885:   4%|▍         | 27/692 [00:00\u003c00:16, 40.44it/s]  \u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 30 Loss: 12.74726448059082 Accuracy: 0.05351161658763885:   5%|▍         | 32/692 [00:00\u003c00:16, 40.38it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 30 Loss: 12.74726448059082 Accuracy: 0.05351161658763885:   5%|▌         | 37/692 [00:00\u003c00:16, 40.49it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 40 Loss: 12.747048664093018 Accuracy: 0.051919367536902426:   5%|▌         | 37/692 [00:01\u003c00:16, 40.49it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 40 Loss: 12.747048664093018 Accuracy: 0.051919367536902426:   6%|▌         | 41/692 [00:01\u003c00:16, 40.28it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 40 Loss: 12.747048664093018 Accuracy: 0.051919367536902426:   7%|▋         | 45/692 [00:01\u003c00:16, 40.17it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 40 Loss: 12.747048664093018 Accuracy: 0.051919367536902426:   7%|▋         | 50/692 [00:01\u003c00:15, 40.46it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 50 Loss: 12.790887832641602 Accuracy: 0.05334493070840836:   7%|▋         | 50/692 [00:01\u003c00:15, 40.46it/s] \u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 50 Loss: 12.790887832641602 Accuracy: 0.05334493070840836:   8%|▊         | 54/692 [00:01\u003c00:15, 39.97it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 50 Loss: 12.790887832641602 Accuracy: 0.05334493070840836:   9%|▊         | 59/692 [00:01\u003c00:15, 40.36it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 60 Loss: 12.653525447845459 Accuracy: 0.05264199897646904:   9%|▊         | 59/692 [00:01\u003c00:15, 40.36it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 60 Loss: 12.653525447845459 Accuracy: 0.05264199897646904:   9%|▉         | 64/692 [00:01\u003c00:15, 40.17it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 60 Loss: 12.653525447845459 Accuracy: 0.05264199897646904:  10%|▉         | 69/692 [00:01\u003c00:15, 40.64it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 70 Loss: 12.64893388748169 Accuracy: 0.05383473373949528:  10%|▉         | 69/692 [00:01\u003c00:15, 40.64it/s] \u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 70 Loss: 12.64893388748169 Accuracy: 0.05383473373949528:  11%|█         | 74/692 [00:01\u003c00:15, 40.46it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 70 Loss: 12.64893388748169 Accuracy: 0.05383473373949528:  11%|█▏        | 79/692 [00:01\u003c00:15, 40.76it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 80 Loss: 12.705622959136964 Accuracy: 0.05827754586935043:  11%|█▏        | 79/692 [00:02\u003c00:15, 40.76it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 80 Loss: 12.705622959136964 Accuracy: 0.05827754586935043:  12%|█▏        | 84/692 [00:02\u003c00:15, 40.48it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 80 Loss: 12.705622959136964 Accuracy: 0.05827754586935043:  13%|█▎        | 89/692 [00:02\u003c00:14, 40.73it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 90 Loss: 12.675472164154053 Accuracy: 0.05450564473867416:  13%|█▎        | 89/692 [00:02\u003c00:14, 40.73it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 90 Loss: 12.675472164154053 Accuracy: 0.05450564473867416:  14%|█▎        | 94/692 [00:02\u003c00:14, 40.06it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 90 Loss: 12.675472164154053 Accuracy: 0.05450564473867416:  14%|█▍        | 99/692 [00:02\u003c00:14, 40.47it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 100 Loss: 12.67385835647583 Accuracy: 0.05651272572577:  14%|█▍        | 99/692 [00:02\u003c00:14, 40.47it/s]   \u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 100 Loss: 12.67385835647583 Accuracy: 0.05651272572577:  15%|█▌        | 104/692 [00:02\u003c00:14, 40.13it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 100 Loss: 12.67385835647583 Accuracy: 0.05651272572577:  16%|█▌        | 109/692 [00:02\u003c00:14, 40.33it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 110 Loss: 12.678349876403809 Accuracy: 0.054960797727108004:  16%|█▌        | 109/692 [00:02\u003c00:14, 40.33it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 110 Loss: 12.678349876403809 Accuracy: 0.054960797727108004:  16%|█▋        | 114/692 [00:02\u003c00:14, 39.93it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 110 Loss: 12.678349876403809 Accuracy: 0.054960797727108004:  17%|█▋        | 119/692 [00:02\u003c00:14, 40.19it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 120 Loss: 12.799308013916015 Accuracy: 0.05139699950814247:  17%|█▋        | 119/692 [00:02\u003c00:14, 40.19it/s] \u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 120 Loss: 12.799308013916015 Accuracy: 0.05139699950814247:  18%|█▊        | 124/692 [00:03\u003c00:14, 40.25it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 120 Loss: 12.799308013916015 Accuracy: 0.05139699950814247:  19%|█▊        | 129/692 [00:03\u003c00:13, 40.48it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 130 Loss: 12.78411922454834 Accuracy: 0.05433331020176411:  19%|█▊        | 129/692 [00:03\u003c00:13, 40.48it/s] \u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 130 Loss: 12.78411922454834 Accuracy: 0.05433331020176411:  19%|█▉        | 134/692 [00:03\u003c00:13, 40.31it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 130 Loss: 12.78411922454834 Accuracy: 0.05433331020176411:  20%|██        | 139/692 [00:03\u003c00:13, 40.62it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 140 Loss: 12.638501071929932 Accuracy: 0.05346459522843361:  20%|██        | 139/692 [00:03\u003c00:13, 40.62it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 140 Loss: 12.638501071929932 Accuracy: 0.05346459522843361:  21%|██        | 144/692 [00:03\u003c00:13, 40.49it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 140 Loss: 12.638501071929932 Accuracy: 0.05346459522843361:  22%|██▏       | 149/692 [00:03\u003c00:13, 40.68it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 150 Loss: 12.960037326812744 Accuracy: 0.05190853923559189:  22%|██▏       | 149/692 [00:03\u003c00:13, 40.68it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 150 Loss: 12.960037326812744 Accuracy: 0.05190853923559189:  22%|██▏       | 154/692 [00:03\u003c00:13, 40.45it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 150 Loss: 12.960037326812744 Accuracy: 0.05190853923559189:  23%|██▎       | 159/692 [00:03\u003c00:13, 40.69it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 160 Loss: 12.695814514160157 Accuracy: 0.050453486293554305:  23%|██▎       | 159/692 [00:03\u003c00:13, 40.69it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 160 Loss: 12.695814514160157 Accuracy: 0.050453486293554305:  24%|██▎       | 164/692 [00:04\u003c00:13, 40.30it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 160 Loss: 12.695814514160157 Accuracy: 0.050453486293554305:  24%|██▍       | 169/692 [00:04\u003c00:12, 40.51it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 170 Loss: 12.608098888397217 Accuracy: 0.05021274499595165:  24%|██▍       | 169/692 [00:04\u003c00:12, 40.51it/s] \u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 170 Loss: 12.608098888397217 Accuracy: 0.05021274499595165:  25%|██▌       | 174/692 [00:04\u003c00:12, 40.53it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 170 Loss: 12.608098888397217 Accuracy: 0.05021274499595165:  26%|██▌       | 179/692 [00:04\u003c00:12, 40.74it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 180 Loss: 12.88665828704834 Accuracy: 0.05228644944727421:  26%|██▌       | 179/692 [00:04\u003c00:12, 40.74it/s] \u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 180 Loss: 12.88665828704834 Accuracy: 0.05228644944727421:  27%|██▋       | 184/692 [00:04\u003c00:12, 40.36it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 180 Loss: 12.88665828704834 Accuracy: 0.05228644944727421:  27%|██▋       | 189/692 [00:04\u003c00:12, 40.59it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 190 Loss: 12.719367027282715 Accuracy: 0.05413459986448288:  27%|██▋       | 189/692 [00:04\u003c00:12, 40.59it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 190 Loss: 12.719367027282715 Accuracy: 0.05413459986448288:  28%|██▊       | 194/692 [00:04\u003c00:12, 40.50it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 190 Loss: 12.719367027282715 Accuracy: 0.05413459986448288:  29%|██▉       | 199/692 [00:04\u003c00:12, 40.68it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 200 Loss: 12.682092666625977 Accuracy: 0.04967826530337334:  29%|██▉       | 199/692 [00:04\u003c00:12, 40.68it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 200 Loss: 12.682092666625977 Accuracy: 0.04967826530337334:  29%|██▉       | 204/692 [00:05\u003c00:12, 39.88it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 200 Loss: 12.682092666625977 Accuracy: 0.04967826530337334:  30%|███       | 209/692 [00:05\u003c00:11, 40.34it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 210 Loss: 12.80277509689331 Accuracy: 0.05303286612033844:  30%|███       | 209/692 [00:05\u003c00:11, 40.34it/s] \u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 210 Loss: 12.80277509689331 Accuracy: 0.05303286612033844:  31%|███       | 214/692 [00:05\u003c00:11, 40.02it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 210 Loss: 12.80277509689331 Accuracy: 0.05303286612033844:  32%|███▏      | 219/692 [00:05\u003c00:11, 40.40it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 220 Loss: 12.722185420989991 Accuracy: 0.05315325818955898:  32%|███▏      | 219/692 [00:05\u003c00:11, 40.40it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 220 Loss: 12.722185420989991 Accuracy: 0.05315325818955898:  32%|███▏      | 224/692 [00:05\u003c00:11, 40.34it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 220 Loss: 12.722185420989991 Accuracy: 0.05315325818955898:  33%|███▎      | 229/692 [00:05\u003c00:11, 40.63it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 230 Loss: 12.72546911239624 Accuracy: 0.05773249641060829:  33%|███▎      | 229/692 [00:05\u003c00:11, 40.63it/s] \u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 230 Loss: 12.72546911239624 Accuracy: 0.05773249641060829:  34%|███▍      | 234/692 [00:05\u003c00:11, 40.42it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 230 Loss: 12.72546911239624 Accuracy: 0.05773249641060829:  35%|███▍      | 239/692 [00:05\u003c00:11, 40.74it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 240 Loss: 12.541155147552491 Accuracy: 0.04943226203322411:  35%|███▍      | 239/692 [00:05\u003c00:11, 40.74it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 240 Loss: 12.541155147552491 Accuracy: 0.04943226203322411:  35%|███▌      | 244/692 [00:06\u003c00:11, 40.27it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 240 Loss: 12.541155147552491 Accuracy: 0.04943226203322411:  36%|███▌      | 249/692 [00:06\u003c00:10, 40.59it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 250 Loss: 12.760385322570801 Accuracy: 0.050736642256379125:  36%|███▌      | 249/692 [00:06\u003c00:10, 40.59it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 250 Loss: 12.760385322570801 Accuracy: 0.050736642256379125:  37%|███▋      | 254/692 [00:06\u003c00:10, 40.41it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 250 Loss: 12.760385322570801 Accuracy: 0.050736642256379125:  37%|███▋      | 259/692 [00:06\u003c00:10, 40.68it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 260 Loss: 12.800665855407715 Accuracy: 0.05226122103631496:  37%|███▋      | 259/692 [00:06\u003c00:10, 40.68it/s] \u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 260 Loss: 12.800665855407715 Accuracy: 0.05226122103631496:  38%|███▊      | 264/692 [00:06\u003c00:10, 40.31it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 260 Loss: 12.800665855407715 Accuracy: 0.05226122103631496:  39%|███▉      | 269/692 [00:06\u003c00:10, 40.58it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 270 Loss: 12.808076000213623 Accuracy: 0.053557568788528444:  39%|███▉      | 269/692 [00:06\u003c00:10, 40.58it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 270 Loss: 12.808076000213623 Accuracy: 0.053557568788528444:  40%|███▉      | 274/692 [00:06\u003c00:10, 40.36it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 270 Loss: 12.808076000213623 Accuracy: 0.053557568788528444:  40%|████      | 279/692 [00:06\u003c00:10, 40.62it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 280 Loss: 12.601225757598877 Accuracy: 0.05449998155236244:  40%|████      | 279/692 [00:06\u003c00:10, 40.62it/s] \u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 280 Loss: 12.601225757598877 Accuracy: 0.05449998155236244:  41%|████      | 284/692 [00:07\u003c00:10, 40.47it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 280 Loss: 12.601225757598877 Accuracy: 0.05449998155236244:  42%|████▏     | 289/692 [00:07\u003c00:09, 40.87it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 290 Loss: 12.869054985046386 Accuracy: 0.05476651825010777:  42%|████▏     | 289/692 [00:07\u003c00:09, 40.87it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 290 Loss: 12.869054985046386 Accuracy: 0.05476651825010777:  42%|████▏     | 294/692 [00:07\u003c00:09, 40.62it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 290 Loss: 12.869054985046386 Accuracy: 0.05476651825010777:  43%|████▎     | 299/692 [00:07\u003c00:09, 40.81it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 300 Loss: 12.638376617431641 Accuracy: 0.05063819587230682:  43%|████▎     | 299/692 [00:07\u003c00:09, 40.81it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 300 Loss: 12.638376617431641 Accuracy: 0.05063819587230682:  44%|████▍     | 304/692 [00:07\u003c00:09, 40.64it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 300 Loss: 12.638376617431641 Accuracy: 0.05063819587230682:  45%|████▍     | 309/692 [00:07\u003c00:09, 40.74it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 310 Loss: 12.535404205322266 Accuracy: 0.05231947861611843:  45%|████▍     | 309/692 [00:07\u003c00:09, 40.74it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 310 Loss: 12.535404205322266 Accuracy: 0.05231947861611843:  45%|████▌     | 314/692 [00:07\u003c00:09, 40.32it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 310 Loss: 12.535404205322266 Accuracy: 0.05231947861611843:  46%|████▌     | 319/692 [00:07\u003c00:09, 40.53it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 320 Loss: 12.63176441192627 Accuracy: 0.0496483389288187:  46%|████▌     | 319/692 [00:07\u003c00:09, 40.53it/s]  \u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 320 Loss: 12.63176441192627 Accuracy: 0.0496483389288187:  47%|████▋     | 324/692 [00:08\u003c00:09, 40.26it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 320 Loss: 12.63176441192627 Accuracy: 0.0496483389288187:  48%|████▊     | 329/692 [00:08\u003c00:08, 40.52it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 330 Loss: 12.590349197387695 Accuracy: 0.05416090004146099:  48%|████▊     | 329/692 [00:08\u003c00:08, 40.52it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 330 Loss: 12.590349197387695 Accuracy: 0.05416090004146099:  48%|████▊     | 334/692 [00:08\u003c00:08, 40.41it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 330 Loss: 12.590349197387695 Accuracy: 0.05416090004146099:  49%|████▉     | 339/692 [00:08\u003c00:08, 40.86it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 340 Loss: 12.681875801086425 Accuracy: 0.05495696552097797:  49%|████▉     | 339/692 [00:08\u003c00:08, 40.86it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 340 Loss: 12.681875801086425 Accuracy: 0.05495696552097797:  50%|████▉     | 344/692 [00:08\u003c00:08, 40.53it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 340 Loss: 12.681875801086425 Accuracy: 0.05495696552097797:  50%|█████     | 349/692 [00:08\u003c00:08, 40.67it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 350 Loss: 12.731328105926513 Accuracy: 0.052307537943124774:  50%|█████     | 349/692 [00:08\u003c00:08, 40.67it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 350 Loss: 12.731328105926513 Accuracy: 0.052307537943124774:  51%|█████     | 354/692 [00:08\u003c00:08, 40.41it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 350 Loss: 12.731328105926513 Accuracy: 0.052307537943124774:  52%|█████▏    | 359/692 [00:08\u003c00:08, 40.67it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 360 Loss: 12.86777982711792 Accuracy: 0.05378893166780472:  52%|█████▏    | 359/692 [00:08\u003c00:08, 40.67it/s]  \u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 360 Loss: 12.86777982711792 Accuracy: 0.05378893166780472:  53%|█████▎    | 364/692 [00:08\u003c00:08, 40.42it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 360 Loss: 12.86777982711792 Accuracy: 0.05378893166780472:  53%|█████▎    | 369/692 [00:09\u003c00:07, 40.71it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 370 Loss: 12.698482227325439 Accuracy: 0.052543172240257265:  53%|█████▎    | 369/692 [00:09\u003c00:07, 40.71it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 370 Loss: 12.698482227325439 Accuracy: 0.052543172240257265:  54%|█████▍    | 374/692 [00:09\u003c00:07, 40.37it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 370 Loss: 12.698482227325439 Accuracy: 0.052543172240257265:  55%|█████▍    | 379/692 [00:09\u003c00:07, 40.59it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 380 Loss: 12.710755538940429 Accuracy: 0.053077549859881404:  55%|█████▍    | 379/692 [00:09\u003c00:07, 40.59it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 380 Loss: 12.710755538940429 Accuracy: 0.053077549859881404:  55%|█████▌    | 384/692 [00:09\u003c00:07, 40.27it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 380 Loss: 12.710755538940429 Accuracy: 0.053077549859881404:  56%|█████▌    | 389/692 [00:09\u003c00:07, 40.60it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 390 Loss: 12.58006238937378 Accuracy: 0.054640522226691246:  56%|█████▌    | 389/692 [00:09\u003c00:07, 40.60it/s] \u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 390 Loss: 12.58006238937378 Accuracy: 0.054640522226691246:  57%|█████▋    | 394/692 [00:09\u003c00:07, 40.32it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 390 Loss: 12.58006238937378 Accuracy: 0.054640522226691246:  58%|█████▊    | 399/692 [00:09\u003c00:07, 40.58it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 400 Loss: 12.683477592468261 Accuracy: 0.05428818613290787:  58%|█████▊    | 399/692 [00:09\u003c00:07, 40.58it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 400 Loss: 12.683477592468261 Accuracy: 0.05428818613290787:  58%|█████▊    | 404/692 [00:09\u003c00:07, 40.35it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 400 Loss: 12.683477592468261 Accuracy: 0.05428818613290787:  59%|█████▉    | 409/692 [00:10\u003c00:06, 40.58it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 410 Loss: 12.623797988891601 Accuracy: 0.05460354499518871:  59%|█████▉    | 409/692 [00:10\u003c00:06, 40.58it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 410 Loss: 12.623797988891601 Accuracy: 0.05460354499518871:  60%|█████▉    | 414/692 [00:10\u003c00:06, 40.20it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 410 Loss: 12.623797988891601 Accuracy: 0.05460354499518871:  61%|██████    | 419/692 [00:10\u003c00:06, 40.37it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 420 Loss: 12.570027542114257 Accuracy: 0.05528124868869781:  61%|██████    | 419/692 [00:10\u003c00:06, 40.37it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 420 Loss: 12.570027542114257 Accuracy: 0.05528124868869781:  61%|██████▏   | 424/692 [00:10\u003c00:06, 39.97it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 420 Loss: 12.570027542114257 Accuracy: 0.05528124868869781:  62%|██████▏   | 429/692 [00:10\u003c00:06, 40.37it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 430 Loss: 12.589561939239502 Accuracy: 0.05624581165611744:  62%|██████▏   | 429/692 [00:10\u003c00:06, 40.37it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 430 Loss: 12.589561939239502 Accuracy: 0.05624581165611744:  63%|██████▎   | 434/692 [00:10\u003c00:06, 40.11it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 430 Loss: 12.589561939239502 Accuracy: 0.05624581165611744:  63%|██████▎   | 439/692 [00:10\u003c00:06, 40.41it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 440 Loss: 12.539065170288087 Accuracy: 0.057643501460552214:  63%|██████▎   | 439/692 [00:10\u003c00:06, 40.41it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 440 Loss: 12.539065170288087 Accuracy: 0.057643501460552214:  64%|██████▍   | 444/692 [00:10\u003c00:06, 40.21it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 440 Loss: 12.539065170288087 Accuracy: 0.057643501460552214:  65%|██████▍   | 449/692 [00:11\u003c00:06, 40.37it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 450 Loss: 12.764643478393555 Accuracy: 0.05687872879207134:  65%|██████▍   | 449/692 [00:11\u003c00:06, 40.37it/s] \u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 450 Loss: 12.764643478393555 Accuracy: 0.05687872879207134:  66%|██████▌   | 454/692 [00:11\u003c00:05, 40.01it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 450 Loss: 12.764643478393555 Accuracy: 0.05687872879207134:  66%|██████▋   | 459/692 [00:11\u003c00:05, 39.73it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 460 Loss: 12.820175266265869 Accuracy: 0.0528643861413002:  66%|██████▋   | 459/692 [00:11\u003c00:05, 39.73it/s] \u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 460 Loss: 12.820175266265869 Accuracy: 0.0528643861413002:  67%|██████▋   | 463/692 [00:11\u003c00:05, 39.31it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 460 Loss: 12.820175266265869 Accuracy: 0.0528643861413002:  68%|██████▊   | 468/692 [00:11\u003c00:05, 39.68it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 470 Loss: 12.519201850891113 Accuracy: 0.05435957051813602:  68%|██████▊   | 468/692 [00:11\u003c00:05, 39.68it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 470 Loss: 12.519201850891113 Accuracy: 0.05435957051813602:  68%|██████▊   | 472/692 [00:11\u003c00:05, 39.31it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 470 Loss: 12.519201850891113 Accuracy: 0.05435957051813602:  69%|██████▉   | 477/692 [00:11\u003c00:05, 39.64it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 480 Loss: 12.569202709197999 Accuracy: 0.05257133543491364:  69%|██████▉   | 477/692 [00:11\u003c00:05, 39.64it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 480 Loss: 12.569202709197999 Accuracy: 0.05257133543491364:  70%|██████▉   | 481/692 [00:11\u003c00:05, 39.31it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 480 Loss: 12.569202709197999 Accuracy: 0.05257133543491364:  70%|███████   | 485/692 [00:12\u003c00:05, 39.38it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 480 Loss: 12.569202709197999 Accuracy: 0.05257133543491364:  71%|███████   | 490/692 [00:12\u003c00:05, 39.76it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 490 Loss: 12.910585403442383 Accuracy: 0.05012531019747257:  71%|███████   | 490/692 [00:12\u003c00:05, 39.76it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 490 Loss: 12.910585403442383 Accuracy: 0.05012531019747257:  71%|███████▏  | 494/692 [00:12\u003c00:05, 39.36it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 490 Loss: 12.910585403442383 Accuracy: 0.05012531019747257:  72%|███████▏  | 499/692 [00:12\u003c00:04, 39.90it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 500 Loss: 12.735103702545166 Accuracy: 0.04937063492834568:  72%|███████▏  | 499/692 [00:12\u003c00:04, 39.90it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 500 Loss: 12.735103702545166 Accuracy: 0.04937063492834568:  73%|███████▎  | 503/692 [00:12\u003c00:04, 39.50it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 500 Loss: 12.735103702545166 Accuracy: 0.04937063492834568:  73%|███████▎  | 508/692 [00:12\u003c00:04, 39.97it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 510 Loss: 12.867526531219482 Accuracy: 0.051512598246335986:  73%|███████▎  | 508/692 [00:12\u003c00:04, 39.97it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 510 Loss: 12.867526531219482 Accuracy: 0.051512598246335986:  74%|███████▍  | 513/692 [00:12\u003c00:04, 39.67it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 510 Loss: 12.867526531219482 Accuracy: 0.051512598246335986:  75%|███████▍  | 518/692 [00:12\u003c00:04, 40.08it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 520 Loss: 12.650286006927491 Accuracy: 0.04952168427407742:  75%|███████▍  | 518/692 [00:12\u003c00:04, 40.08it/s] \u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 520 Loss: 12.650286006927491 Accuracy: 0.04952168427407742:  76%|███████▌  | 523/692 [00:12\u003c00:04, 40.08it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 520 Loss: 12.650286006927491 Accuracy: 0.04952168427407742:  76%|███████▋  | 528/692 [00:13\u003c00:04, 40.21it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 530 Loss: 12.681753253936767 Accuracy: 0.050726236402988435:  76%|███████▋  | 528/692 [00:13\u003c00:04, 40.21it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 530 Loss: 12.681753253936767 Accuracy: 0.050726236402988435:  77%|███████▋  | 533/692 [00:13\u003c00:03, 40.06it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 530 Loss: 12.681753253936767 Accuracy: 0.050726236402988435:  78%|███████▊  | 538/692 [00:13\u003c00:03, 40.35it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 540 Loss: 12.849773597717284 Accuracy: 0.0548514686524868:  78%|███████▊  | 538/692 [00:13\u003c00:03, 40.35it/s]  \u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 540 Loss: 12.849773597717284 Accuracy: 0.0548514686524868:  78%|███████▊  | 543/692 [00:13\u003c00:03, 40.28it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 540 Loss: 12.849773597717284 Accuracy: 0.0548514686524868:  79%|███████▉  | 548/692 [00:13\u003c00:03, 40.31it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 550 Loss: 12.711626625061035 Accuracy: 0.051199422031641004:  79%|███████▉  | 548/692 [00:13\u003c00:03, 40.31it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 550 Loss: 12.711626625061035 Accuracy: 0.051199422031641004:  80%|███████▉  | 553/692 [00:13\u003c00:03, 39.91it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 550 Loss: 12.711626625061035 Accuracy: 0.051199422031641004:  80%|████████  | 557/692 [00:13\u003c00:03, 39.94it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 560 Loss: 12.758720684051514 Accuracy: 0.05395611226558685:  80%|████████  | 557/692 [00:13\u003c00:03, 39.94it/s] \u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 560 Loss: 12.758720684051514 Accuracy: 0.05395611226558685:  81%|████████  | 561/692 [00:13\u003c00:03, 39.75it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 560 Loss: 12.758720684051514 Accuracy: 0.05395611226558685:  82%|████████▏ | 565/692 [00:14\u003c00:03, 39.70it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 560 Loss: 12.758720684051514 Accuracy: 0.05395611226558685:  82%|████████▏ | 570/692 [00:14\u003c00:03, 39.92it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 570 Loss: 12.57742099761963 Accuracy: 0.05428969860076904:  82%|████████▏ | 570/692 [00:14\u003c00:03, 39.92it/s] \u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 570 Loss: 12.57742099761963 Accuracy: 0.05428969860076904:  83%|████████▎ | 574/692 [00:14\u003c00:02, 39.52it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 570 Loss: 12.57742099761963 Accuracy: 0.05428969860076904:  84%|████████▎ | 579/692 [00:14\u003c00:02, 40.00it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 580 Loss: 12.71934471130371 Accuracy: 0.05391359627246857:  84%|████████▎ | 579/692 [00:14\u003c00:02, 40.00it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 580 Loss: 12.71934471130371 Accuracy: 0.05391359627246857:  84%|████████▍ | 584/692 [00:14\u003c00:02, 39.72it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 580 Loss: 12.71934471130371 Accuracy: 0.05391359627246857:  85%|████████▌ | 589/692 [00:14\u003c00:02, 40.13it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 590 Loss: 12.859680938720704 Accuracy: 0.053222008794546125:  85%|████████▌ | 589/692 [00:14\u003c00:02, 40.13it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 590 Loss: 12.859680938720704 Accuracy: 0.053222008794546125:  86%|████████▌ | 594/692 [00:14\u003c00:02, 39.95it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 590 Loss: 12.859680938720704 Accuracy: 0.053222008794546125:  87%|████████▋ | 599/692 [00:14\u003c00:02, 40.23it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 600 Loss: 12.614633941650391 Accuracy: 0.05569540001451969:  87%|████████▋ | 599/692 [00:14\u003c00:02, 40.23it/s] \u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 600 Loss: 12.614633941650391 Accuracy: 0.05569540001451969:  87%|████████▋ | 604/692 [00:14\u003c00:02, 40.00it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 600 Loss: 12.614633941650391 Accuracy: 0.05569540001451969:  88%|████████▊ | 609/692 [00:15\u003c00:02, 40.44it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 610 Loss: 12.715846538543701 Accuracy: 0.05598008073866367:  88%|████████▊ | 609/692 [00:15\u003c00:02, 40.44it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 610 Loss: 12.715846538543701 Accuracy: 0.05598008073866367:  89%|████████▊ | 614/692 [00:15\u003c00:01, 40.13it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 610 Loss: 12.715846538543701 Accuracy: 0.05598008073866367:  89%|████████▉ | 619/692 [00:15\u003c00:01, 40.45it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 620 Loss: 12.591335010528564 Accuracy: 0.05417957752943039:  89%|████████▉ | 619/692 [00:15\u003c00:01, 40.45it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 620 Loss: 12.591335010528564 Accuracy: 0.05417957752943039:  90%|█████████ | 624/692 [00:15\u003c00:01, 40.22it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 620 Loss: 12.591335010528564 Accuracy: 0.05417957752943039:  91%|█████████ | 629/692 [00:15\u003c00:01, 40.60it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 630 Loss: 12.876177406311035 Accuracy: 0.05140409842133522:  91%|█████████ | 629/692 [00:15\u003c00:01, 40.60it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 630 Loss: 12.876177406311035 Accuracy: 0.05140409842133522:  92%|█████████▏| 634/692 [00:15\u003c00:01, 40.30it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 630 Loss: 12.876177406311035 Accuracy: 0.05140409842133522:  92%|█████████▏| 639/692 [00:15\u003c00:01, 40.47it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 640 Loss: 12.637942886352539 Accuracy: 0.05279744900763035:  92%|█████████▏| 639/692 [00:15\u003c00:01, 40.47it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 640 Loss: 12.637942886352539 Accuracy: 0.05279744900763035:  93%|█████████▎| 644/692 [00:15\u003c00:01, 40.18it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 640 Loss: 12.637942886352539 Accuracy: 0.05279744900763035:  94%|█████████▍| 649/692 [00:16\u003c00:01, 40.35it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 650 Loss: 12.64331521987915 Accuracy: 0.05523027740418911:  94%|█████████▍| 649/692 [00:16\u003c00:01, 40.35it/s] \u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 650 Loss: 12.64331521987915 Accuracy: 0.05523027740418911:  95%|█████████▍| 654/692 [00:16\u003c00:00, 40.13it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 650 Loss: 12.64331521987915 Accuracy: 0.05523027740418911:  95%|█████████▌| 659/692 [00:16\u003c00:00, 40.35it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 660 Loss: 12.732262134552002 Accuracy: 0.05313713178038597:  95%|█████████▌| 659/692 [00:16\u003c00:00, 40.35it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 660 Loss: 12.732262134552002 Accuracy: 0.05313713178038597:  96%|█████████▌| 664/692 [00:16\u003c00:00, 40.12it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 660 Loss: 12.732262134552002 Accuracy: 0.05313713178038597:  97%|█████████▋| 669/692 [00:16\u003c00:00, 40.55it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 670 Loss: 12.733834552764893 Accuracy: 0.05218115709722042:  97%|█████████▋| 669/692 [00:16\u003c00:00, 40.55it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 670 Loss: 12.733834552764893 Accuracy: 0.05218115709722042:  97%|█████████▋| 674/692 [00:16\u003c00:00, 40.48it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 670 Loss: 12.733834552764893 Accuracy: 0.05218115709722042:  98%|█████████▊| 679/692 [00:16\u003c00:00, 40.72it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 680 Loss: 12.839939594268799 Accuracy: 0.054225800558924675:  98%|█████████▊| 679/692 [00:16\u003c00:00, 40.72it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 680 Loss: 12.839939594268799 Accuracy: 0.054225800558924675:  99%|█████████▉| 684/692 [00:16\u003c00:00, 40.63it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 680 Loss: 12.839939594268799 Accuracy: 0.054225800558924675: 100%|█████████▉| 689/692 [00:17\u003c00:00, 40.52it/s]\u001b[A\u001b[A\n","\n","Epoch: 8 Iteration: 690 Loss: 12.716628932952881 Accuracy: 0.055213816463947296: 100%|██████████| 692/692 [00:17\u003c00:00, 40.31it/s]\n","\n","\n","  0%|          | 0/692 [00:00\u003c?, ?it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 0 Loss: 12.771188735961914 Accuracy: 0.05595874674618244:   0%|          | 0/692 [00:00\u003c?, ?it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 0 Loss: 12.771188735961914 Accuracy: 0.05595874674618244:   1%|          | 4/692 [00:00\u003c00:17, 39.32it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 0 Loss: 12.771188735961914 Accuracy: 0.05595874674618244:   1%|▏         | 9/692 [00:00\u003c00:17, 39.78it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 10 Loss: 12.747167873382569 Accuracy: 0.053663090243935584:   1%|▏         | 9/692 [00:00\u003c00:17, 39.78it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 10 Loss: 12.747167873382569 Accuracy: 0.053663090243935584:   2%|▏         | 13/692 [00:00\u003c00:17, 39.67it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 10 Loss: 12.747167873382569 Accuracy: 0.053663090243935584:   3%|▎         | 18/692 [00:00\u003c00:16, 40.19it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 20 Loss: 12.714864826202392 Accuracy: 0.05696835145354271:   3%|▎         | 18/692 [00:00\u003c00:16, 40.19it/s] \u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 20 Loss: 12.714864826202392 Accuracy: 0.05696835145354271:   3%|▎         | 22/692 [00:00\u003c00:16, 39.88it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 20 Loss: 12.714864826202392 Accuracy: 0.05696835145354271:   4%|▍         | 27/692 [00:00\u003c00:16, 40.11it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 30 Loss: 12.815641307830811 Accuracy: 0.05323404185473919:   4%|▍         | 27/692 [00:00\u003c00:16, 40.11it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 30 Loss: 12.815641307830811 Accuracy: 0.05323404185473919:   5%|▍         | 32/692 [00:00\u003c00:16, 40.13it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 30 Loss: 12.815641307830811 Accuracy: 0.05323404185473919:   5%|▌         | 37/692 [00:00\u003c00:16, 40.25it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 40 Loss: 12.827927684783935 Accuracy: 0.056161534413695334:   5%|▌         | 37/692 [00:01\u003c00:16, 40.25it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 40 Loss: 12.827927684783935 Accuracy: 0.056161534413695334:   6%|▌         | 42/692 [00:01\u003c00:16, 40.21it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 40 Loss: 12.827927684783935 Accuracy: 0.056161534413695334:   7%|▋         | 47/692 [00:01\u003c00:15, 40.41it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 50 Loss: 12.780201244354249 Accuracy: 0.05320142842829227:   7%|▋         | 47/692 [00:01\u003c00:15, 40.41it/s] \u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 50 Loss: 12.780201244354249 Accuracy: 0.05320142842829227:   8%|▊         | 52/692 [00:01\u003c00:15, 40.36it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 50 Loss: 12.780201244354249 Accuracy: 0.05320142842829227:   8%|▊         | 57/692 [00:01\u003c00:15, 40.53it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 60 Loss: 12.670907878875733 Accuracy: 0.05043497681617737:   8%|▊         | 57/692 [00:01\u003c00:15, 40.53it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 60 Loss: 12.670907878875733 Accuracy: 0.05043497681617737:   9%|▉         | 61/692 [00:01\u003c00:15, 40.17it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 60 Loss: 12.670907878875733 Accuracy: 0.05043497681617737:   9%|▉         | 65/692 [00:01\u003c00:15, 39.94it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 60 Loss: 12.670907878875733 Accuracy: 0.05043497681617737:  10%|█         | 70/692 [00:01\u003c00:15, 40.40it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 70 Loss: 12.703042888641358 Accuracy: 0.054748058691620825:  10%|█         | 70/692 [00:01\u003c00:15, 40.40it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 70 Loss: 12.703042888641358 Accuracy: 0.054748058691620825:  11%|█         | 75/692 [00:01\u003c00:15, 40.29it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 70 Loss: 12.703042888641358 Accuracy: 0.054748058691620825:  12%|█▏        | 80/692 [00:01\u003c00:15, 40.62it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 80 Loss: 12.661427021026611 Accuracy: 0.05306141451001167:  12%|█▏        | 80/692 [00:02\u003c00:15, 40.62it/s] \u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 80 Loss: 12.661427021026611 Accuracy: 0.05306141451001167:  12%|█▏        | 85/692 [00:02\u003c00:14, 40.48it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 80 Loss: 12.661427021026611 Accuracy: 0.05306141451001167:  13%|█▎        | 90/692 [00:02\u003c00:14, 40.68it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 90 Loss: 12.534259033203124 Accuracy: 0.05082183368504047:  13%|█▎        | 90/692 [00:02\u003c00:14, 40.68it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 90 Loss: 12.534259033203124 Accuracy: 0.05082183368504047:  14%|█▎        | 95/692 [00:02\u003c00:14, 40.36it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 90 Loss: 12.534259033203124 Accuracy: 0.05082183368504047:  14%|█▍        | 100/692 [00:02\u003c00:14, 40.69it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 100 Loss: 12.657558250427247 Accuracy: 0.05427616238594055:  14%|█▍        | 100/692 [00:02\u003c00:14, 40.69it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 100 Loss: 12.657558250427247 Accuracy: 0.05427616238594055:  15%|█▌        | 105/692 [00:02\u003c00:14, 40.47it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 100 Loss: 12.657558250427247 Accuracy: 0.05427616238594055:  16%|█▌        | 110/692 [00:02\u003c00:14, 40.71it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 110 Loss: 12.7161714553833 Accuracy: 0.053469497337937356:  16%|█▌        | 110/692 [00:02\u003c00:14, 40.71it/s] \u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 110 Loss: 12.7161714553833 Accuracy: 0.053469497337937356:  17%|█▋        | 115/692 [00:02\u003c00:14, 40.32it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 110 Loss: 12.7161714553833 Accuracy: 0.053469497337937356:  17%|█▋        | 120/692 [00:02\u003c00:14, 40.57it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 120 Loss: 12.830953884124757 Accuracy: 0.04937484189867973:  17%|█▋        | 120/692 [00:02\u003c00:14, 40.57it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 120 Loss: 12.830953884124757 Accuracy: 0.04937484189867973:  18%|█▊        | 125/692 [00:03\u003c00:14, 40.49it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 120 Loss: 12.830953884124757 Accuracy: 0.04937484189867973:  19%|█▉        | 130/692 [00:03\u003c00:13, 40.76it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 130 Loss: 12.585806941986084 Accuracy: 0.05513635165989399:  19%|█▉        | 130/692 [00:03\u003c00:13, 40.76it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 130 Loss: 12.585806941986084 Accuracy: 0.05513635165989399:  20%|█▉        | 135/692 [00:03\u003c00:13, 40.62it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 130 Loss: 12.585806941986084 Accuracy: 0.05513635165989399:  20%|██        | 140/692 [00:03\u003c00:13, 40.78it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 140 Loss: 12.612089061737061 Accuracy: 0.05890487544238567:  20%|██        | 140/692 [00:03\u003c00:13, 40.78it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 140 Loss: 12.612089061737061 Accuracy: 0.05890487544238567:  21%|██        | 145/692 [00:03\u003c00:13, 40.49it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 140 Loss: 12.612089061737061 Accuracy: 0.05890487544238567:  22%|██▏       | 150/692 [00:03\u003c00:13, 40.64it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 150 Loss: 12.791918468475341 Accuracy: 0.05314941555261612:  22%|██▏       | 150/692 [00:03\u003c00:13, 40.64it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 150 Loss: 12.791918468475341 Accuracy: 0.05314941555261612:  22%|██▏       | 155/692 [00:03\u003c00:13, 40.41it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 150 Loss: 12.791918468475341 Accuracy: 0.05314941555261612:  23%|██▎       | 160/692 [00:03\u003c00:13, 40.69it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 160 Loss: 12.711519908905029 Accuracy: 0.05344262644648552:  23%|██▎       | 160/692 [00:03\u003c00:13, 40.69it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 160 Loss: 12.711519908905029 Accuracy: 0.05344262644648552:  24%|██▍       | 165/692 [00:04\u003c00:13, 40.41it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 160 Loss: 12.711519908905029 Accuracy: 0.05344262644648552:  25%|██▍       | 170/692 [00:04\u003c00:12, 40.69it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 170 Loss: 12.698575687408447 Accuracy: 0.05408135689795017:  25%|██▍       | 170/692 [00:04\u003c00:12, 40.69it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 170 Loss: 12.698575687408447 Accuracy: 0.05408135689795017:  25%|██▌       | 175/692 [00:04\u003c00:12, 40.55it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 170 Loss: 12.698575687408447 Accuracy: 0.05408135689795017:  26%|██▌       | 180/692 [00:04\u003c00:12, 40.79it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 180 Loss: 12.775623512268066 Accuracy: 0.05092272199690342:  26%|██▌       | 180/692 [00:04\u003c00:12, 40.79it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 180 Loss: 12.775623512268066 Accuracy: 0.05092272199690342:  27%|██▋       | 185/692 [00:04\u003c00:12, 40.31it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 180 Loss: 12.775623512268066 Accuracy: 0.05092272199690342:  27%|██▋       | 190/692 [00:04\u003c00:12, 40.59it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 190 Loss: 12.818397331237794 Accuracy: 0.05394978411495686:  27%|██▋       | 190/692 [00:04\u003c00:12, 40.59it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 190 Loss: 12.818397331237794 Accuracy: 0.05394978411495686:  28%|██▊       | 195/692 [00:04\u003c00:12, 40.14it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 190 Loss: 12.818397331237794 Accuracy: 0.05394978411495686:  29%|██▉       | 200/692 [00:04\u003c00:12, 40.36it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 200 Loss: 12.721963214874268 Accuracy: 0.05135784782469273:  29%|██▉       | 200/692 [00:04\u003c00:12, 40.36it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 200 Loss: 12.721963214874268 Accuracy: 0.05135784782469273:  30%|██▉       | 205/692 [00:05\u003c00:12, 39.62it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 200 Loss: 12.721963214874268 Accuracy: 0.05135784782469273:  30%|███       | 210/692 [00:05\u003c00:12, 39.99it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 210 Loss: 12.705206680297852 Accuracy: 0.053460221737623215:  30%|███       | 210/692 [00:05\u003c00:12, 39.99it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 210 Loss: 12.705206680297852 Accuracy: 0.053460221737623215:  31%|███       | 215/692 [00:05\u003c00:11, 40.00it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 210 Loss: 12.705206680297852 Accuracy: 0.053460221737623215:  32%|███▏      | 220/692 [00:05\u003c00:11, 40.27it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 220 Loss: 12.878531455993652 Accuracy: 0.05557892099022865:  32%|███▏      | 220/692 [00:05\u003c00:11, 40.27it/s] \u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 220 Loss: 12.878531455993652 Accuracy: 0.05557892099022865:  33%|███▎      | 225/692 [00:05\u003c00:11, 40.25it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 220 Loss: 12.878531455993652 Accuracy: 0.05557892099022865:  33%|███▎      | 230/692 [00:05\u003c00:11, 40.63it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 230 Loss: 12.750122261047363 Accuracy: 0.057677824050188065:  33%|███▎      | 230/692 [00:05\u003c00:11, 40.63it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 230 Loss: 12.750122261047363 Accuracy: 0.057677824050188065:  34%|███▍      | 235/692 [00:05\u003c00:11, 40.45it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 230 Loss: 12.750122261047363 Accuracy: 0.057677824050188065:  35%|███▍      | 240/692 [00:05\u003c00:11, 40.62it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 240 Loss: 12.85505256652832 Accuracy: 0.05088094919919968:  35%|███▍      | 240/692 [00:05\u003c00:11, 40.62it/s]  \u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 240 Loss: 12.85505256652832 Accuracy: 0.05088094919919968:  35%|███▌      | 245/692 [00:06\u003c00:11, 40.56it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 240 Loss: 12.85505256652832 Accuracy: 0.05088094919919968:  36%|███▌      | 250/692 [00:06\u003c00:10, 40.59it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 250 Loss: 12.520902633666992 Accuracy: 0.05394766107201576:  36%|███▌      | 250/692 [00:06\u003c00:10, 40.59it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 250 Loss: 12.520902633666992 Accuracy: 0.05394766107201576:  37%|███▋      | 255/692 [00:06\u003c00:10, 40.49it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 250 Loss: 12.520902633666992 Accuracy: 0.05394766107201576:  38%|███▊      | 260/692 [00:06\u003c00:10, 40.73it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 260 Loss: 12.684704780578613 Accuracy: 0.05574686452746391:  38%|███▊      | 260/692 [00:06\u003c00:10, 40.73it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 260 Loss: 12.684704780578613 Accuracy: 0.05574686452746391:  38%|███▊      | 265/692 [00:06\u003c00:10, 40.50it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 260 Loss: 12.684704780578613 Accuracy: 0.05574686452746391:  39%|███▉      | 270/692 [00:06\u003c00:10, 40.70it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 270 Loss: 12.7398850440979 Accuracy: 0.053654416278004644:  39%|███▉      | 270/692 [00:06\u003c00:10, 40.70it/s] \u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 270 Loss: 12.7398850440979 Accuracy: 0.053654416278004644:  40%|███▉      | 275/692 [00:06\u003c00:10, 40.51it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 270 Loss: 12.7398850440979 Accuracy: 0.053654416278004644:  40%|████      | 280/692 [00:06\u003c00:10, 40.75it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 280 Loss: 12.67289113998413 Accuracy: 0.05507213994860649:  40%|████      | 280/692 [00:06\u003c00:10, 40.75it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 280 Loss: 12.67289113998413 Accuracy: 0.05507213994860649:  41%|████      | 285/692 [00:07\u003c00:10, 40.52it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 280 Loss: 12.67289113998413 Accuracy: 0.05507213994860649:  42%|████▏     | 290/692 [00:07\u003c00:09, 40.80it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 290 Loss: 12.618302249908448 Accuracy: 0.05603194385766983:  42%|████▏     | 290/692 [00:07\u003c00:09, 40.80it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 290 Loss: 12.618302249908448 Accuracy: 0.05603194385766983:  43%|████▎     | 295/692 [00:07\u003c00:09, 40.56it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 290 Loss: 12.618302249908448 Accuracy: 0.05603194385766983:  43%|████▎     | 300/692 [00:07\u003c00:09, 40.88it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 300 Loss: 12.91119441986084 Accuracy: 0.05167142301797867:  43%|████▎     | 300/692 [00:07\u003c00:09, 40.88it/s] \u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 300 Loss: 12.91119441986084 Accuracy: 0.05167142301797867:  44%|████▍     | 305/692 [00:07\u003c00:09, 40.60it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 300 Loss: 12.91119441986084 Accuracy: 0.05167142301797867:  45%|████▍     | 310/692 [00:07\u003c00:09, 40.73it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 310 Loss: 12.720253562927246 Accuracy: 0.054984016716480254:  45%|████▍     | 310/692 [00:07\u003c00:09, 40.73it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 310 Loss: 12.720253562927246 Accuracy: 0.054984016716480254:  46%|████▌     | 315/692 [00:07\u003c00:09, 40.45it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 310 Loss: 12.720253562927246 Accuracy: 0.054984016716480254:  46%|████▌     | 320/692 [00:07\u003c00:09, 40.74it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 320 Loss: 12.675616264343262 Accuracy: 0.05350777879357338:  46%|████▌     | 320/692 [00:07\u003c00:09, 40.74it/s] \u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 320 Loss: 12.675616264343262 Accuracy: 0.05350777879357338:  47%|████▋     | 325/692 [00:08\u003c00:09, 40.56it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 320 Loss: 12.675616264343262 Accuracy: 0.05350777879357338:  48%|████▊     | 330/692 [00:08\u003c00:08, 40.78it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 330 Loss: 12.556950569152832 Accuracy: 0.0543230913579464:  48%|████▊     | 330/692 [00:08\u003c00:08, 40.78it/s] \u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 330 Loss: 12.556950569152832 Accuracy: 0.0543230913579464:  48%|████▊     | 335/692 [00:08\u003c00:08, 40.43it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 330 Loss: 12.556950569152832 Accuracy: 0.0543230913579464:  49%|████▉     | 340/692 [00:08\u003c00:08, 40.80it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 340 Loss: 12.80787467956543 Accuracy: 0.05441858321428299:  49%|████▉     | 340/692 [00:08\u003c00:08, 40.80it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 340 Loss: 12.80787467956543 Accuracy: 0.05441858321428299:  50%|████▉     | 345/692 [00:08\u003c00:08, 40.49it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 340 Loss: 12.80787467956543 Accuracy: 0.05441858321428299:  51%|█████     | 350/692 [00:08\u003c00:08, 40.76it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 350 Loss: 12.887888145446777 Accuracy: 0.051899983733892444:  51%|█████     | 350/692 [00:08\u003c00:08, 40.76it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 350 Loss: 12.887888145446777 Accuracy: 0.051899983733892444:  51%|█████▏    | 355/692 [00:08\u003c00:08, 40.55it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 350 Loss: 12.887888145446777 Accuracy: 0.051899983733892444:  52%|█████▏    | 360/692 [00:08\u003c00:08, 40.70it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 360 Loss: 12.73745231628418 Accuracy: 0.05288345701992512:  52%|█████▏    | 360/692 [00:08\u003c00:08, 40.70it/s]  \u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 360 Loss: 12.73745231628418 Accuracy: 0.05288345701992512:  53%|█████▎    | 365/692 [00:09\u003c00:08, 40.32it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 360 Loss: 12.73745231628418 Accuracy: 0.05288345701992512:  53%|█████▎    | 370/692 [00:09\u003c00:07, 40.58it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 370 Loss: 12.704160499572755 Accuracy: 0.051166871562600136:  53%|█████▎    | 370/692 [00:09\u003c00:07, 40.58it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 370 Loss: 12.704160499572755 Accuracy: 0.051166871562600136:  54%|█████▍    | 375/692 [00:09\u003c00:07, 40.31it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 370 Loss: 12.704160499572755 Accuracy: 0.051166871562600136:  55%|█████▍    | 380/692 [00:09\u003c00:07, 40.51it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 380 Loss: 12.732170009613037 Accuracy: 0.04998435825109482:  55%|█████▍    | 380/692 [00:09\u003c00:07, 40.51it/s] \u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 380 Loss: 12.732170009613037 Accuracy: 0.04998435825109482:  56%|█████▌    | 385/692 [00:09\u003c00:07, 40.32it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 380 Loss: 12.732170009613037 Accuracy: 0.04998435825109482:  56%|█████▋    | 390/692 [00:09\u003c00:07, 40.55it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 390 Loss: 12.670378017425538 Accuracy: 0.0537410669028759:  56%|█████▋    | 390/692 [00:09\u003c00:07, 40.55it/s] \u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 390 Loss: 12.670378017425538 Accuracy: 0.0537410669028759:  57%|█████▋    | 395/692 [00:09\u003c00:07, 40.54it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 390 Loss: 12.670378017425538 Accuracy: 0.0537410669028759:  58%|█████▊    | 400/692 [00:09\u003c00:07, 40.72it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 400 Loss: 12.67386989593506 Accuracy: 0.0519341342151165:  58%|█████▊    | 400/692 [00:09\u003c00:07, 40.72it/s] \u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 400 Loss: 12.67386989593506 Accuracy: 0.0519341342151165:  59%|█████▊    | 405/692 [00:10\u003c00:07, 40.47it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 400 Loss: 12.67386989593506 Accuracy: 0.0519341342151165:  59%|█████▉    | 410/692 [00:10\u003c00:06, 40.70it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 410 Loss: 12.661611938476563 Accuracy: 0.052885768562555314:  59%|█████▉    | 410/692 [00:10\u003c00:06, 40.70it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 410 Loss: 12.661611938476563 Accuracy: 0.052885768562555314:  60%|█████▉    | 415/692 [00:10\u003c00:06, 40.42it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 410 Loss: 12.661611938476563 Accuracy: 0.052885768562555314:  61%|██████    | 420/692 [00:10\u003c00:06, 40.70it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 420 Loss: 12.817074966430663 Accuracy: 0.05371133200824261:  61%|██████    | 420/692 [00:10\u003c00:06, 40.70it/s] \u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 420 Loss: 12.817074966430663 Accuracy: 0.05371133200824261:  61%|██████▏   | 425/692 [00:10\u003c00:06, 40.50it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 420 Loss: 12.817074966430663 Accuracy: 0.05371133200824261:  62%|██████▏   | 430/692 [00:10\u003c00:06, 40.77it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 430 Loss: 12.69647150039673 Accuracy: 0.05215921215713024:  62%|██████▏   | 430/692 [00:10\u003c00:06, 40.77it/s] \u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 430 Loss: 12.69647150039673 Accuracy: 0.05215921215713024:  63%|██████▎   | 435/692 [00:10\u003c00:06, 40.45it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 430 Loss: 12.69647150039673 Accuracy: 0.05215921215713024:  64%|██████▎   | 440/692 [00:10\u003c00:06, 40.66it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 440 Loss: 12.850767040252686 Accuracy: 0.053610118478536604:  64%|██████▎   | 440/692 [00:10\u003c00:06, 40.66it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 440 Loss: 12.850767040252686 Accuracy: 0.053610118478536604:  64%|██████▍   | 445/692 [00:10\u003c00:06, 40.42it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 440 Loss: 12.850767040252686 Accuracy: 0.053610118478536604:  65%|██████▌   | 450/692 [00:11\u003c00:05, 40.70it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 450 Loss: 12.770908737182618 Accuracy: 0.05124240070581436:  65%|██████▌   | 450/692 [00:11\u003c00:05, 40.70it/s] \u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 450 Loss: 12.770908737182618 Accuracy: 0.05124240070581436:  66%|██████▌   | 455/692 [00:11\u003c00:05, 40.65it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 450 Loss: 12.770908737182618 Accuracy: 0.05124240070581436:  66%|██████▋   | 460/692 [00:11\u003c00:05, 40.85it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 460 Loss: 12.631125736236573 Accuracy: 0.0508598979562521:  66%|██████▋   | 460/692 [00:11\u003c00:05, 40.85it/s] \u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 460 Loss: 12.631125736236573 Accuracy: 0.0508598979562521:  67%|██████▋   | 465/692 [00:11\u003c00:05, 40.58it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 460 Loss: 12.631125736236573 Accuracy: 0.0508598979562521:  68%|██████▊   | 470/692 [00:11\u003c00:05, 40.77it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 470 Loss: 12.594459724426269 Accuracy: 0.05578699707984924:  68%|██████▊   | 470/692 [00:11\u003c00:05, 40.77it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 470 Loss: 12.594459724426269 Accuracy: 0.05578699707984924:  69%|██████▊   | 475/692 [00:11\u003c00:05, 40.67it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 470 Loss: 12.594459724426269 Accuracy: 0.05578699707984924:  69%|██████▉   | 480/692 [00:11\u003c00:05, 40.94it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 480 Loss: 12.72122163772583 Accuracy: 0.04740722291171551:  69%|██████▉   | 480/692 [00:11\u003c00:05, 40.94it/s] \u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 480 Loss: 12.72122163772583 Accuracy: 0.04740722291171551:  70%|███████   | 485/692 [00:11\u003c00:05, 40.79it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 480 Loss: 12.72122163772583 Accuracy: 0.04740722291171551:  71%|███████   | 490/692 [00:12\u003c00:04, 41.06it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 490 Loss: 12.743436717987061 Accuracy: 0.05314214825630188:  71%|███████   | 490/692 [00:12\u003c00:04, 41.06it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 490 Loss: 12.743436717987061 Accuracy: 0.05314214825630188:  72%|███████▏  | 495/692 [00:12\u003c00:04, 40.76it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 490 Loss: 12.743436717987061 Accuracy: 0.05314214825630188:  72%|███████▏  | 500/692 [00:12\u003c00:04, 40.79it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 500 Loss: 12.740796089172363 Accuracy: 0.05376110263168812:  72%|███████▏  | 500/692 [00:12\u003c00:04, 40.79it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 500 Loss: 12.740796089172363 Accuracy: 0.05376110263168812:  73%|███████▎  | 505/692 [00:12\u003c00:04, 40.77it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 500 Loss: 12.740796089172363 Accuracy: 0.05376110263168812:  74%|███████▎  | 510/692 [00:12\u003c00:04, 40.94it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 510 Loss: 12.739703559875489 Accuracy: 0.051286714151501656:  74%|███████▎  | 510/692 [00:12\u003c00:04, 40.94it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 510 Loss: 12.739703559875489 Accuracy: 0.051286714151501656:  74%|███████▍  | 515/692 [00:12\u003c00:04, 40.56it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 510 Loss: 12.739703559875489 Accuracy: 0.051286714151501656:  75%|███████▌  | 520/692 [00:12\u003c00:04, 40.92it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 520 Loss: 12.549731349945068 Accuracy: 0.05058455765247345:  75%|███████▌  | 520/692 [00:12\u003c00:04, 40.92it/s] \u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 520 Loss: 12.549731349945068 Accuracy: 0.05058455765247345:  76%|███████▌  | 525/692 [00:12\u003c00:04, 40.58it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 520 Loss: 12.549731349945068 Accuracy: 0.05058455765247345:  77%|███████▋  | 530/692 [00:13\u003c00:03, 40.84it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 530 Loss: 12.654119682312011 Accuracy: 0.054858763515949246:  77%|███████▋  | 530/692 [00:13\u003c00:03, 40.84it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 530 Loss: 12.654119682312011 Accuracy: 0.054858763515949246:  77%|███████▋  | 535/692 [00:13\u003c00:03, 40.60it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 530 Loss: 12.654119682312011 Accuracy: 0.054858763515949246:  78%|███████▊  | 540/692 [00:13\u003c00:03, 40.84it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 540 Loss: 12.684618759155274 Accuracy: 0.055449002981185914:  78%|███████▊  | 540/692 [00:13\u003c00:03, 40.84it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 540 Loss: 12.684618759155274 Accuracy: 0.055449002981185914:  79%|███████▉  | 545/692 [00:13\u003c00:03, 40.56it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 540 Loss: 12.684618759155274 Accuracy: 0.055449002981185914:  79%|███████▉  | 550/692 [00:13\u003c00:03, 40.87it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 550 Loss: 12.686615467071533 Accuracy: 0.04999449513852596:  79%|███████▉  | 550/692 [00:13\u003c00:03, 40.87it/s] \u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 550 Loss: 12.686615467071533 Accuracy: 0.04999449513852596:  80%|████████  | 555/692 [00:13\u003c00:03, 40.63it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 550 Loss: 12.686615467071533 Accuracy: 0.04999449513852596:  81%|████████  | 560/692 [00:13\u003c00:03, 40.91it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 560 Loss: 12.677283000946044 Accuracy: 0.05458374619483948:  81%|████████  | 560/692 [00:13\u003c00:03, 40.91it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 560 Loss: 12.677283000946044 Accuracy: 0.05458374619483948:  82%|████████▏ | 565/692 [00:13\u003c00:03, 40.57it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 560 Loss: 12.677283000946044 Accuracy: 0.05458374619483948:  82%|████████▏ | 570/692 [00:14\u003c00:02, 40.79it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 570 Loss: 12.653024768829345 Accuracy: 0.05092230774462223:  82%|████████▏ | 570/692 [00:14\u003c00:02, 40.79it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 570 Loss: 12.653024768829345 Accuracy: 0.05092230774462223:  83%|████████▎ | 575/692 [00:14\u003c00:02, 40.51it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 570 Loss: 12.653024768829345 Accuracy: 0.05092230774462223:  84%|████████▍ | 580/692 [00:14\u003c00:02, 40.79it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 580 Loss: 12.651733016967773 Accuracy: 0.057095106691122055:  84%|████████▍ | 580/692 [00:14\u003c00:02, 40.79it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 580 Loss: 12.651733016967773 Accuracy: 0.057095106691122055:  85%|████████▍ | 585/692 [00:14\u003c00:02, 40.46it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 580 Loss: 12.651733016967773 Accuracy: 0.057095106691122055:  85%|████████▌ | 590/692 [00:14\u003c00:02, 40.55it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 590 Loss: 12.595500373840332 Accuracy: 0.052897161617875096:  85%|████████▌ | 590/692 [00:14\u003c00:02, 40.55it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 590 Loss: 12.595500373840332 Accuracy: 0.052897161617875096:  86%|████████▌ | 595/692 [00:14\u003c00:02, 40.39it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 590 Loss: 12.595500373840332 Accuracy: 0.052897161617875096:  87%|████████▋ | 600/692 [00:14\u003c00:02, 40.66it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 600 Loss: 12.632598972320556 Accuracy: 0.05382655635476112:  87%|████████▋ | 600/692 [00:14\u003c00:02, 40.66it/s] \u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 600 Loss: 12.632598972320556 Accuracy: 0.05382655635476112:  87%|████████▋ | 605/692 [00:14\u003c00:02, 40.21it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 600 Loss: 12.632598972320556 Accuracy: 0.05382655635476112:  88%|████████▊ | 610/692 [00:15\u003c00:02, 40.52it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 610 Loss: 12.640552711486816 Accuracy: 0.05574110187590122:  88%|████████▊ | 610/692 [00:15\u003c00:02, 40.52it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 610 Loss: 12.640552711486816 Accuracy: 0.05574110187590122:  89%|████████▉ | 615/692 [00:15\u003c00:01, 40.35it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 610 Loss: 12.640552711486816 Accuracy: 0.05574110187590122:  90%|████████▉ | 620/692 [00:15\u003c00:01, 40.62it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 620 Loss: 12.641345882415772 Accuracy: 0.05315760523080826:  90%|████████▉ | 620/692 [00:15\u003c00:01, 40.62it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 620 Loss: 12.641345882415772 Accuracy: 0.05315760523080826:  90%|█████████ | 625/692 [00:15\u003c00:01, 40.48it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 620 Loss: 12.641345882415772 Accuracy: 0.05315760523080826:  91%|█████████ | 630/692 [00:15\u003c00:01, 40.82it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 630 Loss: 12.767692375183106 Accuracy: 0.05201948955655098:  91%|█████████ | 630/692 [00:15\u003c00:01, 40.82it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 630 Loss: 12.767692375183106 Accuracy: 0.05201948955655098:  92%|█████████▏| 635/692 [00:15\u003c00:01, 40.71it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 630 Loss: 12.767692375183106 Accuracy: 0.05201948955655098:  92%|█████████▏| 640/692 [00:15\u003c00:01, 40.90it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 640 Loss: 12.829744815826416 Accuracy: 0.05185932070016861:  92%|█████████▏| 640/692 [00:15\u003c00:01, 40.90it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 640 Loss: 12.829744815826416 Accuracy: 0.05185932070016861:  93%|█████████▎| 645/692 [00:15\u003c00:01, 40.61it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 640 Loss: 12.829744815826416 Accuracy: 0.05185932070016861:  94%|█████████▍| 650/692 [00:16\u003c00:01, 40.59it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 650 Loss: 12.58550148010254 Accuracy: 0.05815217904746532:  94%|█████████▍| 650/692 [00:16\u003c00:01, 40.59it/s] \u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 650 Loss: 12.58550148010254 Accuracy: 0.05815217904746532:  95%|█████████▍| 655/692 [00:16\u003c00:00, 40.42it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 650 Loss: 12.58550148010254 Accuracy: 0.05815217904746532:  95%|█████████▌| 660/692 [00:16\u003c00:00, 40.62it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 660 Loss: 12.796254920959473 Accuracy: 0.0546420730650425:  95%|█████████▌| 660/692 [00:16\u003c00:00, 40.62it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 660 Loss: 12.796254920959473 Accuracy: 0.0546420730650425:  96%|█████████▌| 665/692 [00:16\u003c00:00, 40.51it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 660 Loss: 12.796254920959473 Accuracy: 0.0546420730650425:  97%|█████████▋| 670/692 [00:16\u003c00:00, 40.77it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 670 Loss: 12.575613307952882 Accuracy: 0.053189515322446826:  97%|█████████▋| 670/692 [00:16\u003c00:00, 40.77it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 670 Loss: 12.575613307952882 Accuracy: 0.053189515322446826:  98%|█████████▊| 675/692 [00:16\u003c00:00, 40.52it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 670 Loss: 12.575613307952882 Accuracy: 0.053189515322446826:  98%|█████████▊| 680/692 [00:16\u003c00:00, 40.75it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 680 Loss: 12.749401378631593 Accuracy: 0.05370619632303715:  98%|█████████▊| 680/692 [00:16\u003c00:00, 40.75it/s] \u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 680 Loss: 12.749401378631593 Accuracy: 0.05370619632303715:  99%|█████████▉| 685/692 [00:16\u003c00:00, 40.59it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 680 Loss: 12.749401378631593 Accuracy: 0.05370619632303715: 100%|█████████▉| 690/692 [00:17\u003c00:00, 40.76it/s]\u001b[A\u001b[A\n","\n","Epoch: 9 Iteration: 690 Loss: 12.753700923919677 Accuracy: 0.049681270495057106: 100%|██████████| 692/692 [00:17\u003c00:00, 40.56it/s]\n"]}],"source":["# Skeleton code\n","# You have to write your own training process to obtain a\n","# Good performing model on the validation set, and save it.\n","\n","model.train()\n","losses = []\n","accuracies = []\n","from tqdm import tqdm\n","for epoch in range(epochs):\n","    indices = np.random.permutation(range(len(d_train)))\n","    t = tqdm(range(0,(len(d_train)//batch_size)+1))\n","    for i in t:\n","        # Here is how you obtain a batch:\n","        batch = build_batch(d_train, indices[i*batch_size:(i+1)*batch_size])\n","        (batch_input, batch_target, batch_target_mask) = batch_to_torch(*batch)\n","        (batch_input, batch_target, batch_target_mask) = list_to_device((batch_input, batch_target, batch_target_mask))\n","        model.to(device)\n","        \n","        prediction = model.forward(batch_input) #####\n","        loss = loss_fn(prediction, batch_target, batch_target_mask) ######\n","        losses.append(loss.item())\n","        accuracy = (th.eq(prediction.argmax(dim=2,keepdim=False),batch_target).float()*batch_target_mask).sum()/batch_target_mask.sum()\n","        accuracies.append(accuracy.item())\n","\n","        loss.backward()\n","        optimizer.step()\n","        #your_code ####\n","        if i % 10 == 0:\n","            t.set_description(f\"Epoch: {epoch} Iteration: {i} Loss: {np.mean(losses[-10:])} Accuracy: {np.mean(accuracies[-10:])}\")\n","    # save your latest model\n","    save_dict = dict(\n","        kwargs = dict(\n","            vocab_size=vocab_size,\n","            rnn_size=hidden_size,\n","            num_layers=num_layers,\n","            dropout=dropout\n","        ),\n","        model_state_dict = model.state_dict(),\n","        notes = \"\",\n","        optimizer_class = optimizer_class,\n","        lr = lr,\n","        epochs = epochs,\n","        batch_size = batch_size,\n","    )\n","    th.save(save_dict,root_folder+f'models/part1/model_{model_id}.pt')"]},{"cell_type":"markdown","metadata":{"id":"fhaj6XIdyUKZ"},"source":["# Using the language model"]},{"cell_type":"markdown","metadata":{"id":"9lgsKMqmyUKa"},"source":["Congratulations, you have now trained a language model! We can now use it to evaluate likely news headlines, as well as generate our very own headlines.\n","\n","**TODO**: Complete the three parts below, using the model you have trained."]},{"cell_type":"markdown","metadata":{"id":"EnR8ma3cyUKb"},"source":["## (1) Evaluation loss\n","\n","To evaluate the language model, we evaluate its loss (ability to predict) on unseen data that is reserved for evaluation.\n","Your first evaluation is to load the model you trained, and obtain a test loss. If you are running this validation and not training, run the setup cell above the training loop first."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zkL164RCyUKc"},"outputs":[],"source":["model_id = \"test1\"\n","save_dict = th.load(root_folder+'models/part1/'+f\"model_{model_id}.pt\",map_location='cpu')\n","model = LanguageModel(**save_dict['kwargs'])\n","model.load_state_dict(save_dict['model_state_dict'])\n","model.eval()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o0B71owvyUKe"},"outputs":[],"source":["# We will evaluate your model in the best_models folder\n","# In a very similar way as the code below.\n","# Make sure your validation loss is below the threshold we specified\n","# and that you didn't train using the validation set\n","\n","batch = build_batch(d_valid, range(len(d_valid)))\n","(batch_input, batch_target, batch_target_mask) = batch_to_torch(*batch)\n","prediction = model(batch_input.long())\n","loss = loss_fn(prediction, batch_target, batch_target_mask)\n","print(\"Evaluation set loss:\", loss.item())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2W-FFdHoyUKg"},"outputs":[],"source":["# Your best performing model should go here.\n","os.makedirs(root_folder+\"best_models\",exist_ok=True)\n","best_model_file = root_folder+\"best_models/part1_best_model.pt\"\n","th.save(save_dict,best_model_file)"]},{"cell_type":"markdown","metadata":{"id":"-oP9wBwfyUKj"},"source":["## (2) Evaluation of likelihood of data\n","\n","One use of a language model is to see what data is more likely to have originated from the training data. Because we have trained our model on news headlines, we can see which of these headlines is more likely:\n","\n","``Apple to release another iPhone in September``\n","\n","\n"," ``Apple and Samsung resolve all lawsuits amicably``\n"," \n","**TODO**: Use the model to obtain the loss the neural network assigns to each sentence.\n","Because the neural network assigns probability to the words appearing in a sequence, this loss can be used as a proxy to measure how likely the sentence is to have occurred in the dataset.\n","Once you have the loss for each headline, write down which sentence was judged to be more likely, and explain why/if you think this is coherent.\n","\n","**Your answer:**\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CH-YlqE2yUKk"},"outputs":[],"source":["def raw_sample_pred(headline, model):\n","    #####\n","    # BEGIN YOUR CODE HERE \n","    #####\n","    # From the code in the Preprocessing section at the end of the notebook\n","    # Find out how to tokenize the headline\n","    tokenized = your_code\n","\n","    # Find out how to numerize the tokenized headline\n","    numerized = your_code\n","\n","    # Learn how to pad and obtain the mask of the sequence.\n","    padded, mask = your_code\n","\n","    # Obtain the predicted headline and target headline\n","    input_headline = your_code\n","    pred_headline = your_code\n","    target_headline = your_code\n","    mask = your_code\n","\n","    #####\n","    # END YOUR CODE HERE \n","    #####\n","\n","    return pred_headline,target_headline,mask"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LexHAsuiyUKm"},"outputs":[],"source":["model.eval()\n","\n","headline1 = \"Apple to release new iPhone in July\"\n","headline2 = \"Apple and Samsung resolve all lawsuits\"\n","\n","headlines = [headline1.lower(), headline2.lower()] # Our LSTM is trained on lower-cased headlines\n","for headline in headlines:\n","    pred_headline,target_headline,mask = raw_sample_pred(headline, model)\n","    loss = your_code # Obtain the loss\n","    \n","    print(\"----------------------------------------\")\n","    print(\"Headline:\", headline)\n","    print(\"Loss of the headline:\", loss)\n","validate_to_array(raw_sample_pred,zip(headlines,[model]*2),'raw_sample_pred',root_folder,multi=True)\n","# Important check: one headline should be more likely (and have lower loss)\n","# Than the other headline. You should know which headline should have lower loss."]},{"cell_type":"markdown","metadata":{"id":"kpn8XlLXyUKn"},"source":["## (3) Generation of headlines\n","\n","We can use our language model to generate text according to the distribution of our training data.\n","The way generation works is the following:\n","\n","We seed the model with a beginning of sequence, and obtain the distribution for the next word.\n","We select the most likely word (argmax) and add it to our sequence of words.\n","Now our sequence is one word longer, and we can feed it in again as an input, for the network to produce the next sentence.\n","We do this a fixed number of times (up to 20 words), and obtain automatically generated headlines!\n"]},{"cell_type":"markdown","metadata":{"id":"hycdvFs6yUKo"},"source":["We have provided a few headline starters that should produce interesting generated headlines.\n","\n","**TODO:** Get creative and find at least 2 more headline_starters that produce interesting headlines."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GCYvwLw1yUKp"},"outputs":[],"source":["def generate_sentence(headline_starter, model):\n","    # Tokenize and numerize the headline. Put the numerized headline\n","    # beginning in `current_build`\n","    tokenized = tokenizer.word_tokenizer(headline_starter.lower())\n","    current_build = [startI] + numerize_sequence(tokenized)\n","\n","    while len(current_build) \u003c input_length:\n","        # Pad the current_build into a input_length vector.\n","        # We do this so that it can be processed by our LanguageModel class\n","        current_padded, _m = pad_sequence(current_build, padI, input_length)\n","\n","        # Obtain the logits for the current padded sequence\n","        # This involves obtaining the output_logits from our model,\n","        # and not the loss like we have done so far\n","        logits = your_code\n","        logits_np = logits.detach().cpu().numpy()\n","\n","        # Obtain the row of logits that interest us, the logits for the last non-pad\n","        # inputs\n","        last_logits = your_code\n","\n","        # Find the highest scoring words in the last_logits\n","        # array, or sample from the softmax.\n","        # The np.argmax function may be useful for first option,\n","        # sp.special.softmax and np.random.choice may be useful for second option.\n","        # Append this word to our current build\n","        current_build.append(your_code)\n","\n","    # Go from the current_build of word_indices\n","    # To the headline (string) produced. This should involve\n","    # the vocabulary, and a string merger.\n","    produced_sentence = your_code\n","    return produced_sentence"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xVKeMmSAyUKq","scrolled":true},"outputs":[],"source":["model.eval()\n","# Here are some headline starters.\n","# They're all about tech companies, because\n","# That is what is in our dataset\n","headline_starters = [\"apple has released\", \"google has released\", \"amazon\", \"tesla to\"]\n","for headline_starter in headline_starters:\n","    print(\"===================\")\n","    print(\"Generating headline starting with: \"+headline_starter)\n","\n","    produced_sentence = generate_sentence(headline_starter, model)\n","    print(produced_sentence)\n","validate_to_array(generate_sentence,zip(headline_starters,[model]*len(headline_starters)),\"generate_sentence\",root_folder,multi=True)"]},{"cell_type":"markdown","metadata":{"id":"JQ6ni5GZyUKr"},"source":["## All done\n","\n","You are done with the first part of the HW.\n","\n","Next notebook deals with Summarization of text!\n"]},{"cell_type":"markdown","metadata":{"id":"QoPgKURxyUKs"},"source":["# Preprocessing (read only)\n"]},{"cell_type":"markdown","metadata":{"id":"FfOq00MZyUKt"},"source":["**You can skip this section, however you may find these functions useful in later sections of this notebook**\n","\n","We have provided this code so you see how the dataset was generated. You will have to come back some of these functions later in the assignment, so feel free to read through, to get familiar."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uS8FUmo9yUKt"},"outputs":[],"source":["# You do not need to run this\n","# This is to show you how the dataset was created\n","# You should read to understand, so you can preprocess text\n","# In the same way, in the evaluation section\n","\n","for a in dataset:\n","    a['tokenized'] = tokenizer.word_tokenizer(a['title'].lower())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g_9okOHoyUKu","scrolled":true},"outputs":[],"source":["# You do not need to run this\n","# This is to show you how the dataset was created\n","# You should read to understand, so you can preprocess text\n","# In the same way, in the evaluation section\n","\n","word_counts = Counter()\n","for a in dataset:\n","    word_counts.update(a['tokenized'])\n","\n","print(word_counts.most_common(30))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OhNeO1LdyUKv"},"outputs":[],"source":["# You do not need to run this\n","# This is to show you how the dataset was created\n","# You should read to understand, so you can preprocess text\n","# In the same way, in the evaluation section\n","\n","# Creating the vocab\n","vocab_size = 20000\n","special_words = [\"\u003cSTART\u003e\", \"UNK\", \"PAD\"]\n","vocabulary = special_words + [w for w, c in word_counts.most_common(vocab_size-len(special_words))]\n","w2i = {w: i for i, w in enumerate(vocabulary)}\n","\n","# Numerizing and padding\n","input_length = 20\n","unkI, padI, startI = w2i['UNK'], w2i['PAD'], w2i['\u003cSTART\u003e']\n","\n","for a in dataset:\n","    a['numerized'] = numerize_sequence(a['tokenized']) # Change words to IDs\n","    a['numerized'], a['mask'] = pad_sequence(a['numerized'], padI, input_length) # Append appropriate PAD tokens\n","    \n","# Compute fraction of words that are UNK:\n","word_counters = Counter([w for a in dataset for w in a['input'] if w != padI])\n","\n","print(\"Fraction of UNK words:\", float(word_counters[unkI]) / sum(word_counters.values()))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rpeDdDrUyUKw"},"outputs":[],"source":["# You do not need to run this\n","# This is to show you how the dataset was created\n","# You should read to understand, so you can preprocess text\n","# In the same way, in the evaluation section\n","\n","d_released_processed   = [d for d in dataset if d['cut'] != 'testing']\n","d_unreleased_processed = [d for d in dataset if d['cut'] == 'testing']\n","\n","with open(\"dataset/headline_generation_dataset_processed.json\", \"w\") as f:\n","    json.dump(d_released_processed, f)\n","\n","# This file is purposefully left out of the assignment, we will use it to evaluate your model.\n","with open(\"dataset/headline_generation_dataset_unreleased_processed.json\", \"w\") as f:\n","    json.dump(d_unreleased_processed, f)\n","    \n","with open(\"dataset/headline_generation_vocabulary.txt\", \"w\") as f:\n","    f.write(\"\\n\".join(vocabulary).encode('utf8'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lS--8I0KlDvO"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","anaconda-cloud":{},"colab":{"collapsed_sections":[],"machine_shape":"hm","name":"1 Language Modeling.ipynb","toc_visible":true,"version":""},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false}},"nbformat":4,"nbformat_minor":0}